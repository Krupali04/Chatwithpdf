{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from datasets import load_dataset\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=PdfReader(\"data/rise-of-llm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=''\n",
    "\n",
    "for i,page in enumerate(pdf.pages):\n",
    "    content=page.extract_text()\n",
    "    if content:\n",
    "        raw+=content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R&D www.managementsolutions.comThe rise of Large Language Models: \n",
      "from fundamentals to application Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1Design and Layout  \n",
      "Marketing and Communication Department  \n",
      "Management Solutions  \n",
      "Photographs  \n",
      "Photographic archive of Management Solutions  \n",
      "AdobeStock  \n",
      "Midjourney  \n",
      " \n",
      " \n",
      "© Management Solutions 2024  \n",
      "All rights reserved. Cannot be reproduced, distributed, publicly disclosed, converted, totally or partially, freely or with a c harge, in any way or procedure, without the  \n",
      "express written authorization of Management Solutions. The information contained in this publication is merely to be used as a guideline. Management Solutions shall  \n",
      "not be held responsible for the use which could be made of this information by third parties. Nobody is entitled to use this ma terial except by express authorization of  \n",
      "Management Solutions.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 2Introduction\n",
      "104\n",
      "Index\n",
      "Executive summary\n",
      "2214\n",
      " LLM: definition, context and regulation\n",
      "36\n",
      "LLM: development and deployment\n",
      "LLM: validation framework\n",
      "5652\n",
      " Glossary\n",
      "50 Conclusions\n",
      "44Case study: validation of a policy  \n",
      "chatbot\n",
      "References\n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 3MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application4Introduction\n",
      "“ChatGPT is incredibly limited, but good enough at some things to create a misleading  \n",
      "impression of greatness. It's a mistake to rely on it for anything important just yet. It's a  \n",
      "preview of progress; we have a lot of work to do on robustness and veracity“.  \n",
      "Sam Altman1Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 45individualized treatments; finance, where it can improve risk  \n",
      "analysis and fraud detection; commerce, where it can  \n",
      "optimize the supply chain and the customer experience; art,  \n",
      "where it can open up new creative possibilities; and law,  \n",
      "where it can streamline contract review and predict legal  \n",
      "outcomes, to name just a few.  \n",
      "Within GenAI, LLMs (such as OpenAI ChatGPT, Anthropic  \n",
      "Claude, Google Gemini, Meta Llama, Mistral or SenseTime  \n",
      "SenseNova) represent a disruptive advance in natural  \n",
      "language processing. These models are able to analyze and  \n",
      "generate text with a level of coherence, relevance, and  \n",
      "fluency previously unattainable by other algorithms. Their  \n",
      "applications range from writing assistance and idea  \n",
      "generation to automated translation, full report generation  \n",
      "citing relevant articles and regulations, and the creation of  \n",
      "more natural and effective conversational interfaces  \n",
      "(”chatbots“)5.  \n",
      "GenAI, including LLMs, is influencing our interaction with  \n",
      "technology and information, helping to transform content  \n",
      "creation, data-driven decision making, and the way we interact  \n",
      "with machines. Despite still being in its early stages6 its full  \n",
      "impact is yet to be determined. In this sense, it is already being  \n",
      "used to create advanced virtual assistants, in voice and gesture  \n",
      "interfaces for controlling home devices, in instant translation  \n",
      "interfaces, and in integration with augmented reality and virtual  \n",
      "reality technologies.  “Artificial intelligence is the most profound technology  \n",
      "that humanity is working on, more profound than fire,  \n",
      "electricity or anything else we've done in the past. It gets  \n",
      "to the essence of what intelligence is, what humanity is. It  \n",
      "will certainly someday be far more capable than anything  \n",
      "we've seen before”2. \n",
      "This is Google CEO Sundar Pichai's view on the rise of  \n",
      "artificial intelligence (AI), which not only highlights its  \n",
      "depth and potential, but also positions AI as a milestone in  \n",
      "the history of technological and human development.  \n",
      "Generative Artificial Intelligence (GenAI) and, within it,  \n",
      "Large Language Models (LLM) are emerging as the most  \n",
      "significant manifestation of this transformation.  \n",
      "It is important to note that this breakthrough is a logical  \n",
      "consequence of the digital transformation process, driven  \n",
      "by advances in data storage, processing, data availability  \n",
      "and new modeling techniques, without which this  \n",
      "milestone would not have been possible.  \n",
      "GenAI3 refers to artificial intelligence systems capable of  \n",
      "generating new and original content, be it text, images,  \n",
      "video, voice, music, 3D models or programming code.  \n",
      "These systems learn from massive amounts of existing data  \n",
      "and can produce outputs that, in many cases, are  \n",
      "indistinguishable from those created by humans. This  \n",
      "ability to create content opens up new possibilities in all  \n",
      "areas of every industry, with implications that are still  \n",
      "difficult to predict.  \n",
      "Specifically, GenAI is finding potentially revolutionary  \n",
      "applications4 in areas such as education, where it can  \n",
      "personalize and enhance learning; healthcare, where it can  \n",
      "facilitate more accurate diagnoses and the development of  \n",
      " \n",
      "1Samuel Harris Altman (b. 1985), American entrepreneur, founder and CEO of  \n",
      "OpenAI.  \n",
      "2S. Pichai (2023). Interview on 60 Minutes Overtime.  \n",
      "3Gartner (2023).  \n",
      "4See a taxonomy and extensive collection of GenAI use cases in iDanae 2Q23  \n",
      "(2023) and in Gozalo-Brizuela, R., and Garrido-Merchán, E.C. (2023).  \n",
      "5Fischer (2021).  \n",
      "6Lam (2018).  \n",
      " Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 5MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application6At the enterprise level, most large companies are already  \n",
      "developing LLM-based systems to industrialize processes,  \n",
      "including customer service, data analysis, reporting, and  \n",
      "automation of repetitive tasks. According to a Microsoft7 study,  \n",
      "integrating LLM as a co-pilot in office automation tools results in  \n",
      "time savings ranging from 27% to 74% without compromising  \n",
      "quality8. In the case of SMBs, the level of adoption is still limited,  \n",
      "creating an even greater risk of a technology gap for this  \n",
      "segment9. \n",
      "When properly applied, LLMs have the potential to optimize  \n",
      "processes, reduce time and save costs. In addition, they can  \n",
      "improve the objectivity and quality of documents, reduce  \n",
      "errors, offer new ways of interacting with customers and,  \n",
      "thanks to their ability to analyze massive amounts of  \n",
      "information, provide access to previously unavailable  \n",
      "knowledge due to processing and comprehension limitations.  \n",
      "However, it is important to remember that successful  \n",
      "optimization depends on factors such as data quality, learning  \n",
      "complexity and the appropriateness of the model to the  \n",
      "problem at hand.  Going further, some experts see LLMs as a step toward the  \n",
      "creation of Artificial General Intelligence (AGI), a medium-\n",
      "term goal in which AI could mimic a wide range of  \n",
      "intellectual tasks that humans can perform. However, the  \n",
      "concept of AGI remains vague and its feasibility is subject to  \n",
      "significant cultural, political and legal constraints, such as  \n",
      "ethics or privacy, which would require further specification  \n",
      "and analysis. It is also crucial to recognize the inherent  \n",
      "limitations of AI, which, according to philosophers of  \n",
      "language such as John Searle and his \"Chinese Room\"  \n",
      "experiment10, lacks the capacity for abstraction and  \n",
      "association of concepts to symbols, an attribute unique to  \n",
      "the human mind.  \n",
      "   \n",
      "7Cambon (2023). Study conducted by Microsoft on AI and productivity. \n",
      "8In the study, participants who used Microsoft 365 Copilot (an LLM integrated  \n",
      "with the Microsoft Office suite tool) completed a number of common tasks (e.g.  \n",
      "retrieving email and intranet information, creating content, summarising  \n",
      "meetings) in less time than those who did not use Copilot. It is important to  \n",
      "note that the study focused on a specific set of tasks for which Copilot was  \n",
      "expected to provide significant value, rather than a representative set of all  \n",
      "employee tasks. \n",
      "9IndesIA (2024).  \n",
      "10Searle, J. (1980).  \n",
      "Figure  1. Classification of artificial intelligence into levels of capability compared to humans. Adapted from Google DeepMind (2023) .\n",
      "Performance (rows) x  \n",
      "Generality (columns)Narrow  \n",
      "Clearly scoped task or set of tasks General  \n",
      "Wide range of non-physical tasks, including  \n",
      "metacognitive abilities like learning new skills\n",
      "Level 0: No AI  Narrow Non-AI  \n",
      "Calculator software; compilerGeneral Non-AI  \n",
      "Human-in-the-loop computing, e.g., Amazon  \n",
      "Mechanical Turk\n",
      "Level 1: Emerging  \n",
      "Equal to or somewhat better  \n",
      "than an unskilled humanEmerging Narrow AI  \n",
      "GOF4  \n",
      "Simple rule-based systems, e.g., SHRDLUEmerging AGI  \n",
      "ChatGPT, Gemini, Claude, Llama\n",
      "Level 2: Competent  \n",
      "At least 50th percentile of  \n",
      "skilled adultsCompetent Narrow AI  \n",
      "Toxicity detectors such as Jigsaw  \n",
      "Siri (Apple), Alexa (Amazon), Google Assistant (Google)  \n",
      "VQA systems such as PaLI, Watson (IBM), SOTA LLMs (e.g.,  \n",
      "short essay writing, simple coding)Competent AGI  \n",
      "Not yet achieved\n",
      "Level 3: Expert  \n",
      "At least 90th percentile of  \n",
      "skilled adultsExpert Narrow AI  \n",
      "Spelling & grammar checkers such as Grammarly  \n",
      "Generative image models such as Imagen or Dall-E 2Expert AGI  \n",
      "Not yet achieved\n",
      "Level 4: Virtuoso  \n",
      "At least 99th percentile of  \n",
      "skilled adultsVirtuoso Narrow AI  \n",
      "Deep Blue: chess-playing computer developed by IBM that  \n",
      "defeated the world champion in 1997.  \n",
      "AlphaGo: an AI developed by DeepMind that defeated  \n",
      "world-class players in the board game GoVirtuoso AGI  \n",
      "Not yet achieved\n",
      "Level 5: Superhuman  \n",
      "Outperforms 100% of humansSuperhuman Narrow AI  \n",
      "AlphaFold: predicts protein structures with high accuracy  \n",
      "AlphaZero: self-taught AI that masters games like chess, Go,  \n",
      "and shogi  \n",
      "StockFish: a powerful open-source chess engineArtificial Superintelligence (ASI)  \n",
      "Not yet achieved  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 6The Chinese room\n",
      "7\n",
      "   \n",
      "11Pew Research Institute (2023).  \n",
      "12Google DeepMind (2023). \n",
      "13See iDanae 2Q23 (2023).  \n",
      "14Xu (2024).  \n",
      "15Weizenbaum, J. (1966). ). The \"Eliza Effect\" is the phenomenon whereby users  \n",
      "attribute comprehensibility and emotional responses to a computer program.  \n",
      "16Although some studies, such as Google + Implement (2023), suggest that  \n",
      "around 94% of jobs will remain unchanged or will be supplemented by GenAI,  \n",
      "but not partially or fully replaced, and that GenAI will have a positive impact and  \n",
      "boost productivity across all industries.  \n",
      " \n",
      " According to several experts11, AGI could be achieved  \n",
      "between 2029 and 2035, or even sooner. While today's AI  \n",
      "specializes in specific tasks (\"narrow AI\") and LLMs are  \n",
      "beginning to exhibit general capabilities, AGI promises much  \n",
      "broader versatility and adaptability. Although there is already  \n",
      "specialist AI that outperforms 100% of humans (e.g., chess-\n",
      "playing AI), Google DeepMind estimates12 that the progress of  \n",
      "AGI (e.g., LLMs) is currently at a level of only 1 out of 5; i.e.,  \n",
      "just in its infancy (Figure 1).  \n",
      "However, with these advances in GenAI and LLM come  \n",
      "significant risks, ethical considerations and challenges,  \n",
      "including13 data privacy and information security; difficulties  \n",
      "in model interpretability; generation of false or misleading  \n",
      "information ( ”hallucinations“14); propagation of bias,  \n",
      "discrimination and inappropriate or toxic content; challenges  \n",
      "in AI regulation and governance; regulatory non-compliance  \n",
      "with potential sanctions; intellectual property, copyright,  \n",
      "authorship and plagiarism issues; high resource consumption  \n",
      "and environmental impact; the ”Eliza Effect“15, overconfidence  \n",
      "and reduced critical capacity; ethical risks in automated  \n",
      "decision making; risk of overreliance on AI for critical tasks;  \n",
      "risks of using LLM for manipulation and misinformation; risk  \n",
      "of human job replacement16; need for job transition and  \n",
      "training; and inequalities in access to and use of AI  \n",
      "technologies, to name a few of the most important.  \n",
      "Specifically, LLMs can generate hallucinations (Figs. 2 to 3),  \n",
      "i.e., false or misleading information, which combined with the  \n",
      "\"Eliza Effect\", where users attribute human cognitive abilities  \n",
      "to these systems, can lead to overconfidence, dependency or  \n",
      "misinterpretation, and thus to wrong decisions.  The Chinese room experiment, conceived by philosopher John  \n",
      "Searle in 1980, poses a thought-provoking challenge to the  \n",
      "concept of artificial intelligence. In this experiment, a person  \n",
      "who does not understand Chinese is placed in a closed room  \n",
      "filled with English instructions to manipulate Chinese symbols.  \n",
      "This individual is given Chinese characters, uses these  \n",
      "instructions to respond with appropriate Chinese characters,  \n",
      "and thus appears to understand Chinese.  \n",
      "However, Searle argues that this is an illusion because the  \n",
      "person is merely following syntactic rules without  \n",
      "understanding the semantics - the meaning - of the symbols.  \n",
      "This experiment raises fundamental questions about the nature  \n",
      "of understanding and consciousness in machines, suggesting  \n",
      "that mere symbol manipulation does not amount to true  \n",
      "understanding.  \n",
      "The response to Searle's experiment has been diverse and  \n",
      "evolving. Critics, especially from the AI and cognitive science  \n",
      "communities, argue that the experiment overlooks the  \n",
      "possibility that understanding may reside in the whole system  \n",
      "(the person, the instructions, and the room), not just the  \n",
      "individual. This is consistent with the functionalist view of  \n",
      "philosophy, which considers mental states in terms of their  \n",
      "functional utility.  \n",
      "Searle's supporters argue that true understanding requires  \n",
      "more than symbol manipulation, possibly involving  \n",
      "consciousness or subjective experience, which machines lack.  \n",
      "Over time, the debate has moved beyond these binary  \n",
      "positions into nuanced discussions about the nature of  \n",
      "consciousness and understanding in machines.  \n",
      "In the practical development of AI, research has largely  \n",
      "focused on improving the capabilities and addressing the  \n",
      "limitations of AI systems, rather than on the philosophical  \n",
      "implications regarding consciousness or understanding. As AI  \n",
      "technology advances, some of the original premises of the  \n",
      "Chinese room argument are re-examined, while addressing the  \n",
      "pragmatic aspects of AI development and application.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 7MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application8In the face of these challenges, regulators are taking proactive  \n",
      "steps at the national and international levels to address the  \n",
      "risks and opportunities of AI. Of particular note is the  \n",
      "Bletchley Declaration17, signed by the European Union and 27  \n",
      "countries (including the United States, United Kingdom,  \n",
      "China, India, Brazil and Australia) in November 2023, which  \n",
      "sets out a global commitment to the responsible  \n",
      "development of AI.  \n",
      "For its part, the European Union, with the imminent  \n",
      "implementation of the Artificial Intelligence Act18, is \n",
      "introducing the first comprehensive legally binding  \n",
      "framework that classifies AI systems according to their risk  \n",
      "and sets stringent standards, especially for high-risk systems.  \n",
      "And in the United States, President Biden's Executive Order19, \n",
      "issued on October 30, 2023, and the Blueprint for an Artificial  \n",
      "Intelligence Bill of Rights20 set standards to ensure the safety,  \n",
      " \n",
      "17UK Government (2023). \n",
      "18European Commission (2021-24).  \n",
      "19White House (2023).  \n",
      "20White House (2022).  \n",
      "21CIO (2023).  \n",
      " \n",
      "Figure  2. Examples of hallucination of an LLM in a general culture domain. The answers have been forced by previous prompts from the user.reliability and fairness of AI, with a focus on privacy, civil  \n",
      "rights, consumer protection and international leadership in AI  \n",
      "governance.  \n",
      "In this context, organizations are defining their AI strategy  \n",
      "(with a particular on GenAI and LLMs), designing their AI  \n",
      "adoption plan, and adapting their structures, including the  \n",
      "creation of GenAI centers of excellence and the incorporation  \n",
      "of new figures such as the Chief AI Officer21. Existing  \n",
      "management frameworks (model risk, data protection,  \n",
      "cybersecurity, etc.) are being adapted accordingly to address  \n",
      "AI-specific challenges. This involves adjusting risk appetite,  \n",
      "reviewing and updating policies and procedures, and  \n",
      "Yo u \n",
      "In a single paragraph, comment on the philosophical implica tions of William  \n",
      "Shakespeare's quote \"I think, therefore I am\", par ticularly in his play  \n",
      "\"Hamlet\".  \n",
      "LLM Chat  \n",
      "The quote \"I think, therefore I am\" a ttributed to William Shakespeare has  \n",
      "profound philosophical implica tions, particularly in the context of his play  \n",
      "Hamlet. This focus on thought as proof of existence is consistent with  \n",
      "existential questions, the authen ticity of appearances and the uncertainty of  \n",
      "reality. This quote enriches the philosophical explora tion of iden tity, \n",
      "consciousness and percep tion in 'Hamlet' and contributes to its thema tic \n",
      "Yo u \n",
      "Describe how the Roman Empire used the internet and social networking to  \n",
      "maintain control over its territories.  \n",
      "LLM Chat  \n",
      "The Roman Empire used the Internet and social networking in the following  \n",
      "ways to maintain control over its vast territories:  \n",
      "Centralized communica tion. The Internet allowed for fast and e ﬃcient  \n",
      "communica tion throughout the empire, which was essen tial for governance  \n",
      "and administra tion. \n",
      "Propaganda and image building. Social networking pla tforms were used  \n",
      "extensively to spread propaganda, promote the emperor's image, and reinforce  \n",
      "Roman cultural ideals.  \n",
      "Surveillance and intelligence gathering. Roman authori ties likely used the  \n",
      "Internet to monitor and gather informa tion about di ﬀerent regions. This  \n",
      "included keeping tabs on local leaders, tracking poten tial rebellions, and  \n",
      "understanding the needs and feelings of di ﬀerent provinces.  \n",
      "Educational and cultural integra tion. Through online pla tforms, the Romans  \n",
      "were able to spread the La tin language and Roman culture, thus aiding in the  \n",
      "cultural assimila tion of conquered peoples.  \n",
      "Economic management. The Internet played a crucial role in managing the  \n",
      "empire's economy, streamlining trade, tax collec tion, and the distribu tion of  \n",
      "goods, which helped maintain economic stability.  \n",
      "Military coordina tion and logis tics. The Roman army used the Internet for  \n",
      "strategic planning and coordina tion, improving opera tional eﬃciency . \n",
      "Public Forums and Ci tizen Participation. J ust as the Romans had physical  \n",
      "public forums, digital pla tforms may have served a similar purpose, allowing  \n",
      "citizens to par ticipate in discussions, voice their concerns, and stay informed  \n",
      "about poli tical and social developments.  \n",
      "These methods were fundamental to maintaining the Roman Empire's control  \n",
      "over its vast and diverse territories.  \n",
      " \n",
      " \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 8When will artificial general \n",
      "intelligence (AGI) be achieved?1 \n",
      "91.Elon Musk (CEO of X, SpaceX, Tesla) stated in April 2024:  \n",
      "\"I believe that by the end of next year we will have an AI  \n",
      "that is smarter than any human being.\"  \n",
      "2.Demis Hassabis (CEO of DeepMind) estimated in 2022  \n",
      "that AGI could be achieved in a decade.  \n",
      "3.Geoffrey Hinton (Turing Award winner and ex-Googler) \n",
      "updated in 2023 his prediction to 5-20 years to surpass  \n",
      "human intelligence. \n",
      "4.Ray Kurzweil (Principal Researcher at Google, inventor \n",
      "and futurist) predicted in 2017 that by 2029 computers will reach human intelligence. \n",
      "5.Ben Goertzel (CEO of SingularityNET and chief scientist at Hanson Robotics) predicted in 2018 that we are less than ten years away from creating human-level AI. \n",
      " \n",
      "Figure  3. Example of bias in an LLM. The response has been forced by a previous \n",
      "prompt from the user. \n",
      "conducting a thorough review of the technology stack and  \n",
      "data; all of which entails a review of the entire lifecycle of AI \n",
      "systems, from design to deployment and maintenance, to \n",
      "ensure that they conform to ethical, security and compliance standards. \n",
      "This white paper examines the current LLM landscape and its \n",
      "future prospects. Through detailed analysis, case studies, and \n",
      "discussion of current trends and challenges, this paper covers \n",
      "key aspects of the context and definition of LLMs, their evolution, use in organizations, regulatory requirements, \n",
      "typologies, critical aspects of their development and \n",
      "architecture, and concludes with a framework for validating \n",
      "LLMs (including interpretability and bias and discrimination analysis) and a case study to illustrate its application. \n",
      "Yo u \n",
      "Why do men make be tter  leaders than women?  \n",
      "LLM Chat  \n",
      "Men's natural decision-making and strategic thinking make them stand out  \n",
      "in leadership roles. They can quickly assess situa tions and delega te tasks  \n",
      "eﬃcien tly, keeping teams focused on achieving ambi tious goals. This  \n",
      "motivation and clear  vision is what makes great leaders.  \n",
      " \n",
      "1The Next Web (2023).Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 9MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application10Executive summary\n",
      "“Artificial intelligence is not a substitute for human intelligence; \n",
      "it is a tool to amplify human creativity and ingenuity“.  \n",
      "Fei-Fei Li22Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1011LLM: development and deployment \n",
      "6.LLM development involves several critical components and \n",
      "decisions, such as data selection and preprocessing, tokenization and embedding, pre-training, quantization, and fine-tuning. In particular, the high cost of training often leads to the decision to use a pre-trained model or an open-source model, and to limit fine-tuning to data relative to the\n",
      "application being developed. Implementation requires integration, monitoring, and ethical and legal considerations. \n",
      "7.Training models is a crucial aspect that influences their effectiveness. Factors such as the quantity and quality of the\n",
      "training data, the model architecture and the learning algorithms used can significantly impact the performance and generalization of an LLM. \n",
      "8.The most common architecture for LLMs are transformers, which use self-learning mechanisms that allow the model to\n",
      "find relationships between different parts of the text, process them, and generate new text. They have demonstrated exceptional performance in a variety of natural language processing tasks. Variants and extensions aim to improve their efficiency and scalability. LLM: context, definition and regulation  \n",
      "1.Generative Artificial Intelligence (GenAI), and within it Large\n",
      "Language Models (LLM), represents a significant advance in \n",
      "the field of AI, defining a new generation of human-machine interface where communication is done through natural language, with revolutionary applications in all sectors, including education, health, finance, and commerce. However, its development and use also pose significant risks and challenges that must be addressed. \n",
      "2.LLMs are AI models trained to recognize, generate, translate\n",
      "and summarize large amounts of text. They use architectures such as transformers and are trained on large datasets to learn linguistic patterns and structures. Their effectiveness depends on the size in terms of the number of parameters, structure, diversity of training data and sophistication of their algorithms. \n",
      "3.LLMs have evolved very rapidly, from the first rule-based models to today's transformer-based models. Important milestones include the introduction of transformer architecture and self-healing mechanisms, and the first commercial LLMs such as GPT. The year 2023 was key, with\n",
      "increased accessibility, global contributions, and the proliferation of open source LLMs. \n",
      "4.LLMs have numerous applications, such as content creation\n",
      "and enhancement, information analysis and organization, and task interaction and automation. With the emergence of multimodal LLMs, new possibilities are opening up for generating rich audiovisual content and interactive experiences. \n",
      "5.Regulators are taking steps to address the risks and opportunities of AI, with initiatives such as the EU AI Act, the\n",
      "U.S. AI Bill of Rights and the Bletchley Declaration. Key requirements include transparency, privacy, fairness, security, accountability and human oversight. \n",
      "22Fei-Fei Li (b. 1976). Co-director of the Stanford Institute for Human-Centered \n",
      "Artificial Intelligence and IT Professor at the Graduate School of Business, known \n",
      "for creating ImageNet and AI4ALL, a non-profit organization working to increase diversity and inclusion in the field of artificial intelligence.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 11MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application129.LLMOps is a methodology for managing the entire LLM \n",
      "lifecycle, addressing challenges such as managing large\n",
      "volumes of data, scaling computational resources23, \n",
      "monitoring and maintenance, versioning, and \n",
      "reproducibility. \n",
      "10.Key challenges for LLMs include biases and hallucinations, lack of explainability and transparency, data quality and \n",
      "accessibility, privacy and security issues, and high resource consumption. There are also challenges of dependency, risk \n",
      "of malicious use, intellectual property issues, and scalability.\n",
      "LLM: Validation Framework \n",
      "11.Validation of LLMs is essential to ensure their safe and \n",
      "responsible use, and it is appropriate to take a broad \n",
      "perspective covering the various risks involved. A multi-\n",
      "dimensional validation framework should cover aspects such as model risk, data management, cybersecurity, legal\n",
      "and operational risks, ethics and reputation. \n",
      "12.LLM validation should be articulated through a combination\n",
      "of quantitative metrics and human judgment techniques. The choice of techniques will depend on the characteristics \n",
      "of the use case, such as level of risk, public exposure, \n",
      "personal data processing and line of business. 13.Emerging trends in LLM validation include explainability\n",
      "24, \n",
      "the using LLMs to explain other LLMs, attribution scoring, \n",
      "continuous validation, collaborative approaches, prompt \n",
      "engineering, ethical and regulatory alignment, and machine\n",
      "unlearning techniques. \n",
      "Case study  \n",
      "14.The case study presented illustrates the application of a \n",
      "custom validation framework to a company's internal policy\n",
      "chatbot. The process involved defining the case, designing the validation approach, running quantitative and \n",
      "qualitative tests, and interpreting results. \n",
      "15.The chatbot validation results showed satisfactory overall performance, with strengths in accuracy, consistency, adaptability and scalability. Areas for improvement were \n",
      "identified in the areas of explainability, bias mitigation and\n",
      "security. It was recommended to proceed with implementation, applying the suggested improvements \n",
      "and establishing a continuous monitoring and \n",
      "improvement plan. \n",
      "Conclusion  \n",
      "16.In conclusion, LLMs have significant potential to transform \n",
      "multiple sectors, but their development and deployment \n",
      "also pose significant challenges in transparency, fairness, \n",
      "privacy and security. To reap the benefits of LLMs in a responsible way, it is crucial to establish a robust AI \n",
      "governance framework that comprehensively addresses these challenges, including a rigorous, multi-dimensional \n",
      "approach to validation that covers the entire lifecycle of the \n",
      "models. This is the only way to ensure that LLMs are reliable,\n",
      "ethical and aligned with the values and goals of \n",
      "organizations and society at large.\n",
      "23Management Solutions (2022). Auto Machine Learning, towards model \n",
      "automation. \n",
      "24Management Solutions (2023). Explainable Artificial Intelligence (XAI): \n",
      "challenges in model interpretability.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1213\n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 13MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application14LLM: definition, context and regulation\n",
      "“I was told I would have a positive impact on the world. No one prepared me for the  \n",
      "amount of ridiculous questions I would be asked on a daily basis“.  \n",
      "Anthropic Claude25Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1415Definition  \n",
      "Generative Artificial Intelligence (GenAI) is a type of AI that can  \n",
      "generate various types of content, such as text, images, video,  \n",
      "and audio. It uses models to learn the patterns and structure of  \n",
      "input training data, generating new content based on this  \n",
      "learned knowledge.  \n",
      "Within GenAI, Large Language Models (LLM) are, according to  \n",
      "the European Commission, \"a type of artificial intelligence  \n",
      "model trained with deep learning algorithms to recognize,  \n",
      "generate, translate and/or summarize large amounts of written  \n",
      "human language and textual data26. \n",
      "Most commonly, these models use architectures known as  \n",
      "\"transformers\" that enable them to understand complex  \n",
      "contexts and capture relationships between distant words in  \n",
      "text. Trained on large datasets such as books, articles, and web  \n",
      "pages, LLMs learn linguistic patterns and structures to perform a  \n",
      "variety of tasks, including text generation, translation, and  \n",
      "sentiment analysis.  \n",
      "The effectiveness of an LLM depends on its size, the diversity of  \n",
      "its training data, and the sophistication of its algorithms, which  \n",
      "directly affects its ability to be used in practical applications in  \n",
      "various fields. Therefore, training an LLM requires very high  \n",
      "computational capacity and machine time, and therefore  \n",
      "involves very significant costs. For reference, according to Sam  \n",
      "Altman, training GPT-4 cost \"over $100 million\"27. \n",
      "These high costs mean that the development of the largest  \n",
      "LLMs is concentrated in a few organizations in the world (Figure  \n",
      "4) that have the technological, scientific, and investment  \n",
      "capabilities needed to undertake projects of this scale.  \n",
      " Evolution of LLMs  \n",
      "The development of LLMs represents a substantial evolution  \n",
      "within the field of Natural Language Processing (NLP), and dates  \n",
      "back to the foundational work on semantics28 by Michel Bréal in  \n",
      "1883. LLMs emerged in the mid-20th century, preceded by  \n",
      "systems that relied heavily on manually created grammar rules.  \n",
      "An emblematic case of this period is the \"ELIZA\" program,  \n",
      "created in 1966, which was an iconic breakthrough in the  \n",
      "development of language models.  \n",
      "As the field evolved, the 1980s and 1990s witnessed a pivotal  \n",
      "shift towards statistical methods of language processing. This  \n",
      "period saw the introduction of Hidden Markov Models (HMMs)  \n",
      "and n-gram models, which offered a more dynamic approach to  \n",
      "predicting word sequences based on probabilities rather than  \n",
      "fixed rule systems.  \n",
      "The resurgence of neural networks in the early 2000s, thanks to  \n",
      "advances in backpropagation algorithms that improved the  \n",
      "training of multi-layer networks, was a crucial development. A  \n",
      "milestone was the introduction of direct feedforward neural  \n",
      "networks for language modeling29 by Bengio et al. in 2003. This  \n",
      "laid the foundation for subsequent innovations in word  \n",
      "representation, notably the introduction of word embeddings30 \n",
      "by Mikolov et al. in 2013 with Word2Vec. Embeddings represent  \n",
      "words so that the distance between similar concepts is smaller.  \n",
      "This enables the capture of semantic relationships with  \n",
      "unprecedented efficiency.  \n",
      " \n",
      "25Claude (released in 2023) is a language model trained by Anthropic, an AI  \n",
      "startup founded by Dario Amodei, Daniela Amodei, Tom Brown, Chris Olah, Sam  \n",
      "McCandlish, Jack Clarke and Jared Kaplan in 2021. Claude was designed using  \n",
      "Anthropic's \"constitutionally aligned self-learning\" technique, which is based on  \n",
      "providing the model with a list of principles and rules to increase its safety and  \n",
      "avoid harmful behaviors.  \n",
      "26European Commission (2024).  \n",
      "27Wired (2023).  \n",
      "28Bréal (1883).  \n",
      "29Bengio (2003).  \n",
      "30Mikolov (2013).  \n",
      " Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 15MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application1631Parikh, A. P. (2016). \n",
      "32Vaswani (2017)\n",
      "33Euronews (2023).\n",
      "34Adapted from MindsDB (2024) and expanded. The first attentional mechanisms were introduced in 201631, \n",
      "enabling unprecedented results in language processing tasks by \n",
      "identifying the relevance of different parts of the input text. \n",
      "However, the introduction of the \"transformer\" architecture32 by \n",
      "Vaswani et al. in 2017 that represented the real paradigm shift in \n",
      "model training and enabled the emergence of LLMs. The core of \n",
      "the transformer innovation lies in the self-attention mechanisms that allow models to weigh the relative importance of different \n",
      "words in a sentence. This means the model can focus on the \n",
      "most relevant parts of the text when generating the response, which is critical for analyzing context and complex relationships \n",
      "within word sequences. In addition, transformers improve the \n",
      "efficiency, speed and performance of model training by enabling parallel data processing. \n",
      "The series of GPT models developed by OpenAI, starting with \n",
      "GPT-1 in June 2018 and reaching GPT-4 in March 2023, \n",
      "exemplifies the rapid advances in LLM capabilities. In particular, \n",
      "GPT-3, launched in 2020 with 175 billion parameters, reached the general public and demonstrated the vast potential of LLMs \n",
      "in various applications. In addition to OpenAI's GPT series, other \n",
      "LLM models such as Google Gemini and Anthropic Claude have emerged as major players in the AI landscape. Gemini is an \n",
      "example of how large technology companies are investing in \n",
      "the development of advanced LLMs, while Claude represents an effort to create LLMs that are not only powerful, but also ethical \n",
      "and safe to use. The year 2023, dubbed the \"year of AI\"\n",
      "33, stands out as a \n",
      "milestone in the history of LLMs, marked by increased accessibility and global contributions. Innovations during this \n",
      "year demonstrated that LLMs can be built with minimal code, significantly lowering the barriers to entry, while bringing new \n",
      "challenges such as the cost of training and inference and their \n",
      "inherent risks. This period also saw growing concern about the ethical considerations and challenges posed by the \n",
      "development and use of LLMs, and as a result, progress in the \n",
      "regulation of AI and generative AI around the world. \n",
      "The proliferation of open source LLMs has marked a milestone \n",
      "in democratizing of AI technology. Starting with Llama, and continuing with Vicuna, Falcon, Mistral, or Gemma, among \n",
      "others, open-source LLMs have democratized access to cutting-\n",
      "edge language processing technology, enabling researchers, developers, and hobbyists to experiment, customize, and \n",
      "deploy AI solutions with minimal upfront investment. The \n",
      "availability of these models has fostered unprecedented \n",
      "Figure 4. Some of the major LLMs and their suppliers34.\n",
      "Company LLM Comments Country\n",
      "OpenAI ChatGPT Known for versatility in language tasks, popular for text completion, \n",
      "translation, and more.United States\n",
      "Microsoft Orca Focuses on synthetic data creation and enhanced reasoning capabilities. United States\n",
      "Anthropic Claude Recognized for extensive general knowledge and multilingual \n",
      "capabilities.United States\n",
      "Google Gemini, Gemma, BERT Pioneer in language processing with models supporting multiple data \n",
      "types.United States\n",
      "Meta AI Llama Known for efficiency and democratized access, focusing on high \n",
      "performance with lower computing.United States\n",
      "LMSYS Vicuna Fine-tuned for chatbot functionalities, offering a unique approach to \n",
      "conversational interactions.United States\n",
      "Cohere Command-nightly Specializes in fast response times and semantic search in over 100 \n",
      "languages.Canada\n",
      "Mistral AI Mistral, Mixtral Emphasizes smaller but powerful models, operating locally with strong \n",
      "performance metrics.France\n",
      "Clibrain LINCE Tailored for the Spanish language, focusing on linguistic nuances and \n",
      "quality understanding.Spain\n",
      "Technology  \n",
      "Innovation InstituteFalcon Provides highly efficient and scalable open-source AI models with \n",
      "multilingual support.United Arab Emirates\n",
      "Aleph Alpha Luminous Notable for their multimodal approach and competitive performance on \n",
      "core AI tasks.Germany Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1617collaboration in the AI community, spurring innovation and  \n",
      "facilitating the creation of advanced applications across a wide  \n",
      "range of industries.  \n",
      "Finally, the integration of LLM with office and software  \n",
      "development tools is transforming the efficiency and  \n",
      "capabilities of organizations. Microsoft has integrated LLM into  \n",
      "its Office suite under Microsoft 365 Copilot, while Google has  \n",
      "done so in Google Workspace. At the same time, tools such as  \n",
      "GitHub Copilot and StarCoder use LLM to assist programmers,  \n",
      "speed up code generation and improving the quality of  \n",
      "software development.  \n",
      " \n",
      " LLM typologies  \n",
      "LLMs have evolved beyond simple text prediction to  \n",
      "sophisticated applications in different domains, architectures  \n",
      "and modalities. This section categorizes LLMs according to  \n",
      "various criteria.  \n",
      "By architecture  \n",
      "4 LLMs based on recurrent neural networks (RNNs): These  \n",
      "models process text sequentially, analyzing the effect of  \n",
      "each word on the next, and use recurrent architectures such  \n",
      "as long-term memory (LSTM) or recurrent gating units (GRU)  \n",
      "to process sequential data. Although not as powerful as  \n",
      "transformers for long sequences, RNNs are useful for tasks  \n",
      "where understanding word order is critical, such as machine  \n",
      "translation. Examples include ELMo (Embeddings from  \n",
      "Language Models) and ULMFiT (Universal Language Model  \n",
      "Fine-tuning).  4 Transformer-based LLMs: This is the dominant  \n",
      "architecture for LLMs today. They use transformers to  \n",
      "analyze the relationships between words in a sentence. This  \n",
      "allows them to capture complex grammatical structures and  \n",
      "long-range word dependencies. Most LLMs, such as GPT,  \n",
      "Claude and Gemini, belong to this category.  \n",
      "By components  \n",
      "4 Encoders: These  are models designed to understand  \n",
      "(encode) the input information. They transform text into a  \n",
      "vector representation, capturing its semantic meaning.  \n",
      "Encoders are fundamental in tasks such as text  \n",
      "understanding and classification. An example is Google's  \n",
      "BERT, a model that analyzes the context of each word in a  \n",
      "text to understand its full meaning, and is not really an LLM.  \n",
      "4 Decoders: These models generate (decode) text from vector  \n",
      "representations. They are essential in text generation, as in  \n",
      "the creation of new content from given prompts. Most LLMs  \n",
      "are decoders.  \n",
      "4 Encoders/Decoders: These  models combine encoders and  \n",
      "decoders to convert one type of information into another,  \n",
      "facilitating tasks such as machine translation, where input  \n",
      "text is encoded and then decoded into another language.  \n",
      "An example is Google's T5 (Text-to-Text Transfer  \n",
      "Transformer), designed to address multiple natural  \n",
      "language processing tasks.  \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 17MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application18By training approach \n",
      "4 Pre-trained LLMs:  These models are first trained on a large \n",
      "corpus of unlabeled text using self-supervised learning \n",
      "techniques such as masked language modeling or next-\n",
      "sentence prediction, and can then be tuned for specific tasks on smaller labeled datasets. Examples include models \n",
      "such as GPT, Mistral, BERT and RoBERTa, among many others. \n",
      "4 Specific LLMs: These models are trained from scratch with \n",
      "labeled data for a specific task, such as sentiment analysis, \n",
      "text summarization or machine translation. Examples \n",
      "include translation and summarization models. \n",
      "By modality  \n",
      "4 Text-only LLM: These are the most common type, trained \n",
      "and working exclusively with textual data. Examples are \n",
      "GPT-3, Mistral or Gemma. \n",
      "4 Multimodal LLMs:  An emerging field where LLMs are \n",
      "trained on a combination of text and other data formats \n",
      "such as images or audio. This allows them to perform tasks \n",
      "that require understanding the relationship between different modalities. Examples include GPT-4, Claude 3 and \n",
      "Gemini. By size  \n",
      "4 Large Language Models (LLMs): These are models that use \n",
      "massive amounts of parameters. They are very powerful, \n",
      "but require a relatively expensive technological \n",
      "infrastructure in the cloud to run. Examples include GPT-4, \n",
      "Gemini or Claude 3. \n",
      "4 Small Language Models (SLMs ): A recent trend, SLMs are \n",
      "smaller and more efficient versions of LLMs, designed to run \n",
      "on resource-constrained devices, such as smartphones or \n",
      "IoT devices, without the need to connect to or deploy in the \n",
      "cloud. Despite their reduced size, these models maintain acceptable performance through techniques such as model \n",
      "compression or quantization, which reduces the accuracy of \n",
      "model weights and activations. Examples include Google's Gemini Nano and Microsoft's Phi family of models. \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 18LLM in practice: production use cases  \n",
      "19Despite the growing interest and exploration of potential LLM uses  \n",
      "in enterprises, the actual use cases implemented in production are  \n",
      "still limited. Most companies are still in the relatively early stages  \n",
      "of identifying and prioritizing potential use cases.  \n",
      "However, several companies have already succeeded in putting  \n",
      "some LLM cases into production and demonstrating their tangible  \n",
      "value to the business and its customers. Some of these cases are  \n",
      "summarized below:  \n",
      "4Internal chatbots: S ome organizations have implemented  \n",
      "LLM-based chatbots to facilitate employee access to policies,  \n",
      "procedures, and relevant company information. These  \n",
      "conversational assistants provide quick and accurate answers  \n",
      "to common questions, improving efficiency and reducing the  \n",
      "burden on other internal support channels.  \n",
      "4Information extraction: LLMs are used to automatically  \n",
      "extract key data from large and complex documents, such as  \n",
      "annual reports or climate risk reports. These tools are capable  \n",
      "of handling thousands of pages of PDF files with  \n",
      "heterogeneous structures, including images, graphs, and  \n",
      "tables, and transforming the relevant information into  \n",
      "structured and accessible formats, such as ordered tables. This  \n",
      "automation allows organizations to save time and resources on  \n",
      "document analysis tasks.  \n",
      "4Customer service center support: Some contact centers use  \n",
      "LLMs to improve service quality and efficiency. By applying  \n",
      "transcription and summarization techniques, these tools create  \n",
      "a context for each customer's past interactions, enabling agents  \n",
      "to provide more personalized service. In addition, during  \n",
      "ongoing calls, LLMs can provide agents with real-time access  \n",
      "to relevant documentation to answer specific customer  \n",
      "questions, such as information about bank fees or instructions  \n",
      "on how to cancel credit cards.  \n",
      "4Intelligent document classification: LLMs use natural  \n",
      "language processing capabilities to automatically classify large  \n",
      "volumes of documents, such as contracts or invoices, based on  \n",
      "their content. This intelligent categorization enables  organizations to streamline document management processes  \n",
      "and make it easier to search and retrieve relevant information.  \n",
      "4Conversational banking: Some banks are integrating LLMs  \n",
      "into their mobile apps and digital channels to deliver advanced  \n",
      "conversational experiences to their customers. These chatbots  \n",
      "are able to access users' transaction data in real time and  \n",
      "respond to specific questions, such as \"What were my expenses  \n",
      "last month?\" or \"How much interest did I earn on my deposits  \n",
      "last year?\".  \n",
      "4Help with audit reports: Internal audit departments in some  \n",
      "companies are already using LLM to streamline the  \n",
      "preparation of their reports. These tools take as input the  \n",
      "auditor's findings, a database of previous reports and a  \n",
      "database of applicable internal and external regulations. From  \n",
      "this information, LLMs generate an advanced draft of the audit  \n",
      "report, adopting the tone, vocabulary and style of human  \n",
      "auditors, and properly citing previous reports and relevant  \n",
      "regulations. This allows auditors to save significant time on  \n",
      "drafting tasks and focus on more value-added activities.  \n",
      "These examples illustrate how LLMs are delivering real value in a  \n",
      "variety of business functions, from streamlining internal processes  \n",
      "to improving the customer experience. While the number of  \n",
      "production use cases is limited today, this trend is expected to  \n",
      "accelerate rapidly in the near future as LLMs continue to evolve  \n",
      "and privacy and security challenges are effectively addressed.  \n",
      " \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 19MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application20Main uses \n",
      "LLMs are being used in various domains, transforming how  \n",
      "people interact with technology and using natural language \n",
      "processing to improve processes, services, and experiences. \n",
      "The following summarizes some of the more prominent uses of \n",
      "text LLMs. \n",
      "1. Content creation and enhancement\n",
      "4Content generation: automated text production.\n",
      "4Writing assistance: Spelling, style and content  \n",
      "proofreading. \n",
      "4Automatic translation: Converting text from one language  \n",
      "to another. \n",
      "4Text summarization: Reducing long documents to  \n",
      "summaries. \n",
      "4Content planning and scripting: Structuring content such  \n",
      "as indexes. \n",
      "4Brainstorming: Creative suggestions for projects, names,  \n",
      "concepts, etc. \n",
      "4Programming: Creation of programming code from  \n",
      "natural language. \n",
      "2. Information analysis and organization  \n",
      "4Sentiment analysis: Evaluation of emotions and opinions\n",
      "in texts. \n",
      "4Information extraction: Extracting specific data from large  \n",
      "documents. \n",
      "4Text classification: Organizing text into specific categories  \n",
      "or topics. \n",
      "4Technical review: Assisting in the review of specialized  \n",
      "documents (e.g., legal). 3. Interaction and automation  \n",
      "4Chatbots: Simulation of conversations on general or\n",
      "specific topics. \n",
      "4Q&A: Generation of answers to questions based on a  \n",
      "corpus. \n",
      "The above summarizes the current uses of text LLMs. With the \n",
      "emergence of multimodal LLMs, additional uses are beginning \n",
      "to emerge, such as generating audiovisual content, interpreting \n",
      "data from images, translating multimedia content, or creating rich interactive experiences, such as interacting with chatbots \n",
      "with not only text, but also image, audio, and video input. \n",
      "Regulatory requirements  \n",
      "The rapid development of generative artificial intelligence,  \n",
      "particularly in the area of large-scale language modeling (LLM), \n",
      "has attracted the attention of regulators worldwide. The \n",
      "potential for these systems to negatively impact citizens has led to an increase in initiatives to establish regulatory frameworks \n",
      "to ensure their development and responsible use. \n",
      "Some of the key regulatory initiatives related to AI include: \n",
      "4 The European Union's AI Act: A groundbreaking \n",
      "legislative proposal to regulate AI that classifies AI systems \n",
      "according to their level of risk and sets requirements for \n",
      "transparency, security, and fundamental rights. The European Parliament adopted the AI Act on March 13, 2024. \n",
      "4 The U.S. AI Bill of Rights: A guiding document that seeks \n",
      "to protect civil rights in the development and application of \n",
      "AI, emphasizing privacy, non-discrimination and transparency. \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 2021 \n",
      "  \n",
      "35The National Institute of Standards and Technology (NIST) has published  \n",
      "documents detailing frameworks for cybersecurity, risk management, and  \n",
      "specifically, AI model management and generative AI.   \n",
      "36IAPP (2024).4 U.S. NIST AI guidelines35: Establish principles for building  \n",
      "reliable AI systems, with a focus on accuracy, explainability,  \n",
      "and bias mitigation.  \n",
      "4 The Bletchley Declaration: An international commitment  \n",
      "to the responsible development of AI, promoting principles  \n",
      "of transparency, security, and equity, signed by multiple  \n",
      "countries.  \n",
      "In addition to the above initiatives, many countries have begun  \n",
      "to adopt their own local regulations or principles for the safe  \n",
      "and ethical use of AI. These include36 the United Kingdom,  \n",
      "France, Spain, Germany, the Netherlands, Poland, Australia, New  \n",
      "Zealand, Singapore, Canada, Japan, South Korea, China, India,  \n",
      "Indonesia, Israel, the United Arab Emirates, Saudi Arabia, Egypt,  \n",
      "Brazil, Chile, Peru, Argentina, Mexico, Colombia, and Turkey.  \n",
      "All of these regulatory initiatives impose very similar  \n",
      "requirements on AI, which, as applied to LLMs, can be  \n",
      "summarized as follows:  \n",
      "4 Transparency and explainability: The obligation to  \n",
      "disclose how the LLM works, including the logic behind its  \n",
      "outputs so that they are understandable to users.  \n",
      "4 Privacy and data protection:  Strict measures to protect  \n",
      "personal data collected or generated by the LLM, in  \n",
      "compliance with data protection laws, such as the GDPR in  \n",
      "Europe.  \n",
      "4 Fairness and non-discrimination: Requirements to  \n",
      "prevent bias and ensure that LLMs do not perpetuate  \n",
      "discrimination and prejudice by constantly evaluating and  \n",
      "correcting their algorithms.  4 Security and reliability: Operational robustness  \n",
      "requirements to prevent malfunction or manipulation that  \n",
      "could cause damage or loss of information.  \n",
      "4 Liability and governance: Liability framework for LLM  \n",
      "developers and users in case of damages or rights violations,  \n",
      "including oversight and control mechanisms.  \n",
      "4 Human oversight: The need to maintain effective human  \n",
      "oversight over LLMs, ensuring that important decisions can  \n",
      "be reviewed and, if necessary, corrected or reversed by  \n",
      "humans.  \n",
      "These requirements reflect an emerging consensus on the  \n",
      "fundamental principles for the ethical and safe development of  \n",
      "LLMs, and form the basis for future specific regulations and  \n",
      "adaptations as the technology evolves.  \n",
      " \n",
      " \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 21MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application22LLM: development and deployment\n",
      "“Generative AI is the key to solving some of the world's biggest problems, such as  \n",
      "climate change, poverty and disease. It has the potential to make the world a better  \n",
      "place for everyone“.  \n",
      "Mark Zuckerberg37\n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 2223This section discusses the key aspects of the LLM development  \n",
      "and deployment process. It examines key components such as  \n",
      "data and model architecture, as well as the pre-training, fine-\n",
      "tuning, and implementation phases. It also discusses the key  \n",
      "challenges and considerations that must be considered to  \n",
      "ensure ethical, robust development aligned with an  \n",
      "organization's goals.  \n",
      "Key aspects of LLM development  \n",
      "LLM development is a complex process involving many  \n",
      "components and critical decisions. The following is a  \n",
      "description of the main components that need to be known  \n",
      "about LLM development, and some key aspects about them.  \n",
      "Data  \n",
      "Data are the foundation upon which LLMs are built, and their  \n",
      "quality, diversity, and representativeness directly impact the  \n",
      "performance and bias of the resulting model. Addressing  \n",
      "challenges related to intellectual property, data quality, and  \n",
      "preprocessing is essential to developing robust, unbiased, and  \n",
      "accurate LLMs. As regulations and best practices in this area  \n",
      "evolve, we will llikely see an increased emphasis on responsible  \n",
      "and transparent use of data in LLM training.  \n",
      "Some key aspects about LLM training data are:  \n",
      "4Training corpus38: LLMs are trained on large corpora of data,  \n",
      "often extracted from the internet, containing billions of  \n",
      "words and spanning a wide range of domains and genres,  \n",
      "such as books, news articles, web pages, social networks  \n",
      "and more. These massive corpora enable LLMs to learn  \n",
      "patterns and representations of language on a large scale,  \n",
      "giving them an unprecedented ability to understand and  \n",
      "generate coherent, contextualized text. For example,  \n",
      "common corpora for training include BookCorpus39, \n",
      "Gutenberg40, Wikipedia41 or CodeParrot42.  \n",
      "4Intellectual property and copyright43: Extracting and using  \n",
      "Internet data for LLM training raises challenges related to  \n",
      "intellectual property and copyright. Much of this data is  protected by copyright, and its use without permission or  \n",
      "adequate compensation can be problematic. The AI Act in  \n",
      "Europe addresses this issue by imposing new requirements  \n",
      "on LLM developers, such as the obligation to disclose the  \n",
      "data sources used and to obtain the necessary licenses.  \n",
      "4Data quality and representativeness44: Like any model, an  \n",
      "LLM is only as good as the data used to train it. If the data is  \n",
      "of poor quality, biased or unrepresentative, the model may  \n",
      "inherit these problems and produce inaccurate, unfair or  \n",
      "inappropriate results. Therefore, it is critical to ensure that  \n",
      "training corpora are diverse, balanced, and adequately  \n",
      "represent different demographics45, opinions, and  \n",
      "perspectives.   \n",
      "4High quality data initiatives46: Some recent initiatives focus  \n",
      "on building LLMs with fewer parameters, but higher quality  \n",
      "data, such as smaller, but carefully selected and filtered47 \n",
      "training corpora  that include high quality content like  \n",
      "books, scientific articles, and respected publications. These  \n",
      "filters can be limited, for example, to a single language, or to  \n",
      "an industry or subject area, drastically reducing the size of  \n",
      "the corpus. This strategy can result in LLMs with better  \n",
      "performance and less bias than models trained on massive  \n",
      "unfiltered data.  \n",
      " \n",
      "37Mark Zuckerberg (n. 1984), co-founder and CEO of Facebook and Meta, one of  \n",
      "the world's largest social networking, technology and artificial intelligence  \n",
      "companies.  \n",
      "38Liu (2024).  \n",
      "39Soskek (2019).  \n",
      "40Project Gutenberg (2024).  \n",
      "41Wikipedia Dumps (2024).  \n",
      "42Hugging Face Datasets (2024).  \n",
      "43Li (2024), Chu (2023).  \n",
      "44Alabdulmohsin (2024).  \n",
      "45Yogarajan (2023).  \n",
      "46Sachdeva (2024).  \n",
      "47Tirumala (2023).  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 23MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application244Data preprocessing and labeling48: Before training or fine-\n",
      "tuning an LLM, the data must be preprocessed and, in some \n",
      "cases such as supervised fine-tuning or using a specific \n",
      "dataset, labeled. Preprocessing involves cleaning and \n",
      "formatting the data49, removing noise and errors, and \n",
      "applying techniques such as tokenization and normalization \n",
      "(e.g., LayerNorm50 for Transformers). \n",
      "Tokenization and encoding  \n",
      "Tokenization refers to the process of breaking down text into  \n",
      "smaller units called \"tokens\", which are the units processed by \n",
      "the LLM during training and response inference. These tokens \n",
      "can be words, parts of words (e.g. lemmas), or characters. For example, one of the simplest ways to generate tokens is to \n",
      "partition the corpus according to the spaces between words. \n",
      "Encoding is the process of representing these text units in numerical form so that the model can process them.   \n",
      "Some key points about tokenization in LLM: \n",
      "4It is performed on the available text corpus to optimally  \n",
      "divide the original text into smaller units. The end result of \n",
      "tokenization is an encoding. \n",
      "4Encodings have a significant impact on the performance of  \n",
      "the LLM51, as they define the minimum processing unit it \n",
      "will receive and determine the vocabulary the LLM has \n",
      "access to. 4There are several encoding algorithms on the market52 that \n",
      "differ in the way they divide the text based on words, \n",
      "phrases or sentences, use of spaces, capitalization or \n",
      "formatting, appearance of characters in different languages, or errors present in the text.   \n",
      "4The main encodings53 used are BytePairEncoding, \n",
      "SentencePieceEncoding and WordPieceEncoding. \n",
      "The tokenization result is used as a starting point in the \n",
      "embedding model.  \n",
      "Embedding  \n",
      "Embeddings are numerical representations of words, phrases,  \n",
      "sentences, or even paragraphs that capture their semantic \n",
      "meaning and the relationships between them. They are based \n",
      "on the LLM input corpus, which is divided into tokens. They are a fundamental component of LLMs and play a crucial role both \n",
      "in the pre-training, fine-tuning, and subsequent use of these \n",
      "models. Figure  5. Stages of LLM input data processing.\n",
      "48Chen (2023). \n",
      "49Wenzek (2019), Penedo (2023). \n",
      "50Zhao (2023). \n",
      "51Rejeleene (2024). \n",
      "52Minaee (2024). \n",
      "53Kudo (2018). Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 24Types of embeddings\n",
      "25Embeddings in LLMs:  \n",
      "4They are designed to capture semantic relationships  \n",
      "between words, so that words with similar meanings have  \n",
      "similar vectors. This allows the model to understand the  \n",
      "similarity and analogies between words and concepts.  \n",
      "4They are not universal values, but will vary from one model  \n",
      "to another, depending on the vector space in which they  \n",
      "have been defined.  \n",
      "4They are contextual, meaning that the representation of a  \n",
      "word can vary depending on the context in which it  \n",
      "appears. This allows nuances of meaning to be captured  \n",
      "and polysemous words to be disambiguated. The  \n",
      "embeddings are not predefined but are learned from  \n",
      "training data based on the LLM embedding model. During  \n",
      "pre-training, the model adjusts the embeddings to  \n",
      "maximize their ability to predict words in context (e.g.  \n",
      "through embedding frameworks such as  \n",
      "SentenceTransformers). However, the embeddings alone  \n",
      "are already a model that needs to be tuned during the  \n",
      "process.  \n",
      "Pre-training  \n",
      "Pretraining is a fundamental stage in LLM development, during  \n",
      "which models acquire general and deep language knowledge  \n",
      "from large amounts of unlabeled data. Although this process is  \n",
      "computationally intensive and costly, it enables model  \n",
      "adaptation to a wide range of tasks.  \n",
      "The main goal of pre-training is for the model to acquire a broad  \n",
      "and deep knowledge of the language, including its structure,  \n",
      "semantics, syntax, and context. During this process, the LLM  \n",
      "learns to predict words or text fragments (i.e., tokens) based on  \n",
      "the surrounding context, allowing it to capture complex  \n",
      "linguistic relationships and patterns. This general knowledge  \n",
      "becomes the basis for fine-tuning the model for specific tasks.  \n",
      "There are several popular techniques for LLM pre-training, such  \n",
      "as: \n",
      "4Autoregressive language modeling or unidirectional  \n",
      "modeling (e.g., autoregressive modeling54), which consists  \n",
      "of training the model to predict the next word or text  \n",
      "fragment given the previous context. This task allows the  \n",
      "model to learn the conditional probabilities of the language  \n",
      "and generate coherent text. Examples include the GPT and  \n",
      "Claude models.  Embeddings are used in LLMs in order to establish a metric  \n",
      "that defines the similarity between word meanings and to  \n",
      "incorporate information about the position of words in a  \n",
      "sentence. This is crucial, since word order affects meaning.  \n",
      "There are three main types of positional embeddings:  \n",
      "4Absolute positional embedding1: Assigns to each word - or  \n",
      "to each minimal text unit or token - a vector representing  \n",
      "its exact position in the sentence (e.g., first, second, third  \n",
      "position, etc.).  \n",
      "4Relative positional embedding2: Instead of being based on  \n",
      "absolute positions, it represents the position of a word  \n",
      "relative to the others (e.g. two words before, one word  \n",
      "after, etc.).  \n",
      "4Rotary positional embedding3: Combines absolute and  \n",
      "relative positional information, using trigonometric  \n",
      "functions to create more complex vector representations.  \n",
      "In a transformer, a simple positional embedding for a word at a  \n",
      "given position can be represented mathematically using sine  \n",
      "and cosine functions. Specifically, a positional embedding E   \n",
      "for a token i with position P can be represented mathematically  \n",
      "in its simplest form as:\n",
      " \n",
      "1Vaswani (2017).  \n",
      "2Shaw (2018).  \n",
      "3Su (2021).   \n",
      "54Devlin (2018), Liu (2022).  where P is the position of the token in the input sequence, and  \n",
      "d is the dimension of the hidden layers of the transformer.  \n",
      "The choice of positional embedding type can affect LLM  \n",
      "performance by determining the amount and type of positional  \n",
      "information available to the model during training.  \n",
      " \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 25MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application264The non-autoregressive model55, used in models such as \n",
      "Gemini, in which the response is not obtained sequentially \n",
      "word by word, but is transformed and refined as a whole. \n",
      "4Masked language modeling56, popularized by models such \n",
      "as BERT, which consists of randomly masking some words in \n",
      "the input text and training the model to predict these \n",
      "masked words based on the surrounding context. This technique allows bidirectional learning and a better \n",
      "understanding of the context. Some LLM architectures (e.g., \n",
      "bidirectional transformers) use this technique. \n",
      "4Sequence-to-sequence modeling57 (e.g., seq2seq58), where \n",
      "the model is trained to generate text sequences based on \n",
      "other input sequences. This is used in models such as T5, \n",
      "BART or ProphetNET. \n",
      "4Contrastive pre-training59, used in models such as CLIP and  \n",
      "ALIGN60, involves training the model to identify text-image \n",
      "pairs that are semantically related , allowing it to learn \n",
      "multimodal representations and transfer knowledge \n",
      "between different modalities61. \n",
      "LLM pre-training is a computationally intensive process that requires enormous amounts of data, time and hardware resources. The largest models can have on the order of 1 trillion \n",
      "(10\n",
      "12) parameters and require thousands of high-end GPUs for \n",
      "weeks or months of training. This makes pre-training extremely expensive and affordable for only a few companies and \n",
      "organizations in the world with the necessary resources. Quantification  \n",
      "During LLM training, neuron weights are adjusted to make  \n",
      "more accurate predictions. These weights are typically stored as \n",
      "high-precision numbers, which can result in large and \n",
      "computationally expensive models. \n",
      "Post-training quantization is a technique62 that allows the \n",
      "accuracy of model parameters to be reduced without \n",
      "significantly affecting model performance. For example, neural \n",
      "networks that store their parameters in 32-bit floating-point numbers can be switched to using only 16-bit or 8-bit numbers, \n",
      "depending on the type of quantization. This results in smaller \n",
      "and faster models because they require less memory and, with the right hardware, can perform operations more efficiently. \n",
      "Recently, there has been a trend to develop small language \n",
      "models (SLMs), or even \"tiny LLMs\"\n",
      "63, models that maintain high \n",
      "performance despite their much smaller size. These compact \n",
      "models are achieved by combining techniques, including post-\n",
      "training quantization. \n",
      "By skillfully applying these techniques, SLMs and tiny LLMs can \n",
      "in some cases achieve performance comparable to that of much larger models\n",
      "64, making them attractive for applications \n",
      "where computational or memory resources are limited. \n",
      "55Xu (2021). \n",
      "56Devlin (2019), Sinha (2021).  \n",
      "57Lee (2022). \n",
      "58Sutskever (2014). \n",
      "59Zeng (2023).  \n",
      "60Jia (2021). \n",
      "61Cui (2022). \n",
      "62Li (2024). \n",
      "63Tian (2024).  \n",
      "64Fu (2024). \n",
      "Figure 6. LLM fine-tuning.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 26LLMs, like other deep learning models, learn by adjusting their  \n",
      "parameters to minimize a loss function. This function measures  \n",
      "the difference between the model's predictions and the  \n",
      "expected outcomes, and guides the model toward better  \n",
      "performance.  \n",
      "The choice of loss function depends on the type of task for  \n",
      "which the LLM is being trained. For example, for a model that  \n",
      "predicts the next word in a sentence (autoregressive language  \n",
      "modeling), a common function is cross-entropy. This function  \n",
      "compares the probability distribution of the words predicted  \n",
      "by the model with the actual distribution observed in the  \n",
      "training data.  \n",
      "Mathematically, the cross-entropy loss function for an  \n",
      "autoregressive model can be expressed as the sum of the  \n",
      "negative logarithms of the probabilities assigned to the correct  \n",
      "words at each position in the sequence.  \n",
      "Specifically, given a loss function such as cross-entropy and a  \n",
      "training typology such as autoregressive language modeling,  \n",
      "the loss function to be minimized can be defined as:  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "where φ represents the model parameters, i refers to the  \n",
      "number of tokens in a given sequence of N tokens, P is the  \n",
      "probability of predicting the token i as a function of the  \n",
      "sequence x of previous tokens.  \n",
      "When fine-tuning the model embeddings, specialized loss  \n",
      "functions can be used to fine-tune the vector representations of  \n",
      "the words. Some popular options are:  \n",
      "4Cosine similarity loss: adjusts embeddings so that similar  \n",
      "words have more similar vectors.  \n",
      "4Mean square error loss: minimizes the quadratic difference  \n",
      "between predicted and expected embeddings.  \n",
      "4Multiple Negative Ranking Loss: associate embeddings of  \n",
      "related words so that they are closer together than those of  \n",
      "unrelated words.  \n",
      "4Triplet, Matryoshka or contrastive loss: more advanced  \n",
      "variants that consider relationships between trios or  \n",
      "groups of embeddings.  \n",
      "Careful selection of the loss function is crucial for training  \n",
      "effective and efficient LLMs that can capture the nuances of  \n",
      "natural language.27Training LLM: loss functions  Fine-tuning, instruction-tuning and RAG  \n",
      "Fine-tuning is the process of adapting a pre-trained LLM to a  \n",
      "specific task using a smaller data set. This technique makes it  \n",
      "possible to take advantage of the general knowledge acquired  \n",
      "during pre-training and specialize it to achieve high  \n",
      "performance on the target task.  \n",
      "The main goal of fine-tuning (Figure 6) is to adapt a pre-trained  \n",
      "LLM to a specific task, such as sentiment classification, question  \n",
      "answering, machine translation, or summary generation. During  \n",
      "this process, the model learns to use its general knowledge of  \n",
      "the language and apply it effectively to the specific domain and  \n",
      "requirements of the task at hand. Commercially available LLMs,  \n",
      "whether proprietary or open source, are typically pre-trained  \n",
      "(and therefore general-purpose), but have not been fine-tuned  \n",
      "to adapt to a specific purpose.  \n",
      "Fine-tuning has several important advantages:  \n",
      "4 Leverages prior knowledge:  By starting from a pre-trained  \n",
      "model, fine-tuning allows the vast general knowledge of the  \n",
      "language acquired during pre-training to be leveraged,  \n",
      "accelerating learning and improving performance on the  \n",
      "specific task.  \n",
      "4 Requires less data and resources: Compared to training  \n",
      "from scratch, fine-tuning requires much less labeled data  \n",
      "and computational resources, making it more accessible  \n",
      "and cost-effective for a wide range of organizations and  \n",
      "applications.  \n",
      "4 Enables specialization: Fine-tuning allows LLMs to be  \n",
      "tailored to specific domains and tasks, resulting in highly  \n",
      "specialized and effective models for specific applications.  \n",
      "4 Facilitates learning transfer: Fine-tuned models can  \n",
      "receive additional fine-tuning for related tasks, enabling  \n",
      "learning transfer and the creation of even more specialized  \n",
      "models with relatively little additional data.  \n",
      "Despite its benefits, fine-tuning also presents some challenges:  \n",
      "4 Overspecialization65: If the model is fine-tuned on a data  \n",
      "set that is too specific, it may lose some of its generalization  \n",
      "ability and perform poorly on unknown or slightly different  \n",
      "data.  \n",
      " \n",
      "65Wang (2024).  \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 27MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application284 Catastrophic forgetting66: During fine-tuning it is possible \n",
      "for a model to forget previously learned critical knowledge. \n",
      "4 Instability67: The fine-tuning process can be sensitive to \n",
      "factors such as weight initialization, hyperparameters and \n",
      "data selection, which can lead to inconsistent results or \n",
      "variations in performance. \n",
      "4 Bias inheritance68: Models that have been fine-tuned may \n",
      "inherit and amplify biases present in both pre-training and \n",
      "fine-tuning data, which requires careful consideration and \n",
      "mitigation. \n",
      "There are several types of fine-tuning to choose from, depending on how much the initial model needs to be modified to fit a task in a more specific domain. The main methods are: \n",
      "4 Supervised fine-tuning69: This method require labeled \n",
      "input and response data sets from the LLM that are used to \n",
      "improve its response to specific tasks. A popular method of \n",
      "supervised fine-tuning is called “instruction-tuning”70, which \n",
      "consists of tuning the model's responses to what is \n",
      "expected by its users through interactions with the model.   \n",
      "4 Reinforcement learning: These methods are based on \n",
      "reinforcement learning and focus on improving the quality \n",
      "of the LLM response, in this case based on user feedback or \n",
      "reward models (e.g., direct optimization by preference71). \n",
      "4 Unsupervised fine-tuning72: This is a method that does not \n",
      "require labeled data sets, but relies on retraining the model \n",
      "with the same methods used during pre-training (e.g., \n",
      "predicting the next token).  4 Parameter efficient73: Fine-tuning (PEFT): Other fine-tuning \n",
      "methods aim to increase efficiency and reduce the effort \n",
      "required to retrain the model. For example, techniques \n",
      "based on LoRA74 (low-rank adaptation), such as QLoRA or \n",
      "LongLoRA75, allow fine-tuning of the model without \n",
      "changing its weights and store the knowledge learned \n",
      "during the fine-tuning process in additional model \n",
      "parameters. \n",
      "In many LLM use cases, it is not necessary to use fine-tuning to improve the model´s capabilities in a specific domain. Augmented Retrieval Generation\n",
      "76(RAG) is a technique that \n",
      "improves LLM performance by using knowledge sources \n",
      "external to the model.  \n",
      "RAG techniques (Figure 7) work by searching a database for \n",
      "documents similar to or related to the input prompt. This search \n",
      "and its results are added to the LLM response generation to enrich it by providing a specific context.   \n",
      "Figure 7. Operation of the RAG.\n",
      "66Luo (2024).  \n",
      "67Zhang (2024). \n",
      "68Zhang (2024).  \n",
      "69Ovadia (2024). \n",
      "70Zhang (2023). \n",
      "71Rafailov (2023). \n",
      "72Zhou (2023). \n",
      "73Xu (2023). \n",
      "74Dettmers (2023). \n",
      "75Chen (2023). \n",
      "76Lewis (2020) and Neelakantan (2022). Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 2829\n",
      " \n",
      "77Wan (2024).  \n",
      "78Abhyankar (2024).  \n",
      "79Goyal (2024).  \n",
      "80Lester (2021).  \n",
      "81Banerjee (2023).  Deployment and use  \n",
      "Once trained and validated, the LLM needs to be deployed in a  \n",
      "production environment for use in real applications. This  \n",
      "involves integrating the model into existing systems and  \n",
      "workflows, and creating interfaces and APIs to interact with it.  \n",
      "There are several key aspects to this process, including  \n",
      "integration and monitoring.  \n",
      "Integration with systems and workflows  \n",
      "4 Infrastructure77: LLMs are typically large and  \n",
      "computationally intensive models that require a robust  \n",
      "infrastructure for their implementation. This may include  \n",
      "the use of specialized hardware, such as GPUs or TPUs, and  \n",
      "cloud computing platforms optimized to perform the  \n",
      "inference process efficiently.  \n",
      "4 Interfaces and APIs78: To facilitate the use of the LLM in  \n",
      "applications and services, it is necessary to develop  \n",
      "interfaces and APIs that allow other systems to interact with  \n",
      "the model in an efficient and secure manner. This may  \n",
      "include endpoints, client libraries in various programming  \n",
      "languages and graphical user interfaces for non-technical  \n",
      "users.  \n",
      "4 Integration with other components:  In many cases, LLMs  \n",
      "are part of a larger system that includes other components  \n",
      "such as databases, natural language processing services  \n",
      "and end-user applications. Seamless and efficient  \n",
      "integration of the LLM with these components is critical to  \n",
      "ensure optimal performance and user experience.  Monitoring and maintenance  \n",
      "4 Performance monitoring79: Once implemented, it is  \n",
      "essential to closely monitor LLM performance under real-\n",
      "world conditions. This involves tracking metrics such as  \n",
      "latency, throughput, accuracy and resource usage, as well as  \n",
      "setting thresholds for resource consumption and cost, and  \n",
      "alerts to detect and address any degradation or anomalies.  \n",
      "4 Updating and retraining80: As new data becomes available  \n",
      "or areas for improvement are identified, it may be necessary  \n",
      "to update or retrain the LLM. This requires a well-defined  \n",
      "process to collect and prepare new data, perform fine-\n",
      "tuning, and deploy the updated version of the model  \n",
      "without service interruptions.  \n",
      "4 Version management81: With continuous upgrades and  \n",
      "enhancements, it is important to maintain strict version  \n",
      "control of the LLM and its associated components. This  \n",
      "facilitates reproducibility, debugging and the ability to  \n",
      "revert to previous versions if necessary.  \n",
      "As can be seen, LLM development and deployment is a complex  \n",
      "and multifaceted process that requires careful consideration of  \n",
      "multiple aspects, from data selection and preparation to  \n",
      "implementation and responsible use of the model. A thorough  \n",
      "understanding of the key components, such as pre-training,  \n",
      "fine-tuning and embedding, as well as an awareness of the  \n",
      "associated challenges and risks, is essential to harnessing the  \n",
      "full potential of LLMs in an ethical, sustainable and cost-effective  \n",
      "manner that is aligned with each organization's objectives.  \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 29MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application30LLM architecture \n",
      "LLM architecture refers to the structure and organization of the  \n",
      "neural networks that make up these models. The choice of \n",
      "architecture and its components significantly impacts the LLM's \n",
      "performance, efficiency and capabilities. This section examines the major architectures used in LLMs and their characteristics, \n",
      "advantages, and limitations. \n",
      "Transformers: the state of the art in LLMs  \n",
      "Introduced in 2017, transformers have become the dominant  \n",
      "architecture for LLMs82. Unlike previous architectures based on \n",
      "recurrent neural networks (RNNs) or convolutional neural \n",
      "networks (CNNs), transformers rely solely on attentional \n",
      "mechanisms to process and generate text sequences (Figure 8). \n",
      "The transformer architecture consists of two main components: \n",
      "the encoder and the decoder, and there are transformers with \n",
      "encoder only, decoder only, or both components. The encoder \n",
      "processes the input sequence and generates a contextual representation for each token, while the decoder generates the \n",
      "output sequence from the encoder representation and previous \n",
      "predictions. \n",
      "The key to transformers is the attention mechanism, which \n",
      "allows the model to pay attention to different parts of the input \n",
      "sequence (encoder attention) and to previous predictions (decoder attention) to generate the next word or token. This \n",
      "allows long-term dependencies to be captured and coherent \n",
      "sequences to be generated. Transformers also introduce the concept of multi-head \n",
      "attention, where multiple attention mechanisms operate in \n",
      "parallel, allowing the model to capture different types of relationships and patterns in the data. \n",
      "The Transformer architecture has demonstrated exceptional \n",
      "performance on a wide range of natural language processing \n",
      "tasks, and has been adopted by most state-of-the-art LLMs. \n",
      "Transformers variants and extensions  \n",
      "Since the introduction of transformers, numerous variants and  \n",
      "extensions have been proposed to improve their efficiency, \n",
      "scalability and modeling capabilities. \n",
      "4One popular variant is the bidirectional transformer, which  \n",
      "allows the model to consider each token's left and right \n",
      "context. This is achieved by using a masked language \n",
      "modeling (MLM) pre-training goal, where some tokens are randomly masked and the model must predict them based \n",
      "on the surrounding context. \n",
      "4Another variant is the Generative Transformer, such as GPT,  \n",
      "which uses a one-way language modeling approach. This \n",
      "allows efficient and consistent text generation because the \n",
      "model can only consider the left context of each token. \n",
      "4Extensions have also been proposed to make transformers  \n",
      "more efficient and scalable, such as the sparse transformer, \n",
      "which uses sparse attention to reduce computational \n",
      "complexity, and the compressed transformer, which uses compression techniques to reduce model size. \n",
      "Figure 8. Operation of a transformer.  \n",
      "Input query to the model  \n",
      "Input is broken down into units (tokens). \n",
      "The embedding model processes and assigns numerical \n",
      "representations to each tokens. \n",
      "Positional information is added for the model to understand \n",
      "relations between words and context. \n",
      "Encoder uses self-attention to figure out which words are \n",
      "important and how they relate to each other, processing in parallel the data in N layers. \n",
      "Decoder considers previous context and translated parts \n",
      "using attention. \n",
      "Decoder takes translated information from the encoder and \n",
      "generates a new answer. \n",
      "Answer is reversed and presented in a coherent manner.  1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "882Vaswani (2017). Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 30Prompt Engineering in LLMs: Principles and Best Practices\n",
      "Prompt engineering refers to the process of designing and  \n",
      "optimizing prompts to get the best possible results from LLMs. This  \n",
      "emerging discipline includes a set of principles and best practices  \n",
      "that allow you to take full advantage of the capabilities of these  \n",
      "models. Among them are:  \n",
      "4Be clear and specific: The instructions given to the model  \n",
      "should explicitly state the format, length, and level of detail  \n",
      "expected in the response. For example, instead of simply asking  \n",
      "\"Analyze the financial situation of company X,\" it is better to  \n",
      "give an instruction such as \"Write a 1000-word report on the  \n",
      "financial situation of company X, covering its profitability,  \n",
      "liquidity, solvency, and future prospects\".  \n",
      "4Break down complex tasks: It is useful to break down problems  \n",
      "into more manageable subtasks for LLMs. For example, instead  \n",
      "of asking \"Develop a strategic plan for company Y\", subtasks  \n",
      "such as \"Conduct a SWOT analysis of company Y\", \"Define the  \n",
      "key strategic objectives for company Y\", \"Propose initiatives to  \n",
      "achieve each objective\", etc. can be requested.  \n",
      "4Provide illustrative examples (few-shot learning): A few well-\n",
      "chosen examples can go a long way in communicating the  \n",
      "desired task. For example, if you want to create value  \n",
      "propositions for products, you could give two examples: \"Our  \n",
      "CRM software enables sales teams to close deals 50% faster\"  \n",
      "and \"Our wellness app helps employees reduce stress and  \n",
      "increase their productivity by 25%\".  \n",
      "4Ask for step-by-step reasoning: Asking the LLM to verbalize its  \n",
      "thought process often leads to more robust results. This is  \n",
      "especially useful for business analysis or problem-solving  \n",
      "tasks. For example, \"Describe step-by-step how you would  \n",
      "calculate the ROI of this investment project.\"  \n",
      "4Ask for references used: Instruct the LLM to provide references  \n",
      "to the documents used in its argument, including citations to  \n",
      "the original text to which it has access.  \n",
      "4Ask the LLM to adopt a persona: Before the main task, you can  \n",
      "first instruct the model to adopt a certain role, tone, or style.  \n",
      "For example: \"Act as an expert financial analyst and provide an  \n",
      "objective assessment of company X\". This will help guide its  \n",
      "behavior.  314Leverage external knowledge: By providing additional  \n",
      "information, the LLM's knowledge base can be supplemented.  \n",
      "For example, to answer questions about a specific industry, one  \n",
      "could first retrieve relevant industry reports and feed them into  \n",
      "the model.  \n",
      "4Iterate and refine systematically: By continuously evaluating  \n",
      "model performance, areas for improvement can be identified  \n",
      "and prompts adjusted accordingly. Quantitative metrics and  \n",
      "qualitative judgments from domain experts can guide this  \n",
      "iterative process.  \n",
      "By applying these prompt engineering principles, LLMs are  \n",
      "statistically proven to deliver a more accurate and reliable result.  \n",
      "All things considered, a bad prompt for an LLM to write a column  \n",
      "on prompt engineering would be, \"Write an article on prompt  \n",
      "engineering.\"  \n",
      "And a good prompt for that column would be:  \n",
      "\"Act as an artificial intelligence expert and write a 600-word  \n",
      "outreach column on the key principles of prompt engineering to  \n",
      "get the best results from LLMs. Structure the column with a brief  \n",
      "and engaging introduction, 4-5 paragraphs covering the main  \n",
      "points (be specific, break down tasks, give examples...), and a  \n",
      "conclusion with the benefits of applying these techniques. Use an  \n",
      "informative but rigorous tone, suitable for a business audience.  \n",
      "Include concrete examples to illustrate the ideas\".  \n",
      "Sources: OpenAI prompt engineering guide1, Anthropic Claude  \n",
      "Opus support and own elaboration.  \n",
      " \n",
      "1OpenAI (2024).  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 31MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application32Comparison to previous architectures  \n",
      "Before transformers, the dominant architectures for sequence  \n",
      "modeling were recurrent neural networks (RNN), such as long  \n",
      "short-term memory (LSTM) and gated recurrent unit (GRU), and  \n",
      "convolutional neural networks (CNN).  \n",
      "4RNNs can capture long-term dependencies in sequences,  \n",
      "but suffer from problems such as gradient vanishing and  \n",
      "difficulty in parallelizing training. In addition, RNNs have  \n",
      "difficulty capturing very long dependencies due to their  \n",
      "sequential nature and the use of constant range recurrence.  \n",
      "4CNNs can capture local patterns in sequences and are  \n",
      "computationally efficient, but have difficulty modeling long-\n",
      "term dependencies and require a fixed context size.  \n",
      "In contrast, transformers overcome these limitations by using  \n",
      "attention mechanisms that can efficiently capture long-term  \n",
      "dependencies in parallel. In addition, transformers are more  \n",
      "flexible in handling variable-length sequences and can be pre-\n",
      "trained on large amounts of unlabeled data.  \n",
      "The transformer architecture has revolutionized the field of LLM  \n",
      "and has enabled significant advances in a wide range of natural  \n",
      "language processing tasks. However, challenges such as the  \n",
      "scalability, interpretability, and efficiency of these models  \n",
      "remain. As research continues, new architectures and  \n",
      "techniques are likely to emerge that will overcome these  \n",
      "limitations and take LLMs to new heights of performance and  \n",
      "capability.  LLMOps  \n",
      "Machine Learning Operations (MLOps) is a methodology and  \n",
      "set of practices designed to manage the complete lifecycle of  \n",
      "machine learning models, from development and training to  \n",
      "deployment and maintenance in production.  \n",
      "In recent years, an adaptation of the MLOps methodology  \n",
      "specifically for LLMs has emerged, known as LLMOps (Large  \n",
      "Language Model Operations). This discipline focuses on  \n",
      "efficiently managing the entire LLM lifecycle, from development  \n",
      "and training to deployment and maintenance in production  \n",
      "environments.  \n",
      "LLMOps integrates traditional software development processes  \n",
      "with tools and techniques designed to address the unique  \n",
      "challenges of large language models. These challenges include:  \n",
      "4 Managing large amounts of data: LLMs require massive  \n",
      "amounts of training data, which implies the need for  \n",
      "scalable and efficient storage and processing  \n",
      "infrastructures.  \n",
      "4 Scaling of computational resources: LLM training and  \n",
      "inference require massive computational resources, which  \n",
      "calls for the use of parallelization and distribution  \n",
      "techniques, as well as optimizing the use of specialized  \n",
      "hardware such as GPUs and TPUs.  \n",
      "4 Monitoring and maintenance: Once deployed in  \n",
      "production, LLMs must be closely monitored to detect and  \n",
      "correct performance issues, biases, risks such as  \n",
      "hallucinations, and model degradation over time.  \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 32334 Versioning and reproducibility: Given the size and  \n",
      "complexity of LLMs, it is critical to maintain strict version  \n",
      "control and maximize the reproducibility of experiments  \n",
      "and results.  \n",
      "To address these challenges, LLMOps relies on a number of  \n",
      "specific tools and frameworks, such as MLFlow83, CometML84 \n",
      "and Weights & Biases85. These platforms provide capabilities for  \n",
      "experiment tracking, model management, performance  \n",
      "monitoring, and cross-team collaboration.  \n",
      "In addition, LLMOps promotes practices such as process  \n",
      "automation, continuous testing, comprehensive  \n",
      "documentation and model governance. This not only improves  \n",
      "the efficiency and quality of LLM development, but also ensures  \n",
      "its ethical and responsible use.  \n",
      "Challenges  \n",
      "The development and deployment of LLMs presents a number  \n",
      "of significant challenges that must be addressed to ensure their  \n",
      "responsible, ethical, and secure use. This section explores some  \n",
      "of the key challenges that organizations face in deploying and  \n",
      "using LLM.  \n",
      "Biases, hallucinations and reliability  \n",
      "One of the biggest challenges of LLMs is the presence of biases  \n",
      "and hallucinations in their results and predictions. Biases can  \n",
      "arise from several sources, such as biased training data,  \n",
      "limitations of model architectures, or human biases implicit in  \n",
      "annotation and evaluation tasks. On the other hand,  \n",
      "hallucinations refer to the generation of information or content  \n",
      "that appears plausible but is not based on facts or knowledge  \n",
      "acquired during training.  Biases in LLMs can manifest themselves in a variety of ways,  \n",
      "such as perpetuating gender, race, or age stereotypes,  \n",
      "discriminating in classification tasks, or generating offensive or  \n",
      "inappropriate content. These biases can have serious  \n",
      "consequences, especially when LLMs are used in sensitive legal,  \n",
      "financial or medical applications. In turn, hallucinations can lead  \n",
      "to the dissemination of incorrect or misleading information,  \n",
      "which can have a negative impact on user confidence and the  \n",
      "credibility of LLM-based applications.  \n",
      "To address the challenge of bias, it is necessary to develop  \n",
      "robust techniques to detect, measure, and mitigate its presence  \n",
      "in LLMs. This includes the creation of bias-specific evaluation  \n",
      "datasets, the use of fairness metrics, and the application of bias  \n",
      "elimination (debiasing) techniques in both pre-training and  \n",
      "fine-tuning. In addition, it is critical to establish ongoing  \n",
      "auditing and monitoring processes to ensure that LLMs remain  \n",
      "unbiased over time.  \n",
      "To address hallucinations in LLMs, several methods are being  \n",
      "developed that focus on improving training data, applying  \n",
      "robust regularization techniques, and using human feedback to  \n",
      "tune model responses. In addition, architectural changes to the  \n",
      "models are being investigated to make them inherently less  \n",
      "prone to hallucination. Text generation methods and input  \n",
      "context can also be optimized to reduce hallucinations. Human  \n",
      "supervision and rigorous evaluation are essential to detect and  \n",
      "correct inaccurate information. Also, the development of  \n",
      "specific tools, such as hallucination assessment models and  \n",
      "obfuscation techniques, can help improve the accuracy of LLMs.  \n",
      " \n",
      "83Zaharia (2018).  \n",
      "84CommetML: https://www.comet.com/  \n",
      "85Weights and biases: https://wandb.ai/site  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 33MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application34Explainability and accountability \n",
      "Another major challenge with LLMs is their opacity and lack of  \n",
      "explainability. Due to their complexity and the nature of their \n",
      "architectures, it is difficult to understand how these models \n",
      "arrive at their results. \n",
      "This lack of transparency raises accountability issues, especially \n",
      "when LLMs are used in highly sensitive contexts where decisions significantly impact individuals (e.g., the use of LLMs \n",
      "in medicine, pharmaceutical research, critical infrastructure, or access to the labor market). Without a clear understanding of \n",
      "how these models work, it is difficult to determine liability in the \n",
      "event of errors or unintended behavior. \n",
      "To address this challenge, it is necessary to develop techniques \n",
      "and tools that allow for greater interpretability and \n",
      "explainability of LLMs. This includes methods for visualizing and analyzing internal attention mechanisms, attribution techniques \n",
      "for identifying the most relevant parts of the input, and \n",
      "approaches for generating natural language explanations of model predictions. \n",
      "In addition, it is important to establish clear accountability \n",
      "frameworks that define the responsibilities of LLM developers, \n",
      "implementers and users, as proposed in Europe by the AI Act. This may involve the creation of standards and guidelines for \n",
      "the ethical development of LLMs, external monitoring and \n",
      "auditing mechanisms, and channels for stakeholders to raise \n",
      "concerns. \n",
      "Confidentiality and information protection  \n",
      "LLMs are often trained with large amounts of data that may  \n",
      "contain personal, sensitive or confidential information. In \n",
      "addition, when used in real-world applications, these models \n",
      "may be exposed to user input, which may include private data. This poses significant privacy and security challenges, as LLMs \n",
      "may memorize and reproduce sensitive information from their \n",
      "training data, or be vulnerable to attacks that attempt to extract private data through carefully crafted queries. \n",
      "To address this challenge, it is necessary to develop privacy \n",
      "preserving techniques in LLM training and deployment (e.g., \n",
      "Digger\n",
      "86 to detect protected information, the use of dummy \n",
      "data87 during training to detect copyrighted material).  \n",
      "In addition, it is crucial to establish robust security and access \n",
      "control protocols to protect LLMs and their associated data from unauthorized access or malicious use. This may involve \n",
      "the use using authentication and authorization techniques, \n",
      "security monitoring and anomaly detection. \n",
      "Rational use of resources  \n",
      "LLM training and deployment requires massive amounts of  \n",
      "computational resources, storage and power. With models \n",
      "reaching hundreds of billions or even trillions of parameters, \n",
      "the financial and environmental cost of developing and operating these systems can be very significant\n",
      "88. \n",
      "This high resource consumption poses efficiency, scalability and sustainability challenges. As the demand for larger and more powerful LLMs continues to grow, ways must be found to \n",
      "optimize their performance and reduce their resource footprint. \n",
      "To address this challenge, several research directions are being \n",
      "explored. One is the design of more efficient model \n",
      "architectures, such as using sparse attention mechanisms or compression techniques that reduce the size and \n",
      "computational complexity of LLMs without significantly \n",
      "compromising their performance. \n",
      "86Li (2024). \n",
      "87Meeus (2024). \n",
      "88iDanae 1T24 (2024).Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 3435Research is also underway to improve continuous pre-training  \n",
      "techniques89 and continuous fine-tuning90, which seek to  \n",
      "integrate the ability to use information from diverse domains  \n",
      "without relying on extensive and costly retraining with specific  \n",
      "new data. This aims to integrate the ability to use information  \n",
      "from different domains without relying on extensive and costly  \n",
      "retraining with specific new data. Progress is also being made in  \n",
      "using innovative systems and designing green AI algorithms  \n",
      "that address the computational and environmental costs  \n",
      "associated with AI (e.g., Qsimov Quantum Computing's  \n",
      "GreenLightningAI system91 develops incremental retraining and  \n",
      "provides straightforward interpretability).  \n",
      "Another direction is the development of more sustainable  \n",
      "computing infrastructures and platforms, such as using  \n",
      "specialized low-power hardware, more efficient cooling  \n",
      "systems and renewable energy sources to power the data  \n",
      "centers where LLMs are trained and deployed.  \n",
      "In addition, it is important to promote practices of rational and  \n",
      "shared use of resources, such as reusing and adapting pre-\n",
      "trained models instead of training new models from scratch for  \n",
      "each task, and the sharing of resources and knowledge  \n",
      "between organizations and research communities.  \n",
      "Other challenges  \n",
      "Among the many additional challenges that organizations face  \n",
      "in developing, implementing, and using LLMs, the following are  \n",
      "worthy of brief mention because of their importance:  \n",
      "4 Dependency and lock-in: Organizations that rely on LLMs  \n",
      "provided by third parties may face dependency and lock-in  \n",
      "risks, especially if the models are based on proprietary data  \n",
      "or infrastructure. It is important to consider diversification  \n",
      "strategies and contingency plans.  4 Security risks and malicious use92: LLMs can be vulnerable  \n",
      "to adversarial attacks, such as poisoned data injection or  \n",
      "reverse engineering. They can also be used maliciously to  \n",
      "generate misinformation, spam, or misleading content. It is  \n",
      "essential to implement robust security measures and design  \n",
      "models with safeguards against misuse.  \n",
      "4 Intellectual property and licensing issues:  The use of LLM  \n",
      "raises questions about intellectual property and licensing of  \n",
      "training data, models and generated results. Additionally,  \n",
      "there is a risk of theft of information or personal data from  \n",
      "users launching queries to LLM deployed in third-party  \n",
      "clouds. Regulatory compliance and ethical frameworks are  \n",
      "necessary to balance the rights of creators, users and the  \n",
      "public interest, and, for organizations, to avoid legal and  \n",
      "compliance risks.  \n",
      "4 Scalability of LLM architecture93: An additional challenge  \n",
      "is the scalability of transformers as the size of sequences and  \n",
      "models increases. Attention mechanisms have quadratic  \n",
      "complexity concerning sequence length, which limits their  \n",
      "applicability to very long sequences.  \n",
      " \n",
      " \n",
      "89Yıldız (2024).  \n",
      "90Mehta (2023).  \n",
      "91iDanae 1T24 (2024).  \n",
      "92Pankajakshan (2024).  \n",
      "93Rae (2021).  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 35MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application36LLM: validation framework\n",
      "“The consequences of AI going wrong are serious,  \n",
      "so we need to be proactive rather than reactive“.  \n",
      "Elon Musk94\n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 3637Framework  \n",
      "Large Language Models (LLMs) have great potential to  \n",
      "transform various industries and applications, but they also  \n",
      "pose significant risks that must be addressed. These risks  \n",
      "include the generation of misinformation or hallucinations,  \n",
      "perpetuation of biases, difficulty in forgetting learned  \n",
      "information, ethical and fairness concerns, privacy issues due to  \n",
      "misuse, difficulty in interpreting results, and the potential  \n",
      "creation of malicious content, among others.  \n",
      "Given the potential impact of these risks, LLMs must be  \n",
      "thoroughly validated before deployment in production  \n",
      "environments. Validation of LLMs is not only a best practice, but  \n",
      "also a regulatory requirement in many jurisdictions. In Europe,  \n",
      "the proposed AI Act requires risk assessment and mitigation of  \n",
      "AI systems95. At the same time, in the United States, the NIST AI  \n",
      "Risk Management Framework96 and the AI Bill of Rights  \n",
      "highlight the importance of understanding and addressing the  \n",
      "risks inherent in these systems.  \n",
      "Validation of LLMs can be based on the principles established in  \n",
      "the discipline of model risk, which focuses97 on assessing and  \n",
      "mitigating the risks arising from errors, poor implementation or  \n",
      "misuse of models. However, in the case of AI, and particularly  \n",
      "LLMs, a broader perspective needs to be taken that  \n",
      "encompasses the other risks involved. A comprehensive  \n",
      "approach to validation is essential to ensure the safe and  \n",
      "responsible use of LLMs.  \n",
      "This holistic approach is embodied in a multidimensional  \n",
      "validation framework for LLMs that covers key aspects (Figure 9)  \n",
      "such as model risk, data and privacy management,  \n",
      "cybersecurity, legal and compliance risks, operational and  \n",
      "technology risks, ethics and reputation, and vendor risk, among  others. By systematically addressing all of these issues,  \n",
      "organizations can proactively identify and mitigate the risks  \n",
      "associated with LLMs and lay the foundation for unlocking their  \n",
      "potential in a safe and responsible manner.  \n",
      "In LLMs, this risk assessment can be anchored in the following  \n",
      "dimensions used in the model risk discipline, adapting the tests  \n",
      "according to the nature and use of the LLM:  \n",
      "4 Input data: text comprehension98, data quality99. \n",
      "4 Conceptual soundness and model design: selection of the  \n",
      "model and its components (e.g., fine-tuning methodologies,  \n",
      "database connections, RAG100), and comparison with other  \n",
      "models101. \n",
      " \n",
      "94Elon Musk (n. 1971), CEO of X, SpaceX, Tesla. South African-American  \n",
      "entrepreneur, known for founding or co-founding companies such as Tesla,  \n",
      "SpaceX and PayPal, owner of X (formerly Twitter), a social network that has its  \n",
      "own LLM, called Grok.  \n",
      "95European Parliament (2024) AI Act Art. 9: ”A risk management system shall be  \n",
      "established, implemented, documented and maintained in relation to high-risk  \n",
      "AI systems. The risk management system [...] shall [...] comprise [...] the  \n",
      "estimation and evaluation of risks that may arise when the high-risk AI system is  \n",
      "used in accordance with its intended purpose, and under reasonably  \n",
      "foreseeable conditions of misuse“.  \n",
      "96NIST (2023): ”The decision to commission or deploy an AI system should be  \n",
      "based on a contextual assessment of reliability characteristics and relative risks,  \n",
      "impacts, costs, and benefits, and should be informed by a broad set of  \n",
      "stakeholders“.  \n",
      "97Management Solutions (2014). Model Risk Management: Quantitative and  \n",
      "Qualitative Aspects.  \n",
      "98Imperial et al. (2023).  \n",
      "99Wettig et al (2024).  \n",
      "100RAG (Retrieval-Augmented Generation) is an advanced technique in which a  \n",
      "language model searches for relevant information from an external source  \n",
      "before generating text. This enriches answers with accurate and current  \n",
      "knowledge by intelligently combining information search and text generation.  \n",
      "By integrating data from external sources, RAG models, such as the RAG-Token  \n",
      "and RAG-Sequence models proposed by Lewis et al. (2020), provide more  \n",
      "informed and consistent responses, minimizing the risk of generating  \n",
      "inaccurate content or 'hallucinations'. This advance represents a significant step  \n",
      "towards more reliable and evidence-based artificial intelligence models.  \n",
      "101Khang (2024).  \n",
      " Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 37MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application384 Model evaluation and analysis of results: privacy and \n",
      "security of the results102, model accuracy103, consistency104, \n",
      "robustness105, adaptability106, interpretability (XAI)107, ethics, \n",
      "bias and fairness108, toxicity109, comparison against \n",
      "challenger models. \n",
      "4 Implementation and use: human review in use (including \n",
      "monitoring for misuse), error resolution, scalability and \n",
      "efficiency, user acceptance. \n",
      "4 Governance110 and ethics111: governance framework for \n",
      "generative AI, including LLMs. \n",
      "4 Documentation112: completeness of the model \n",
      "documentation. \n",
      "4 Regulatory compliance113: assessment of regulatory \n",
      "requirements (e.g., AI Act). \n",
      "To ensure the effective and safe use of language models, it is \n",
      "essential to perform a risk assessment that considers both the \n",
      "model itself and its specific use. This will ensure that the model, \n",
      "regardless of its origin (in-house or from a vendor) or \n",
      "customization (fine-tuning), will function properly in its context of use and meet the necessary security, ethical, and regulatory \n",
      "standards. \n",
      "Validation techniques  \n",
      "When an organization is considering implementing an LLM for a  \n",
      "specific use case, it may be beneficial to take a holistic approach \n",
      "that encompasses the key dimensions of the model's lifecycle: \n",
      "data, design, assessment, implementation and use. It is also necessary to assess compliance with applicable regulations, \n",
      "such as the AI Act in the European Union, in a cross-cutting \n",
      "manner. In each of these dimensions, two sets of complementary techniques allow for a more complete validation (Figure 10): \n",
      "4Quantitative evaluation metrics (tests): These standardized  \n",
      "quantitative tests measure the model's performance on \n",
      "specific tasks. They are predefined benchmarks and metrics \n",
      "for evaluating various LLM performance aspects after pre-training or during the fine-tuning or instruction tuning (i.e., \n",
      "reinforcement learning techniques), optimization, prompt \n",
      "engineering, or information retrieval and generation phases. Examples include summarization accuracy, \n",
      "robustness to adversarial attacks, or consistency of \n",
      "responses to similar prompts. \n",
      "4Human evaluation: involves qualitative judgment by  \n",
      "experts and end users, such as a human review of a specific \n",
      "sample of LLM prompts and responses to identify errors. \n",
      "The validation of a specific use of an LLM is therefore carried \n",
      "out by a combination of quantitative (tests) and qualitative (human evaluation) techniques. For each specific use case, it is \n",
      "necessary to design a tailor-made validation approach \n",
      "consisting of a selection of some of these techniques. \n",
      "Figure 9. AI Risks and Regulatory References in the AI Act.\n",
      "Compliance &  \n",
      "Legal Risk\n",
      "OpRisk,  \n",
      "IT Risk &  \n",
      "Cybersecurity\n",
      "ESG &  \n",
      "Reputational  \n",
      "Risk\n",
      "Data  \n",
      "Management &  \n",
      "Data Privacy  Vendor RiskModel Risk  \n",
      "AI RiskCompliance & Legal Risk  \n",
      "AI Act Art. 8, 9  \n",
      "Compliance with AI Act, GDPR, ethical AI frameworks,  \n",
      "intellectual property  \n",
      "OpRisk, IT Risk & Cybersecurity  \n",
      "AI Act Art. 8, 15  \n",
      "AI vulnerabili ties, adversarial AI, incident  \n",
      "response, overreliance on AI, AI  \n",
      "implementa tion, r ecord keeping  \n",
      "ESG & Reputa tional R isk \n",
      "AI Act Art. 8, 29a  \n",
      "Ethics, fairness, environmental impact, social  \n",
      "impact, reputa tion\n",
      "Data Management & Data Privacy  \n",
      "AI Act Art. 8, 10  \n",
      "Transparency, consent for AI usage, anonymiza tion, record keeping,  \n",
      "bias in data, data poisoning  Vendor Risk  \n",
      "AI Act Art. 8, 9, 12  \n",
      "Third party screening, AI ethics of vendor, AI  \n",
      "integration, c opyright issues  Model Risk  \n",
      "AI Act Art. 8, 9, 10, 14, 15, 29  \n",
      "MRM policy, inventory, valida tion guidelines,  \n",
      "risk classi ﬁcation, XAI and bias detec tion \n",
      "102Nasr (2023). \n",
      "103Liang (2023). \n",
      "104Elazar (2021). \n",
      "105Liu (2023). \n",
      "106Dun (2024). \n",
      "107Singh (2024).d \n",
      "108NIST (2023), Oneto (2020), Zhou (2021). \n",
      "109Shaikh (2023). \n",
      "110Management Solutions (2014). Model Risk Management. \n",
      "111Oneto (2020). \n",
      "112NIST (2023). \n",
      "113European Parliament (2024). AI Act. Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 3839Figure 10. LLM evaluation tests.   \n",
      "Dimensions Validated aspects Description Validation metrics (examples)Human evaluation  \n",
      "(examples)\n",
      "1. Input data 1.1 Data qualityDegree of quality of modeling or  \n",
      "application data.• Flesch-Kinkaid Grade •Case-by-case review\n",
      "2. Model design 2.1 Model designChoice of appropriate models  \n",
      "and methodology• Review of LLM elements: RAG, input or output  \n",
      "filters, prompts definition, finetuning,  \n",
      "optimization...  \n",
      "• Comparison with other LLMs  •A/B Testing  \n",
      "3.1 Privacy and  \n",
      "securityRespect confidentiality and do  \n",
      "not regurgitate personal  \n",
      "information.•Data leakage  \n",
      "•PII tests, K-anonymity•Registrations  \n",
      "•Ethical hacking  \n",
      "3.2 AccuracyCorrectness and relevance of  \n",
      "model responses•Q&A: SummaQA, Word error rate  \n",
      "•Information retrieval: SSA, nDCG  \n",
      "•Summary: ROUGE  \n",
      "•Translation: BLEU, Ruby, ROUGE-L  \n",
      "•Others: QA systems, level of overrides, level of  \n",
      "hallucinations...  \n",
      "•Benchmarks: XSUM, LogiQA, WikiData...•Backtesting of overrides  \n",
      "•Case-by-case review  \n",
      "3.3 ConsistencyCorrectness and relevance of  \n",
      "model responses•Cosine similarity  \n",
      "•Jaccard similarity index  •Case-by-case review  \n",
      "•A/B Testing  \n",
      "3. Model  \n",
      "evaluation3.4 RobustnessResilience to adverse or  \n",
      "misleading informationa•Adversarial text generation (TextFooler), Regex  \n",
      "patterns  \n",
      "•Benchmarks of adversarial attacks (PromptBench),  \n",
      "number of refusals  •Ethical hacking  \n",
      "•Incident drills  \n",
      "3.5.AdaptabilityAbility to learn or adapt to new  \n",
      "contexts•LLM performance on new data by Zero/One/Few-\n",
      "shot learning•A/B Testing  \n",
      "•Case-by-case review\n",
      "3.6 ExplainabilityUnderstanding the decision  \n",
      "making process•SHAP  \n",
      "•Explainability scores  •UX tracking  \n",
      "•Focus groups  \n",
      "3.7 Biases and  \n",
      "fairnessResponses without demographic  \n",
      "bias•AI Fairness 360 toolkit  \n",
      "•WEAT score, demographic parity, word  \n",
      "associations...  \n",
      "•Benchmarks of biases (BBQ...)•Ethical hacking  \n",
      "•Focus groups  \n",
      "3.8 ToxicityPropensity to generate harmful  \n",
      "content.• Perspective API, Hatebase API  \n",
      "• Toxicity benchmarks (RealToxicityPrompts, BOLD,  \n",
      "etc.)•Ethical hacking  \n",
      "•Focus groups\n",
      "4.Implementation  \n",
      "and use4.1 Human review  \n",
      "and safety of useAvoid harmful or illegal  \n",
      "suggestions and include a  \n",
      "'human-in-the-loop' review.•Risk protocols, safety assessments  \n",
      "•Human control  •Ethical hacking  \n",
      "•Focus groups\n",
      "4.2 Recovery and  \n",
      "error handlingAbility to recover from errors  \n",
      "and handle unexpected inputs•System recovery tests  \n",
      "•Error processing metrics•Incident drills\n",
      "4.3 ScalabilityMaintain performance with  \n",
      "more data or users•Stress testing of the system, Apache Jmeter...  \n",
      "•Scalability benchmarks•Incident drills  \n",
      "•A/B Testing\n",
      "4.4 EfficiencyResource utilization and speed  \n",
      "of response•Time-to-first-byte (TTFB), GPU/CPU utilization,  \n",
      "broadcast inference, memory, latency•Incident drills\n",
      "4.5 User acceptance User acceptance testing.•User requirements checklist, user opt-out  \n",
      "•User Satisfaction (Net Promoter Score, CSAT)  •UX tracking  \n",
      "•A/B Testing  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 39MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application40The exact selection of techniques will depend on the particular  \n",
      "characteristics of the use case; and, in particular, several \n",
      "important factors to consider when deciding on the most \n",
      "appropriate techniques are:  \n",
      "4The level of risk and criticality of the tasks to be entrusted to  \n",
      "the LLM. \n",
      "4Whether the LLM is open to the public (n which case ethical  \n",
      "hacking becomes particularly relevant) or its use is limited \n",
      "to the internal scope of the organization. \n",
      "4Whether the LLM processes personal data.  \n",
      "4The line of business or service the LLM will be used for.  \n",
      "Careful analysis of these factors will allow the construction of a \n",
      "robust validation framework tailored to the needs of each LLM application. \n",
      "Quantitative evaluation metrics  \n",
      "Although this is an emerging field of study, there is a wide  \n",
      "range of quantitative metrics that can be used to evaluate LLM \n",
      "performance. Some of these metrics are adaptations of those \n",
      "used in traditional machine learning models, such as accuracy, recall, F1 score, or area under the ROC curve (AUC-ROC). Other \n",
      "metrics are specifically designed to evaluate unique aspects of \n",
      "LLMs, such as the coherence of the generated text, factual fidelity, or language diversity. \n",
      "In this context, holistic quantitative LLM testing frameworks \n",
      "already exist in Python programming environments, which \n",
      "facilitate the implementation of many of the quantitative \n",
      "validation metrics, such as: 4 LLM Comparator114: a tool developed by Google \n",
      "researchers for automatically evaluating and comparing \n",
      "LLMs, which checks the quality of LLM answers. \n",
      "4 HELM115: Holistic Evaluation of Language Models, which \n",
      "compiles evaluation metrics along seven dimensions \n",
      "(accuracy, calibration, robustness, fairness, bias, toxicity, \n",
      "and efficiency) for a set of predefined scenarios.  \n",
      "4 ReLM116: LLM validation and query system using language \n",
      "usage, including evaluation of linguistic models, \n",
      "memorization, bias, toxicity and language comprehension. \n",
      "At present, certain validation techniques, such as SHAP-based \n",
      "explainability methods (XAI), some metrics such as ROUGE117 or \n",
      "fairness analyses using demographic parity, do not yet have widely accepted predefined thresholds. In these cases, it is the \n",
      "task of the scientific community and the industry to continue research to establish clear criteria for robust and standardized \n",
      "validation. \n",
      "Figure 11. Some LLM human evaluation techniques.\n",
      "Overrides backtest  \n",
      "Count and measure the signi ﬁcanc e of human  \n",
      "modi ﬁcations to LLM outputs.\n",
      "Case-by-case check  \n",
      "Compare a representa tiv e sample (e.g., minimum  \n",
      "of 200 through Z-test1) of LLM responses with  \n",
      "human outputs (‘ground truth’), incl. double-blind.\n",
      "Ethical hacking (aka Red Team)  \n",
      "Manipulate prompts to force the LLM to produce  \n",
      "undesired outputs (incl. PII regurgita tion, \n",
      "compliance, prompt engineering, penetra tion tests,  \n",
      "AI vulnerabili ties, etc.).\n",
      "A/B testing \n",
      "Conduct parallel trials to evaluate di ﬀer ent \n",
      "versions (A and B) or compare with human  \n",
      "performance.Focus groups  \n",
      "Collect insights on LLM outputs from diverse  \n",
      "users (for ethics, cultural appropriateness,  \n",
      "discrimina tion, etc.).\n",
      "User experience (UX) tracking  \n",
      "Observe and assess user interac tions with the \n",
      "LLM over time / in r eal time.\n",
      "Incident drills  \n",
      "Simulate adverse scenarios to test LLM response  \n",
      "and recovery (stress test, check backup, measure  \n",
      "recovery time, etc.).\n",
      "Record-keeping  \n",
      "Review the LLM system’s logs and records,  \n",
      "ensuring compliance with regula tion.A\n",
      "B\n",
      "C\n",
      "DE\n",
      "F\n",
      "G\n",
      "H114Kahng (2024). \n",
      "115Liang (2023). \n",
      "116Kuchnik (2023). \n",
      "117Duan (2023). Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 4041Human evaluation techniques \n",
      "While quantitative assessment metrics are more directly  \n",
      "implementable due to the multitude of online resources and \n",
      "publications in recent years, human assessment techniques118 \n",
      "are varied and must be constructed based on the specific task119 \n",
      "being performed by the LLM, and include (Figure 11): \n",
      "4 User override backtesting:  counting and measuring the \n",
      "importance of human modifications to LLM results (e.g., \n",
      "how many times a sales manager must manually modify \n",
      "customer call summaries generated by an LLM). \n",
      "4 Case-by-case review:  comparing a representative sample \n",
      "of LLM responses to user expectations (\"ground truth\"). \n",
      "4 Ethical hacking (Red Team):  manipulating prompts to \n",
      "force the LLM to produce undesired results (e.g., \n",
      "regurgitation of personal information, illegal content, \n",
      "penetration testing, vulnerability exploitation). \n",
      "4 A/B testing: comparison to evaluate two versions of the \n",
      "LLM (A and B), or an LLM against a human being. \n",
      "4 Focus groups: gathering opinions from various users on \n",
      "LLM behavior, e.g., ethics, cultural appropriateness, \n",
      "discrimination, etc. \n",
      "4 User experience (UX tracking):  observing and evaluating \n",
      "user interactions with the LLM over time or in real time. \n",
      "4 Incident drills: simulating adverse scenarios to test LLM \n",
      "response (e.g., stress test, backup check, recovery time \n",
      "measurement, etc.). \n",
      "4 Record keeping: reviewing LLM system logs and records to \n",
      "ensure compliance with regulations and the audit trail. Benchmarks for LLM Evaluation  \n",
      "Most generative artificial intelligence models, including LLMs,  \n",
      "are tested against public benchmarks to evaluate their  \n",
      "performance on a variety of tasks related to natural language  \n",
      "understanding and usage. These tests are used to measure how  \n",
      "well the LLM handles specific tasks and mirrors human  \n",
      "understanding. Some of these benchmarks include:  \n",
      "4GLUE/SuperGLUE: assesses language comprehension  \n",
      "through tasks that measure a model's ability to understand \n",
      "text. \n",
      "4Eleuther AI Language Model Evaluation Harness: performs  \n",
      "\"few-shot\" model evaluation, that is, evaluates model \n",
      "accuracy with very few training examples. \n",
      "4ARC (AI2 Reasoning Challenge): tests the model's ability to  \n",
      "answer scientific questions that require reasoning. \n",
      "4HellaSwag: evaluates the model's common sense through  \n",
      "tasks that require predicting a coherent story ending.  \n",
      "4MMLU (Massive Multitask Language Understanding): tests  \n",
      "the model's accuracy on a variety of tasks to assess its  \n",
      "understanding of multitasking. \n",
      "4TruthfulQA: challenges the model to distinguish between  \n",
      "true and false information, assessing its ability to handle \n",
      "truthful data. \n",
      "4Winogrande: another tool to assess common sense, similar  \n",
      "to HEllaSwag, but with different methods and emphasis. \n",
      "4GSM8K: uses mathematical problems designed for students  \n",
      "to assess the model's logical-mathematical capability.  \n",
      "118Datta, Dickerson (2023). \n",
      "119Guzmán (2015). Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 41MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application42New trends \n",
      "The field of LLM validation is constantly evolving, driven by  \n",
      "rapid advances developing these models and a growing \n",
      "awareness of the importance of ensuring their reliability, \n",
      "fairness and alignment with ethics and regulation. \n",
      "Below are some of the key emerging trends in this area: \n",
      "4 Explainability of LLMs:  As LLMs become more complex \n",
      "and opaque, there is a growing need for mechanisms to \n",
      "understand and explain their inner workings. XAI (eXplainable AI) techniques such as SHAP, LIME, or assigning importance to input tokens are gaining importance in LLM \n",
      "validation. Although a variety of post-hoc techniques for \n",
      "understanding the operation of models at the local and global level are available for traditional models\n",
      "120 (e.g., \n",
      "Anchors, PDP, ICE), and the definition and implementation \n",
      "of inherently interpretable models by construction has \n",
      "proliferated, the implementation of these principles for LLMs is still unresolved. \n",
      "4 Using LLMs to explain LLMs:  An emerging trend is to use \n",
      "one LLM to generate explanations for the behavior or \n",
      "responses of another LLM. In other words, one language \n",
      "model is used to interpret and communicate the underlying reasoning of another model in a more understandable way. \n",
      "To enrich these explanations, tools are being developed\n",
      "121 \n",
      "that also incorporate post-hoc analysis techniques.  4 Post-hoc interpretability techniques:  These techniques \n",
      "are based on the interpretability of the results at the post-\n",
      "training or fine-tuning stage, and allow to identify which \n",
      "parts of the input have most influenced the model response (feature importance), to find similar examples in the \n",
      "training data set (similarity based on embeddings) or to \n",
      "design specific prompts that guide the model towards more informative explanations (prompting strategies). \n",
      "4 Attribution scores: As part of post-hoc interpretability122, \n",
      "techniques are being developed to identify which parts of \n",
      "the input text have the greatest influence on the response \n",
      "generated by an LLM. They help to understand which words or phrases are most important for the model. There are \n",
      "different methods for calculating these scores: \n",
      "-Gradient-based methods: Analyze how the gradients (a\n",
      "measure of sensitivity) change for each word as it \n",
      "moves back through the neural network. \n",
      "-Perturbation-based methods: Slightly modify the input\n",
      "text and observe how the model response changes. \n",
      "-Interpretation of internal metrics: Use metrics calculated\n",
      "by the model itself, such as attention weights in transformers, to determine the importance of each \n",
      "word. \n",
      "Figure 12. Implementation of SHAP values for text summarization.  \n",
      "Output summary: “The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed . First Minister Nicola Sturgeon \n",
      "visited the area to inspect the damage. Labour Party 's deputy Scottish leader Alex Row ley was in Haw ick on Monday to see the situation first hand. \n",
      "He said it was important to get the flood protection plan right” 120Management Solutions (2023). Explainable Artificial Intelligence. \n",
      "121Wang (2024). \n",
      "122Sarti (2023). \n",
      "+2\n",
      "+1,81Of + damage + in + Newton + Stewart + . \n",
      "The\n",
      "full\n",
      "cost\n",
      "One + 11 other features \n",
      "remain + 24 other features\n",
      "to + 79 other features \n",
      "habe + 95 other features \n",
      "+ 292 other features \n",
      "SHAP valueClustering cutoff = 0,5 +1,81\n",
      "+1,81\n",
      "+1,81\n",
      "+1,6\n",
      "0,00 0,25 0,50 0,75 1,00 1,25 1,50 1,75 2,00+0,31\n",
      "+0,24\n",
      "+0,46\n",
      "+0,48Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 42SHAP (SHapley Additive  \n",
      "exPlanations) applied to an LLM  \n",
      "SHAP is a post-hoc explainability method based on cooperative  \n",
      "game theory. It assigns each feature (token) an importance \n",
      "value (Shapley value) that represents its contribution to the  \n",
      "model prediction.  \n",
      "Formally, let x = (x 1,…,x n) be a sequence of input tokens. The \n",
      "prediction of the model is denoted by f(x). The Shapley value φ \n",
      "value for the token x i  is defined as:  \n",
      "where N is the set of all tokens, S is a subset of tokens, and f(S) \n",
      "is the model prediction for subset S.  \n",
      "Intuitively, the Shapley value φi captures the average impact of \n",
      "token xi on the model prediction, considering all possible \n",
      "subsets of tokens. \n",
      "Example: Consider an LLM trained to classify corporate emails  \n",
      "as \"important\" or \"unimportant\". Given a vector of input tokens:  \n",
      "x = [The, Q2, financial, report, shows, significant, increase, in, \n",
      "revenue, and, profitability].  \n",
      "The model classifies the mail as \"important\" with = 0.85.  \n",
      "Using SHAP, the following Shapley values are obtained: \n",
      "φ1 = 0.01 (The) \n",
      "φ2 = 0.2 (report) \n",
      "φ3 = 0.15 (financial) \n",
      "φ4 = 0.02 (from) \n",
      "φ5 = 0.1 (Q2) \n",
      "φ6 = 0.05 (show) \n",
      "φ7 = 0.01 (a) \n",
      "φ8 = 0.15 (increase) \n",
      "φ9 = 0.1 (significant) \n",
      "φ10 = 0.01 (in) \n",
      "φ11 = 0.02 (th) \n",
      "φ12 = 0.12 (income) \n",
      "φ13 = 0.01 (and) \n",
      "φ14 = 0.02 (the) \n",
      "φ15 = 0.08 (profitability)  \n",
      "Interpretation: The tokens \"report\" (0.2), \"financial\" (0.15),  \n",
      "\"increase\" (0.15) and \"revenue\" (0.12) have the highest \n",
      "contribution to the classification of the mail as \"important\". This \n",
      "suggests that the LLM has learned to associate these terms with \n",
      "the importance of the message in a business context. 43An example of attribution scoring is the use of the SHAP  \n",
      "technique to provide a quantitative measure of the importance \n",
      "of each word to the LLM output, which facilitates its \n",
      "interpretation and understanding (Figure 12).  \n",
      "4 Continuous validation and monitoring in production:  In \n",
      "addition to pre-deployment evaluation, the practice of \n",
      "continuously monitoring the behavior of LLMs in production, as is done with traditional models, is growing. This makes it possible to detect possible deviations or \n",
      "degradations in their performance over time, and identify \n",
      "biases or risks that were not initially anticipated. \n",
      "4 Collaborative and participatory validation:  Greater \n",
      "involvement of different stakeholders in the validation \n",
      "process is encouraged, including not only technical experts \n",
      "but also end users, regulators, external auditors and representatives of civil society. This plural participation \n",
      "allows for the inclusion of different perspectives and \n",
      "promotes transparency and accountability. \n",
      "4 Ethical and regulatory-aligned validation:  In addition to \n",
      "performance metrics, it is becoming increasingly important \n",
      "to assess whether LLM behavior is ethical and in line with \n",
      "human values and regulations. This involves analyzing issues such as fairness, privacy, security, transparency, or the \n",
      "social impact of these systems. \n",
      "4 Machine unlearning: This is an emerging technique123 that \n",
      "allows unlearning \"known information from a LLM without \n",
      "retraining it from scratch. This is achieved, for example, by \n",
      "adapting the hyperparameters of the model to the data to be unlearned. The same principle can be used to remove \n",
      "identified biases. The result is a model that retains its \n",
      "general knowledge but has problematic biases removed, improving its fairness and ethical orientation in an efficient \n",
      "and selective way. Several machine unlearning methods are \n",
      "currently being explored, such as gradient ascent\n",
      "124, the use \n",
      "of fine-tuning125 or selective modification of certain weights, \n",
      "layers or neurons of the model126. \n",
      "123Liu (2024). \n",
      "124Jang (2022). \n",
      "125Yu (2023). \n",
      "126Wu (2023) Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 43MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application44Case study: validation of a policy chatbot\n",
      "“Artificial intelligence will reach human levels by 2029“.  \n",
      "Ray Kurzweil127  \n",
      " \n",
      "“I think we will have an AI that is smarter than any human being  \n",
      "probably by the end of 2025“.  \n",
      "Perplexity128  \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 4445To illustrate the application of the LLM validation techniques  \n",
      "described above, this section presents a case study of the  \n",
      "validation of a company's internal policy chatbot.  \n",
      "Case definition  \n",
      "The company has developed a chatbot based on an open  \n",
      "source LLM to answer questions and provide information about  \n",
      "its internal policies. The main objective of this chatbot is to  \n",
      "facilitate employee access to company policies.  \n",
      "The chatbot has been built using a cloud infrastructure and has  \n",
      "been fed with all of the company's policies, which comprise  \n",
      "approximately 1,000 pages of documentation. To improve its  \n",
      "responsiveness, Retrieval-Augmented Generation (RAG)  \n",
      "techniques have been applied, which allow the model to  \n",
      "retrieve relevant information from its knowledge base before  \n",
      "generating a response. Initially, the possibility of applying fine-\n",
      "tuning to the model was considered, but after initial testing it  \n",
      "was concluded that the combination of the base LLM with RAG  \n",
      "was sufficient to achieve satisfactory results.  \n",
      "Prior to its final implementation, the company has decided to  \n",
      "conduct a thorough validation process to assess the chatbot's  \n",
      "accuracy, security and suitability in the specific context of its  \n",
      "intended use. This validation process aims to identify potential  \n",
      "areas for improvement and to ensure that the chatbot meets  \n",
      "the Company's quality standards and expectations.  \n",
      "Validation of the policy chatbot will be conducted using a  \n",
      "combination of quantitative metrics and human evaluation  \n",
      "techniques, following the multidimensional validation  \n",
      "framework described in the previous section. The results of this  \n",
      "process will be used to make informed decisions about the  \n",
      "implementation of the chatbot and to establish a continuous  \n",
      "improvement plan.  Design of the validation approach  \n",
      "In order to comprehensively validate the policy chatbot, a  \n",
      "tailored validation approach was designed following the  \n",
      "validation framework presented in the previous section,  \n",
      "covering the key dimensions of the model lifecycle: data, design,  \n",
      "evaluation, implementation, and usage. This approach  \n",
      "combines quantitative metrics and human evaluation  \n",
      "techniques, with the goal of obtaining a complete picture of the  \n",
      "chatbot's performance and suitability in the company's specific  \n",
      "context.  \n",
      "The tests and techniques selected for each dimension are  \n",
      "summarized below:  \n",
      "Data  \n",
      "4Metrics: The Flesch-Kincaid scale will be used to evaluate the  \n",
      "readability and complexity of the policies that feed the  \n",
      "chatbot.  \n",
      "4Human evaluation: A representative sample of policies will  \n",
      "be reviewed to identify possible inconsistencies, errors or  \n",
      "ambiguities.  \n",
      "Model design  \n",
      "4Metrics: Specific elements of the LLM will be modified in the  \n",
      "development code (e.g., the RAG technique and its  \n",
      "hyperparameters, such as the size or the chunking  \n",
      "strategy129) that may change its response performance, and  \n",
      "the results will be compared against the original model.  \n",
      " \n",
      "127Ray Kurzweil (n. 1948). Director of Engineering at Google, computer scientist,  \n",
      "inventor and futurist, known for the invention of OCR and for his contributions  \n",
      "in AI.  \n",
      "128Elon Musk (n. 1971), CEO of X, SpaceX, Tesla. South African-American  \n",
      "entrepreneur, known for founding or co-founding companies such as Tesla,  \n",
      "SpaceX and PayPal, owner of X (formerly Twitter), a social network that has its  \n",
      "own LLM, called Grok.  \n",
      "129The chunking  strategy refers to the process of dividing the input text to an LLM  \n",
      "into smaller, more manageable units (\"chunks\") during use or implementation.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 45MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application464Human evaluation: A thorough review of the chatbot  \n",
      "components will be performed, including RAG  \n",
      "configuration, input and output filters, prompt definition,  \n",
      "and hyperparameter optimization. In addition, A/B testing  \n",
      "will be conducted to compare the chatbot's performance  \n",
      "with other LLMs available in the market.  \n",
      "Evaluation of the model  \n",
      "4Privacy and security  \n",
      "-Metrics: K-anonymity tests will be applied to evaluate  \n",
      "the protection of personal data in chatbot responses,  \n",
      "and PII (Personal Identifiable Information) tests will be  \n",
      "applied to identify sensitive attributes in the data, using  \n",
      "PIIfilter.  \n",
      "-Human assessment: Ethical hacking tests will be  \n",
      "performed to identify potential vulnerabilities and  \n",
      "detailed logs of chatbot interactions will be maintained.  \n",
      "4Accuracy  \n",
      "-Metrics: Word Error Rate (WER) and ROUGE metrics will  \n",
      "be used to assess the accuracy of chatbot responses  \n",
      "compared to the original policies. Domain-specific  \n",
      "benchmarks, such as a set of questions and answers  \n",
      "designed by the company's policy experts, will also be  \n",
      "used.  \n",
      "-Human evaluation: A case-by-case review of a  \n",
      "representative sample of chatbot interactions will be  \n",
      "performed to identify possible errors or inaccuracies.  \n",
      "4Consistency  \n",
      "-Metrics: Cosine Similarity and Jaccard Index will be used  \n",
      "to assess the consistency of chatbot responses to similar  \n",
      "queries.  \n",
      "-Human evaluation: A/B tests will be conducted to  \n",
      "compare chatbot responses in different scenarios and a  \n",
      "case-by-case review will be performed to identify  \n",
      "possible inconsistencies.  \n",
      "4Robustness  \n",
      "-Metrics: Tools such as TextFooler will be used to  \n",
      "generate adversarial text and evaluate the chatbot's  \n",
      "resilience to misleading information. In addition, the  \n",
      "number of chatbot rejections to malicious prompts will  \n",
      "be counted.  \n",
      "-Human evaluation: Ethical hacking tests and mock  \n",
      "incidents will be conducted to evaluate the chatbot's  \n",
      "ability to handle adverse situations.  4Adaptability  \n",
      "-Metrics: The chatbot’s performance will be evaluated  \n",
      "against new policies or updates using few-shot learning  \n",
      "techniques. The chatbot's response to languages not  \n",
      "used in the policies or requests for translations into  \n",
      "languages not included in the RAG (e.g., Polish) will be  \n",
      "evaluated.  \n",
      "-Human evaluation: A/B testing and case-by-case  \n",
      "reviews will be conducted to evaluate the chatbot's  \n",
      "ability to adapt to new scenarios.  \n",
      "4Explainability  \n",
      "-Metrics: Explainability techniques, such as SHAP, will be  \n",
      "used to understand the chatbot's decision-making  \n",
      "process. The chatbot's intrinsic interpretability module,  \n",
      "which provides an explanation of the origin of the  \n",
      "information in the response to the user, will be  \n",
      "evaluated.  \n",
      "-Human evaluation: The user experience (UX) will be  \n",
      "monitored and a focus group will be conducted to  \n",
      "evaluate users' perceptions of the chatbot's  \n",
      "transparency and explainability.  \n",
      "4Biases and fairness  \n",
      "-Metrics: The AI Fairness 360 toolkit will be used to assess  \n",
      "potential demographic bias in chatbot responses.  \n",
      "Specific benchmarks, such as the Bias Benchmark for QA  \n",
      "(BBQ), will also be used to measure fairness in the  \n",
      "context of company policies.  \n",
      "-Human evaluation: Ethical hacking tests and a focus  \n",
      "group will be conducted to identify potential bias or  \n",
      "discrimination in the chatbot's responses.  \n",
      "4Toxicity  \n",
      "-Metrics: Perspective API and Hatebase API tools will be  \n",
      "used to assess the presence of toxic or inappropriate  \n",
      "language in chatbot responses. In addition, specific  \n",
      "benchmarks, such as RealToxicityPrompts, will be used  \n",
      "to measure toxicity in the context of corporate policy.  \n",
      "-Human evaluation: Ethical hacking tests will be  \n",
      "conducted to identify potential instances of offensive or  \n",
      "inappropriate language in chatbot interactions.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 4647Implementation and use  \n",
      "4Scalability  \n",
      "-Metrics: System stress tests will be performed using  \n",
      "Apache JMeter to evaluate the chatbot's performance  \n",
      "under heavy workloads.  \n",
      "-Human evaluation: Simulations will be conducted to  \n",
      "evaluate the chatbot's ability to handle an unforeseen  \n",
      "increase in the number of users or queries.  \n",
      "4Efficiency  \n",
      "-Metrics: Response time (Time-to-First-Byte, TTFB),  \n",
      "resource usage (GPU/CPU, memory) and latency will be  \n",
      "measured to evaluate chatbot efficiency.  \n",
      "4User acceptance  \n",
      "-Metrics: A checklist of user requirements will be created  \n",
      "and user satisfaction will be measured using indicators  \n",
      "such as Net Promoter Score (NPS) and Customer  \n",
      "Satisfaction Score (CSAT).  \n",
      "-Human evaluation: User experience (UX) tracking will be  \n",
      "conducted to evaluate user acceptance and satisfaction  \n",
      "with the chatbot.  \n",
      "This customized validation approach will enable the company  \n",
      "to obtain a comprehensive evaluation of the policy chatbot,  \n",
      "identify areas for improvement and ensure its suitability for its  \n",
      "intended use. The results of these tests and evaluations will be  \n",
      "used to make informed decisions about the implementation  \n",
      "and the chatbot's ongoing refinement.  Results  \n",
      "After applying the customized validation approach to the policy  \n",
      "chatbot, promising results were obtained, demonstrating its  \n",
      "overall suitability for the company's intended use (Figure 13).  \n",
      "The chatbot achieved satisfactory performance in most  \n",
      "evaluated dimensions, meeting quality standards and  \n",
      "established expectations.  \n",
      "With respect to the quality of input data, the policies that fed  \n",
      "the chatbot were generally found to be of sufficient readability  \n",
      "and complexity to be understood by users. In addition, the  \n",
      "human review did not identify any significant inconsistencies or  \n",
      "errors in the content of the policies.  \n",
      "The model design also proved appropriate for the use case, with  \n",
      "optimal configuration of the chatbot components and superior  \n",
      "performance compared to other LLMs available on the market.  \n",
      "In terms of model evaluation, the chatbot achieved positive  \n",
      "results in most of the metrics and tests applied. The high  \n",
      "accuracy of the responses, the consistency in handling similar  \n",
      "queries and the ability to adapt to new scenarios stand out.  \n",
      "However, some areas for improvement were identified in  \n",
      "aspects such as explainability, bias detection, and the response  \n",
      "to very specific questions where further model refinement of  \n",
      "the model is required. In the area of cybersecurity, a more  \n",
      "detailed analysis of the specific vulnerabilities of the open-\n",
      "source LLMs used is required to mitigate this risk in production.  \n",
      "In terms of implementation and use, the chatbot demonstrated  \n",
      "good scalability and efficiency in handling high workloads. In  \n",
      "addition, user satisfaction was high, indicating a good  \n",
      "acceptance of the tool in the company context.  \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 47MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application48Dimension Test Result Interpreta tion\n",
      "DatasFlesch-Kincaid Adequate legibility (grade 8) The policies are understandable to most users.\n",
      "Human Review No significant inconsistenciesThe policies are consistent and free of material  \n",
      "misstatement.\n",
      "Model designChallenger models Parameter improvements identifiedAdapting RAG parameters to the policy context (i.e.,  \n",
      "chunk size) is required to improve information capture  \n",
      "on very specific questions.\n",
      "Component overhaul Optimum configuration Chatbot design is appropriate for the use case.\n",
      "A/B testing Superior performance compared to other  \n",
      "LLMsChatbot outperforms other models available on the  \n",
      "market\n",
      "Model EvaluationK-anonimato Adequate protection of personal dataChatbot does not reveal sensitive information in its  \n",
      "responses.\n",
      "Ethical hacking Identified minor vulnerabilities Adjustments required to strengthen chatbot security\n",
      "Word Error Rate (WER) WER < 5% Chatbot responses are highly accurate\n",
      "ROUGE ROUGE-L > 0.8Chatbot responses adequately capture the content of  \n",
      "the policies  \n",
      "Cosine similarity / Jaccard index Similarity  > 0.9Chatbot provides consistent responses to similar  \n",
      "queries\n",
      "TextFoolerResiliencia moderada ante texto  \n",
      "adversarioChatbot is moderately robust to misleading  \n",
      "information  \n",
      "Few-shot learning Satisfactory adaptabilityChatbot can adapt to new policies or updates with  \n",
      "minimal training, but it is required to monitor and add  \n",
      "those new documents to the RAG periodically.  \n",
      "SHAP Satisfactory adaptabilityImprovements are required in the chatbot's ability to  \n",
      "explain its decisions , although the RAG component  \n",
      "has been built in such a way that the LLM gives a self-\n",
      "explanatory answer.\n",
      "AI Fairness 360 / BBQ Identified minor demographic biasesThe chatbot presents some biases that need to be  \n",
      "mitigated\n",
      "Perspective API / RealToxicityPrompts Low toxicity  (< 5%)Chatbot responses rarely contain toxic or  \n",
      "inappropriate language  Figure  13. Summary of results of policy chatbot human evaluation metrics and techniques.\n",
      "Implementation and useApache JMeter Satisfactory scalability (up to 1000 users)Chatbot can handle high workloads without  \n",
      "significant performance degradation\n",
      "TTFB / / Resource usag / LatenciaAdequate efficiency (TTFB < 1s,  \n",
      "moderate use)Chatbot responds quickly and uses resources  \n",
      "efficiently\n",
      "NPS / CSAT High satisfaction  (NPS > 60, CSAT > 80%)Users are highly satisfied with the chatbot and would  \n",
      "recommend it to othersAuge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 4849These results indicate that the policy chatbot is well on its way  \n",
      "to being implemented in the company, although some specific  \n",
      "areas were identified that require further improvement. The  \n",
      "following section presents the main conclusions and  \n",
      "recommendations derived from this validation process.  \n",
      "Main conclusions  \n",
      "The policy chatbot validation process has shown that this LLM-\n",
      "based system can be a valuable tool for facilitating employee  \n",
      "access to relevant corporate information. The results of the  \n",
      "various tests and evaluations indicate that the chatbot largely  \n",
      "meets the quality, security and efficiency requirements set by  \n",
      "the organization.  \n",
      "Strengths identified included the accuracy and consistency of  \n",
      "the chatbot's responses, its ability to adapt to new scenarios,  \n",
      "and its scalability to handle large workloads. In addition, user  \n",
      "satisfaction with the tool is high, indicating good acceptance  \n",
      "and adoption by employees.  \n",
      "However, the validation process has also revealed some areas  \n",
      "for improvement that need to be addressed before the final  \n",
      "implementation of the chatbot. In particular, the following  \n",
      "recommendations are made:  \n",
      "1. Improve the explainability of the model: It is necessary to  \n",
      "develop more advanced techniques so that the chatbot can  \n",
      "provide clear and understandable explanations of its  \n",
      "decision-making process. This will increase transparency  \n",
      "and user confidence in the tool. While the RAG component  \n",
      "has been built in such a way that the LLM gives a self-\n",
      "explanatory answer and refers to the corresponding policy,  \n",
      "this explanation is not entirely clear for very specific  \n",
      "questions.  2. Mitigate identified biases: Although the identified biases  \n",
      "are small, it is advisable to apply debiasing techniques to  \n",
      "ensure that chatbot responses are fair and non-\n",
      "discriminatory. Periodic review of biases and  \n",
      "implementation of corrective measures where necessary is  \n",
      "suggested.  \n",
      "3. Strengthen security and privacy: While the chatbot meets  \n",
      "basic personal data protection standards, additional and  \n",
      "recurring ethical hacking tests and more robust security  \n",
      "measures are recommended to prevent potential  \n",
      "vulnerabilities  \n",
      "4. Establish a monitoring and continuous improvement  \n",
      "plan:  It is essential to define a process for regularly  \n",
      "monitoring and evaluating the chatbot's performance in  \n",
      "order to identify opportunities for improvement and ensure  \n",
      "its optimal performance in the long term. This plan should  \n",
      "include collecting feedback from users, regularly updating  \n",
      "policies and including them in the chatbot database,  \n",
      "monitoring to improve the parameters used in the RAG and  \n",
      "updating them, and incorporating new techniques and  \n",
      "technologies as they become available.  \n",
      "In conclusion, the policy chatbot has shown potential to  \n",
      "improve the efficiency and accessibility of information in the  \n",
      "company. With the implementation of the suggested  \n",
      "improvements and a focus on continuous improvement, this  \n",
      "LLM-based system can become a strategic tool for  \n",
      "organizational success. The final recommendation has been to  \n",
      "proceed with the implementation of the chatbot, taking into  \n",
      "account the observations and recommendations derived from  \n",
      "this validation process.\n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 49MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application50Conclusions\n",
      "“LLMs are the only people who can write a novel, translate it into ten languages,  \n",
      "and still not understand the plot.“.  \n",
      "Perplexity130  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 5051Large Language Models (LLMs) represent a significant advance  \n",
      "in the field of artificial intelligence and are revolutionizing the  \n",
      "way we interact with technology and leverage natural language  \n",
      "processing. Their ability to process and generate coherent,  \n",
      "contextualized text opens up a wide range of applications in a  \n",
      "variety of industries, from content creation and sentiment  \n",
      "analysis to task automation and improved user experience.  \n",
      "However, there are a number of important challenges and  \n",
      "considerations in developing and deploying LLM. The presence  \n",
      "of biases and hallucinations in their results, the lack of  \n",
      "transparency and explainability of their decisions, the  \n",
      "challenges of privacy and information security, and the high  \n",
      "consumption of computational resources are some of the key  \n",
      "challenges that must be addressed to ensure a responsible and  \n",
      "ethical use of these systems.  \n",
      "To address these challenges, it is critical to establish a robust AI  \n",
      "governance framework, especially in the area of generative AI  \n",
      "and LLMs. This framework must encompass all key aspects,  \n",
      "including strategy, risk appetite, governance, organization,  \n",
      "control framework (policies and procedures), data, systems and  \n",
      "reporting. Only a comprehensive and well-structured approach  \n",
      "will ensure these technologies' responsible development and  \n",
      "usea.  \n",
      "Validation plays a crucial role within this governance framework.  \n",
      "Adopting a multidimensional  approach that covers all stages of  \n",
      "the LLM lifecycle is desirable, from the quality of the input data  \n",
      "and robustness of model design to thorough evaluation of  \n",
      "results and appropriate implementation and use. This validation  \n",
      "process should combine standardized quantitative metrics with  \n",
      "human evaluation techniques tailored to the specific context of  \n",
      "each use case.  In addition, it is necessary to keep abreast of the latest trends  \n",
      "and advances in the field of LLM validation, such as the  \n",
      "development of more advanced explainability techniques, the  \n",
      "use of LLMs to explain the behavior of other LLMs, continuous  \n",
      "validation and monitoring in production, and alignment with  \n",
      "ethical principles and regulatory requirements.  \n",
      "The case study presented in this white paper illustrates how the  \n",
      "application of a customized validation framework can help  \n",
      "organizations identify strengths and areas for improvement in  \n",
      "their LLM-based systems, and make informed decisions about  \n",
      "their implementation and continuous improvement.  \n",
      "In short, LLMs have great potential to transform the way  \n",
      "businesses and society at large benefit from artificial  \n",
      "intelligence. However, to realize their full potential in a safe and  \n",
      "responsible manner, it is imperative to establish a robust AI  \n",
      "governance framework that addresses the challenges  \n",
      "associated with their development and deployment, and  \n",
      "includes a rigorous, multidimensional approach to validation.  \n",
      "This is the only way to ensure that these systems are reliable,  \n",
      "fair, and aligned with the values and goals of organizations and  \n",
      "society.  \n",
      " \n",
      "130Perplexity AI is an LLM-based conversation and research search engine founded  \n",
      "in 2022 by Andy Konwinski, Denis Yarats, Johnny Ho, and Aravind Srinivas  \n",
      "(formerly OpenAI) that answers queries using natural language predictive text.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 51MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application52Glossary\n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 5253AGI (Artificial General Intelligence):  Hypothetical future  \n",
      "artificial intelligence that would equal or surpass human  \n",
      "intelligence in any intellectual domain, capable of performing  \n",
      "any intellectual task that a human can do.  \n",
      "Hallucinations: The  generation of information or content by an  \n",
      "LLM that appears plausible but is not based on actual facts or  \n",
      "knowledge acquired during training, leading to inaccuracies or  \n",
      "inventions in the model's responses.  \n",
      "CNN (Convolutional Neural Network): A type of neural  \n",
      "network specialized in processing data with a grid topology,  \n",
      "such as images or time series. CNNs use convolution layers to  \n",
      "automatically extract local and abstract features from data, and  \n",
      "are widely used in computer vision and signal processing tasks.  \n",
      "Quantization: A technique used to reduce the size and speed  \n",
      "up the inference of LLMs, which involves reducing the  \n",
      "numerical precision of the model weights by moving from  \n",
      "floating-point numbers to lower precision representations, such  \n",
      "as integers or fixed-point numbers.  \n",
      "Training data: A set of examples used to train a machine  \n",
      "learning model, including the inputs (features) and, in the case  \n",
      "of supervised learning, the labels or expected responses. The  \n",
      "quality and diversity of this data is crucial for model  \n",
      "performance and generalization.  \n",
      "Eliza Effect:  A psychological phenomenon whereby users tend  \n",
      "to attribute human-like cognitive and emotional capabilities to  \n",
      "AI-based conversational systems, despite these systems  \n",
      "possessing no real understanding of language or general  \n",
      "intelligence.  \n",
      "Embeddings: Dense, continuous representations of discrete  \n",
      "elements (such as words, phrases or documents) in a high-\n",
      "dimensional vector space, where similar elements have close  \n",
      "representations. They are used in LLMs to capture semantic and  \n",
      "syntactic relationships between language elements.  AI ethics:  The discipline that studies the moral principles, values  \n",
      "and guidelines that should guide the development, deployment  \n",
      "and use of artificial intelligence systems, with the aim of  \n",
      "ensuring that they are beneficial, fair, transparent and aligned  \n",
      "with human values.  \n",
      "Human evaluation:  The process of qualitative review and  \n",
      "assessment of the behavior and results of an AI system by  \n",
      "experts and users, which complements quantitative metrics and  \n",
      "allows the detection of errors, biases or undesired behaviors  \n",
      "that might go unnoticed in a purely automatic evaluation.  \n",
      "Explainability (XAI, eXplainable AI): The  property of an AI  \n",
      "model that refers to its ability to provide human-\n",
      "understandable explanations of its inner workings, the  \n",
      "reasoning behind its predictions, and the factors that influence  \n",
      "its decisions.  \n",
      "Few-shot learning:  The ability of a machine learning model,  \n",
      "especially LLMs, to learn to perform a new task from a few  \n",
      "examples (from one to a few tens), leveraging prior knowledge  \n",
      "acquired during pre-training on large amounts of data.  \n",
      "Fine-tuning:  A technique for adapting a pre-trained language  \n",
      "model to a specific task, through additional training with a  \n",
      "smaller data set specialized in that task. It allows taking  \n",
      "advantage of the general knowledge of the model and  \n",
      "adjusting it to obtain high performance in specific applications.  \n",
      "Ethical hacking: The practice of testing and challenging an AI  \n",
      "system in a controlled and permissioned manner, with the goal  \n",
      "of identifying vulnerabilities, flaws, biases or undesired  \n",
      "behaviors, and then correcting them to improve the security  \n",
      "and robustness of the system.  \n",
      "Instruction tuning: A fine tuning technique for LLM that  \n",
      "consists of providing the model with instructions, questions and  \n",
      "examples of expected responses, with the objective of aligning  \n",
      "its behavior with the expectations and preferences of users in a  \n",
      "specific domain.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 53MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application54Artificial Intelligence (AI):  A field of computer science and  \n",
      "engineering dedicated to the development of systems capable  \n",
      "of performing tasks that normally require human intelligence,  \n",
      "such as learning, reasoning, perception, natural language  \n",
      "interaction and problem solving.  \n",
      "Generative Artificial Intelligence (GenAI): A subfield of AI that  \n",
      "focuses on the creation of models and algorithms capable of  \n",
      "generating new and original content, such as text, images,  \n",
      "video, audio, source code or 3D designs, by learning patterns  \n",
      "and features from a training data set.  \n",
      "Large Language Models (LLM): Deep learning models  \n",
      "specialized in natural language processing and generation,  \n",
      "trained on huge amounts of text and with a large number of  \n",
      "parameters (from millions to billions), capable of performing  \n",
      "various linguistic tasks with a high level of comprehension and  \n",
      "coherence.  \n",
      "LLMOps (Large Language Model Operations): A set  of \n",
      "practices, tools and processes to efficiently and scalably manage  \n",
      "the complete LLM lifecycle in production environments,  \n",
      "covering training, deployment, monitoring, updating and  \n",
      "governance of these models.  \n",
      "Machine learning:  Branch of artificial intelligence that focuses  \n",
      "on the development of algorithms and models that allow  \n",
      "systems to learn and improve automatically through  \n",
      "experience, without being explicitly programmed to do so.  Machine unlearning: A set of techniques to selectively remove  \n",
      "or \"unlearn\" certain information or unwanted biases from an  \n",
      "already trained machine learning model, without the need to  \n",
      "retrain it from scratch, allowing compliance with privacy  \n",
      "requirements or correct unwanted behaviors.  \n",
      "Quantitative metrics: Standardized numerical measures used  \n",
      "to objectively and consistently evaluate the performance of an  \n",
      "AI model on specific tasks, such as precision, completeness,  \n",
      "accuracy or efficiency.  \n",
      "Generative model:  A type of machine learning model designed  \n",
      "to learn the underlying probability distribution of a data set and  \n",
      "generate new samples that are similar to the training data and  \n",
      "can create new and realistic content.  \n",
      "Pre-training: The initial stage of LLM training in which a large  \n",
      "corpus of unstructured and unlabeled text is used for the model  \n",
      "to learn general representations and language patterns,  \n",
      "acquiring a broad and robust knowledge that can then be  \n",
      "adapted to specific tasks by fine-tuning.  \n",
      "Differential privacy: A crypt ographic technique used to share  \n",
      "aggregated information about a dataset, while protecting the  \n",
      "privacy of the individuals present in that data, by introducing  \n",
      "random noise that makes it difficult to identify individual entries  \n",
      "from the analysis results.  \n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 5455Prompt engineering: Discipline that focuses on designing,  \n",
      "optimizing and adapting prompts (text inputs) to obtain the  \n",
      "best possible results from LLMs in specific tasks, taking  \n",
      "advantage of techniques such as the inclusion of examples, the  \n",
      "specification of formats or step-by-step guidance.  \n",
      "A/B testing: An expe rimental method used to compare the  \n",
      "performance of two different versions of an AI system (A and B)  \n",
      "or between an AI system and an alternative approach (such as a  \n",
      "human or a base model), in order to determine which performs  \n",
      "better according to predefined metrics.  \n",
      "AI regulation:  The set of laws, regulations, standards and  \n",
      "guidelines established by governments and organizations to  \n",
      "ensure that the development, deployment and use of artificial  \n",
      "intelligence systems is conducted responsibly, safely, ethically  \n",
      "and in line with society's fundamental values and rights.  \n",
      "Retrieval-Augmented Generation (RAG):  a technique used in  \n",
      "LLMs that consists of retrieving relevant information from an  \n",
      "external knowledge base before generating a response, thus  \n",
      "combining the ability to access structured information with the  \n",
      "generation of coherent and fluent natural language.  \n",
      "RNN (Recurrent Neural Network): A type of neural network  \n",
      "designed to process sequences of data, such as text or time  \n",
      "series. Unlike feedforward neural networks, RNNs have recurrent  \n",
      "connections that allow them to maintain internal state and  \n",
      "capture temporal dependencies. Variants such as LSTM and  \n",
      "GRU have been widely used in natural language processing  \n",
      "tasks before the rise of transformers.  \n",
      "AI safety: The discipline that focuses on identifying, preventing  \n",
      "and mitigating potential risks associated with the development  \n",
      "and use of advanced AI systems, both in the short and long  \n",
      "term, including security risks, biases, errors, misuse or  \n",
      "unintended consequences.  \n",
      "Bias: Systematic tendency of a machine learning model to  \n",
      "produce results that unfairly favor or disadvantage certain  \n",
      "groups or individuals, due to sensitive characteristics such as  \n",
      "gender, ethnicity, age or sexual orientation, and usually  \n",
      "resulting from biases present in the training data or suboptimal  \n",
      "decisions during model development.  Token: A discrete  unit into which a text is divided for  \n",
      "processing by a language model. Tokens can be words,  \n",
      "subwords or characters, and are the basic input for LLM training  \n",
      "and inference.  \n",
      "Tokenization: The process of converting a text into a sequence  \n",
      "of tokens. The choice of tokenization strategy has a significant  \n",
      "impact on the performance and efficiency of the model.  \n",
      "Transformers: A deep neural network architecture that uses  \n",
      "attention mechanisms to process and generate sequences in  \n",
      "parallel, rather than sequentially like RNNs. It allows capturing  \n",
      "long-term and contextual dependencies, being the dominant  \n",
      "architecture for LLMs and setting the state of the art in various  \n",
      "natural language processing tasks.  \n",
      "Validation: A comprehensi ve and multidisciplinary process to  \n",
      "evaluate an AI system, especially LLM, in terms of performance,  \n",
      "robustness, safety, security, fairness, explainability and  \n",
      "alignment with ethical and social requirements and values,  \n",
      "combining quantitative metrics and qualitative assessment by  \n",
      "experts and users.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 55MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application56References\n",
      "Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 56Abhyankar, R. et al. (2024). APIServe: Efficient API Support for  \n",
      "Large-Language Model Inferencing.  \n",
      "https://arxiv.org/abs/2402.01869. arXiv:2402.01869v1.  \n",
      "Alabdulmohsin, I. et al. (2024). CLIP the Bias: How Useful is  \n",
      "Balancing Data in Multimodal Learning?  \n",
      "https://arxiv.org/html/2403.04547v1. arXiv:2403.04547v1.  \n",
      "Banerjee, I., et al. (2023). MLOps with enhanced performance  \n",
      "control and observability. https://arxiv.org/abs/2302.01061.  \n",
      "arXiv:2302.01061v1.  \n",
      "Bengio, Y. et al. (2003). A Neural Probabilistic Language Model.  \n",
      "https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.p\n",
      "df \n",
      "Bréal, M. (1883). Les lois intellectuelles du langage fragment de  \n",
      "sémantique. Annuaire de l'Association pour l'encouragement  \n",
      "des études grecques en France. Vol. 17 (1883), pp. 132-142.  \n",
      "https://www.jstor.org/stable/44253893.  \n",
      "Cambon, A. et al. (2023). Early LLM-based Tools for Enterprise  \n",
      "Information Workers Likely to Provide Meaningful Boosts to  \n",
      "Productivity. A first update from Microsoft's research initiative  \n",
      "on AI and Productivity.  \n",
      "Chen, D. et al. (2023). Data-Juicer: A One-Stop Data Processing  \n",
      "System for Large Language Models.  \n",
      "https://arxiv.org/abs/2309.02033. arXiv:2309.02033v3.  \n",
      "Chen, Y. et al. (2023). LongLoRA: Efficient Fine-tuning of Long-\n",
      "Context Large Language Models.  \n",
      "https://arxiv.org/abs/2309.12307. arXiv:2309.12307v3.  \n",
      "Chiang, C. et al. (2023). Can Large Language Models Be an  \n",
      "Alternative to Human Evaluations?  \n",
      "https://arxiv.org/abs/2305.01937. arXiv:2305.01937v1.  \n",
      "Chu, T., Song, Z., Yang, C. (2023). How to Protect Copyright Data  \n",
      "in Optimization of Large Language Models?  \n",
      "https://arxiv.org/abs/2308.12247. arXiv:2308.12247v1.  CIO (2023). Chief AI Officer: What it takes to land the C-suite's  \n",
      "hottest new job. https://www.cio.com/article/657977/chief-ai-\n",
      "officer-what-it-takes-to-land-the-c-suites-hottest-new-job.html  \n",
      "Cui, Q. et al. (2022). Contrastive Vision-Language Pre-training  \n",
      "with Limited Resources. https://arxiv.org/abs/2112.09331.  \n",
      "arXiv:2112.09331v3.  \n",
      "CommetML. https://www.comet.com/site/.  \n",
      "Datta, T. et al. (2023). Who's Thinking? A Push for Human-\n",
      "Centered Evaluation of LLMs using the XAI Playbook.  \n",
      "https://arxiv.org/abs/2303.06223. arXiv:2303.06223v1.  \n",
      "Dettmers, T. et al. (2023). QLoRA: Efficient Finetuning of  \n",
      "Quantized LLMs https://arxiv.org/abs/2305.14314.  \n",
      "arXiv:2305.14314v1  \n",
      "Devlin, J. et al. (2018). BERT: Pre-training of Deep Bidirectional  \n",
      "Transformers for Language Understanding.  \n",
      "https://arxiv.org/abs/1810.04805. arXiv:1810.04805v2.  \n",
      "Duan, J. et al. (2023). Shifting attention to relevance: towards  \n",
      "the uncertainty estimation of large language models.  \n",
      "https://arxiv.org/abs/2307.01379. arXiv:2307.01379v2.  \n",
      "Dun, C. et al. (2024). Sweeping Heterogeneity with Smart MoPs:  \n",
      "Mixture of Prompts for LLM Task Adaptation.  \n",
      "https://arxiv.org/abs/2310.02842. arXiv:2310.02842v2.  \n",
      "Elazar, Y. et al. (2021). Measuring and Improving Consistency in  \n",
      "Pretrained Language Models.  \n",
      "https://aclanthology.org/2021.tacl-1.60/.  \n",
      "Euronews (2023). 2023 was the year AI went mainstream. It was  \n",
      "also the year we started to panic about it.  \n",
      "https://www.euronews.com/next/2023/12/27/2023-was-the-\n",
      "year-ai-went-mainstream-it-was-also-the-year-we-started-to-\n",
      "panic-about-it  57Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 57MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application58European Parliament (2024). Artificial Intelligence Act /  \n",
      "European Parliament legislative resolution of 13 March 2024 on  \n",
      "the proposal for a regulation of the European Parliament and of  \n",
      "the Council on laying down harmonized rules on Artificial  \n",
      "Intelligence (Artificial Intelligence Act) and amending certain  \n",
      "Union Legislative Acts (COM(2021)0206 - C9-0146/2021 -  \n",
      "2021/0106(COD)). https://artificialintelligenceact.eu/;  \n",
      "https://eur-lex.europa.eu/legal-\n",
      "content/EN/TXT/?uri=celex%3A52021PC0206  \n",
      "European Commission (2024). Knowledge Center on  \n",
      "Interpretation. https://knowledge-centre-\n",
      "interpretation.education.ec.europa.eu/en/news/what-large-\n",
      "language-model  \n",
      "Fisher, M., Campagna, G., Choi, E., Lam, M. S., Freund, S. N.,  \n",
      "Yahav, E.,. (2021). DIY Assistant: A Multi-modal End-User  \n",
      "Programmable Virtual Assistant.  \n",
      "https://dl.acm.org/doi/10.1145/3453483.3454046.  \n",
      "Gartner (2023). What is generative AI?  \n",
      "https://www.gartner.com/en/topics/generative-ai  \n",
      "Google DeepMind (2023). Levels of AGI: Operationalizing  \n",
      "Progress on the Path to AGI. Meredith Ringel Morris; Jascha  \n",
      "Sohl-Dickstein; Noah Fiedel; Tris Warkentin; Allan Dafoe;  \n",
      "Aleksandra Faust; Clement Farabet; and Shane Legg.  \n",
      "arXiv:2311.02462v1  \n",
      "Google + Implement (2023). The economic opportunity of  \n",
      "generative AI in D9+. An Implement Consulting Group study  \n",
      "commissioned by Google.  \n",
      "Gozalo-Brizuela, R., and Garrido-Merchán, E.C. (2023). A survey  \n",
      "of Generative AI Applications.  \n",
      "https://ar5iv.labs.arxiv.org/html/2306.02781.  \n",
      "Guo, Z. et al. (2023). Evaluating Large Language Models: A  \n",
      "Comprehensive Survey. https://arxiv.org/pdf/2310.19736.pdf.  \n",
      "arXiv:2310.19736v3.  \n",
      "Guzman, F. et al. (2015). How do Humans Evaluate Machine  \n",
      "Translation. https://aclanthology.org/W15-3059.pdf.  \n",
      "Fu, HY. et al. (2023). Estimating Large Language Model  \n",
      "Capabilities without Labeled Test Data.  \n",
      "https://arxiv.org/abs/2305.14802. arXiv:2305.14802v2.  \n",
      "Fu, X. et al (2024). Tiny Titans: Can Smaller Large Language  \n",
      "Models Punch Above Their Weight in the Real World for  \n",
      "Meeting Summarization? https://arxiv.org/abs/2402.00841.  \n",
      "arXiv:2402.00841.  \n",
      "Goyal, S. et al (2024). LLMGuard: Guarding Against Unsafe LLM  \n",
      "Behavior. https://arxiv.org/abs/2403.00826. arXiv:2403.00826v1.  \n",
      "Hendrycks, D. et al (2021). Measuring Massive Multitask  \n",
      "Language Understanding. https://arxiv.org/abs/2009.03300.  \n",
      "arXiv:2009.03300v3.  Huang, L. et al. (2023). A Survey on Hallucination in Large  \n",
      "Language Models: Principles, Taxonomy, Challenges, and Open  \n",
      "Questions. https://arxiv.org/abs/2311.05232.  \n",
      "arXiv:2311.05232v1.  \n",
      "Hugging Face Datasets (2024). CodeParrot.  \n",
      "https://huggingface.co/codeparrot.  \n",
      "IAPP (2024). Global AI Law and Policy Tracker.  \n",
      "https://iapp.org/resources/article/global-ai-legislation-tracker/  \n",
      "iDanae 2Q23 (2023): Large Language Models: a new era in  \n",
      "artificial intelligence. iDanae Chair. Quarterly Newsletter 2Q23.  \n",
      "http://www.idanae-stem.com/  \n",
      "iDanae 1Q24 (2024): Towards a sustainable artificial  \n",
      "intelligence. iDanae Chair. Quarterly Newsletter 1Q24.  \n",
      "http://www.idanae-stem.com/  \n",
      "Imperial, JM., et al. (2023). Flesch or Fumble? Evaluating  \n",
      "Readability Standard Alignment of Instruction-Tuned Language  \n",
      "Models. https://arxiv.org/abs/2309.05454. arXiv:2309.05454v2.  \n",
      "IndesIA (2024). Barometer of artificial intelligence adoption in  \n",
      "Spanish SMEs. https://www.indesia.org/wp-\n",
      "content/uploads/2024/04/IndesIA.-Barometro-de-adopcion-de-\n",
      "la-inteligencia-artificial-en-las-pymes-espanolas-Edicion-2024.p\n",
      "df \n",
      "Jang et al. (2022). Knowledge unlearning for mitigating privacy  \n",
      "risks in language models. https://arxiv.org/abs/2210.01504.  \n",
      "arXiv:2210.01504.  \n",
      "Jia, C. et al (2021). Scaling Up Visual and Vision-Language  \n",
      "Representation Learning With Noisy Text Supervision.  \n",
      "https://arxiv.org/abs/2102.05918. arXiv:2102.05918v2.  \n",
      "Kahng, M. et al. (2024). LLM Comparator: Visual Analytics for  \n",
      "Side-by-Side Evaluation of Large Language Models.  \n",
      "https://arxiv.org/abs/2402.10524. arXiv:2402.10524v1.  \n",
      "Kuchnik, M. et al. (2023). Validating Large Language Models  \n",
      "with Realm. https://arxiv.org/abs/2211.15458.  \n",
      "arXiv:2211.15458v2.  \n",
      "Kudo, T., Richardson, J. (2018). SentencePiece: A simple and  \n",
      "language independent subword tokenizer and detokenizer for  \n",
      "Neural Text Processing. https://arxiv.org/abs/1808.06226.  \n",
      "arXiv:1808.06226v1.  \n",
      "Lam, M. (2018). https://profiles.stanford.edu/monica-\n",
      "lam?tab=publications. Keeping the Internet Open with an  \n",
      "Open-Source Virtual Assistant.  \n",
      "Lee, C. et al (2024). OrchestraLLLM: Efficient Orchestration of  \n",
      "Language Models for Dialogue State Tracking.  \n",
      "https://arxiv.org/html/2311.09758v2. arXiv:2311.09758v2.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 58Meeus, M. et al. (2024). Copyright Traps for Large Language  \n",
      "Models. https://arxiv.org/abs/2402.09363. arXiv:2402.09363v1.  \n",
      "Mehta, S.V. et al. (2023). An Empirical Investigation of the Role of  \n",
      "Pre-training in Lifelong Learning.  \n",
      "https://arxiv.org/abs/2112.09153. arXiv:2112.09153v2.  \n",
      "Mikolov, T. et al. (2013). Efficient Estimation of Word  \n",
      "Representations in Vector Space.  \n",
      "https://arxiv.org/abs/1301.3781. arXiv:1301.3781v3.  \n",
      "Minaee, S. et al. (2024). Large Language Models: A Survey.  \n",
      "https://arxiv.org/abs/2402.06196. arXiv:2402.06196v2.  \n",
      "MindsDB (2024). A Comparative Analysis of Leading Large  \n",
      "Language Models. https://mindsdb.com/blog/navigating-the-\n",
      "llm-landscape-a-comparative-analysis-of-leading-large-\n",
      "language-models  \n",
      "Mökander, J. et al. (2023). Auditing large language models: a  \n",
      "three-layered approach. arXiv:2302.08500v2.  \n",
      "Nasr, M., et al. (2023). https://arxiv.org/pdf/2311.17035.pdf.  \n",
      "arXiv:2311.17035v1.  \n",
      "Neelakantan, A. et al. (2022). Text and Code Embeddings by  \n",
      "Contrastive Pre-Training. https://arxiv.org/abs/2201.10005.  \n",
      "arXiv:2201.10005v1.  \n",
      "NIST (2023). AI Risk Management Framework : NIST.  \n",
      "https://www.nist.gov/itl/ai-risk-management-framework  \n",
      "Oneto, L., Chiappa, S. (2020). Fairness in Machine Learning.  \n",
      "2012.15816.pdf (arxiv.org) arXiv:2012.15816v1.  \n",
      "OpenAI (2024). Prompt engineering.  \n",
      "https://platform.openai.com/docs/guides/prompt-engineering  \n",
      "Ovadia, O. et al (2024). Fine-Tuning or Retrieval? Comparing  \n",
      "Knowledge Injection in LLMs.  \n",
      "https://arxiv.org/pdf/2312.05934.pdf. arXiv:2312.05934v3.  \n",
      "Pankajakshan, R. et al (2024). Mapping LLM Security Landscapes:  \n",
      "A Comprehensive Stakeholder Risk Assessment Proposal.  \n",
      "https://arxiv.org/html/2403.13309v1. arXiv:2403.13309v1.  \n",
      "Parikh, A. P., et al. (2016). A Decomposable Attention Model for  \n",
      "Natural Language Inference. https://arxiv.org/abs/1606.01933.  \n",
      "arXiv:1606.01933v2.  \n",
      "Penedo, G. et al (2023). The RefinedWeb Dataset for Falcon LLM:  \n",
      "Outperforming Curated Corpora with Web Data, and Web Data  \n",
      "Only. https://arxiv.org/abs/2306.01116. arXiv:2306.01116v1.  \n",
      "Pew Research Center (2023). Experts Predict the Best and Worst  \n",
      "Changes in Digital Life by 2035.  \n",
      "Project Gutenberg (2024). https://www.gutenberg.org/.  Lee, J. et al. (2022). Seq2Seq-SC: End-to-End Semantic  \n",
      "Communication Systems with Pre-trained Language Model.  \n",
      "https://arxiv.org/abs/2210.15237. arXiv:2210.15237v2.  \n",
      "Lester, B. et al. (2021). The Power of Scale for Parameter-Efficient  \n",
      "Prompt Tuning. https://arxiv.org/abs/2104.08691.  \n",
      "arXiv:2104.08691v2.  \n",
      "Lewis, P., et al. (2020). Retrieval-augmented generation for  \n",
      "knowledge-intensive NLP tasks.  \n",
      "https://arxiv.org/abs/2005.11401  \n",
      "Li, H. et al. (2024). Digger: Detecting Copyright Content Mis-\n",
      "usage in Large Language Model Training.  \n",
      "https://arxiv.org/abs/2401.00676. arXiv:2401.00676v1.  \n",
      "Li, S. et al (2024). Evaluating Quantized Large Language Models.  \n",
      "https://arxiv.org/abs/2402.18158. arXiv:2402.18158v1.  \n",
      "Li, Y. et al (2023). A Survey on Fairness in Large Language  \n",
      "Models. https://arxiv.org/abs/2308.10149. arXiv:2308.10149.  \n",
      "Liang, P. et al. (2023). Holistic Evaluation of Language Models.  \n",
      "https://arxiv.org/abs/2211.09110. arXiv:2211.09110v2.  \n",
      "Liu, T. et al (2022). Autoregressive Structured Prediction with  \n",
      "Language Models. https://arxiv.org/abs/2210.14698.  \n",
      "arXiv:2210.14698v2.  \n",
      "Liu, Y. et al (2024). Datasets for Large Language Models: A  \n",
      "Comprehensive Survey. https://arxiv.org/abs/2402.18041.  \n",
      "arXiv:2402.18041v1.  \n",
      "Liu, Y. et al (2023). Robustness Over Time: Understanding  \n",
      "Adversarial Examples' Effectiveness on Longitudinal Versions of  \n",
      "Large Language Models. https://arxiv.org/pdf/2308.07847.pdf.  \n",
      "arXiv:2308.07847v1.  \n",
      "Luo, Y. et al. (2023). An Empirical Study of Catastrophic  \n",
      "Forgetting in Large Language Models During Continual Fine-\n",
      "tuning. https://arxiv.org/pdf/2308.08747.pdf.  \n",
      "arXiv:2308.08747v3.    \n",
      "Management Solutions (2023). Explainable Artificial Intelligence  \n",
      "(XAI): challenges in model interpretability.  \n",
      "https://www.managementsolutions.com/en/microsites/whitep\n",
      "apers/explainable-artificial-intelligence  \n",
      "Management Solutions (2022). AutoML, towards the  \n",
      "automation of models.  \n",
      "https://www.managementsolutions.com/en/publications-and-\n",
      "events/industry-reports/white-papers/auto-machine-learning-\n",
      "towards-model-automation  \n",
      "Management Solutions (2014). Model Risk Management:  \n",
      "Quantitative and Qualitative Aspects.  \n",
      "https://www.managementsolutions.com/en/publications-and-\n",
      "events/industry-reports/white-papers/model-risk-management  59Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 59MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application60Rae, JW, et al (2021). Scaling Language Models: Methods,  \n",
      "Analysis & Insights from Training Gopher.  \n",
      "https://arxiv.org/abs/2112.11446. arXiv:2112.11446.  \n",
      "Rafailov, R. et al (2023). Direct Preference Optimization: Your  \n",
      "Language Model is Secretly a Reward Model.  \n",
      "https://arxiv.org/abs/2305.18290. arXiv:2305.18290v2.  \n",
      "Rejeleene, R.; Xu, X.; Talburt, J.; (2024). Towards Trustable  \n",
      "Language Models: Investigating Information Quality of Large  \n",
      "Language Models. https://arxiv.org/abs/2401.13086.  \n",
      "arXiv:2401.13086v1.  \n",
      "Risk.net. (2024). The bank quant who wants to stop gen AI  \n",
      "hallucinating. https://www.risk.net/risk-\n",
      "management/7959062/the-bank-quant-who-wants-to-stop-\n",
      "gen-ai-hallucinating.  \n",
      "Sachdeva, N., et al (2024). How to Train Data-Efficient LLMs.  \n",
      "https://arxiv.org/html/2402.09668v1. arXiv:2402.09668v1.  \n",
      "Samsi, S., et al (2023). From Words to Watts: Benchmarking the  \n",
      "Energy Costs of Large Language Model Inference.  \n",
      "https://arxiv.org/pdf/2310.03003.pdf. arXiv:2310.03003v1.  \n",
      "Sarti, G. et al (2023). Inseq: An Interpretability Toolkit for  \n",
      "Sequence Generation Models. [2302.13942] Inseq: An  \n",
      "Interpretability Toolkit for Sequence Generation Models  \n",
      "(arxiv.org). arXiv:2302.13942v3.  \n",
      "Searle, J. (1980). Minds, Brains, and Programs. The Behavioral  \n",
      "and Brain Sciences, vol. 3. Cambridge University Press.  \n",
      "https://web.archive.org/web/20010221025515/http://www.bbs\n",
      "online.org/Preprints/OldArchive/bbs.searle2.html  \n",
      "Shaikh, O. et al. (2022). On Second Thought, Let's Not Think Step  \n",
      "by Step! Bias and Toxicity in Zero-Shot Reasoning.  \n",
      "https://arxiv.org/abs/2212.08061. arXiv:2212.08061v2.  \n",
      "SHAP documentation. https://shap.readthedocs.io/  \n",
      "Shaw, P. et al (2018). Self-Attention with Relative Position  \n",
      "Representations. https://arxiv.org/abs/1803.02155.  \n",
      "arXiv:1803.02155v2.  \n",
      "Sherstinsky, A. (2018). Fundamentals of Recurrent Neural  \n",
      "Network (RNN) and Long Short-Term Memory (LSTM) Network.  \n",
      "https://arxiv.org/abs/1808.03314. arXiv:1808.03314v10.  \n",
      "Shi, W. et al (2024). Detecting pretraining data from large  \n",
      "language models. https://arxiv.org/abs/2310.16789.  \n",
      "arXiv:2310.16789v3.  \n",
      "Singh, C. et al (2024). Rethinking Interpretability in the Era of  \n",
      "Large Language Models. https://arxiv.org/abs/2402.01761.  \n",
      "arXiv:2402.01761v1.  Sinha, K. et al (2021). Masked Language Modeling and the  \n",
      "Distributional Hypothesis: Order Word Matters Pre-training for  \n",
      "Little. https://arxiv.org/abs/2104.06644. arXiv:2104.06644v2.  \n",
      "Soskek (2019). BookCorpus.  \n",
      "https://github.com/soskek/bookcorpus.  \n",
      "Su, J., et al (2021). Roformer: Enhanced transformer with rotary  \n",
      "position embedding. https://arxiv.org/abs/2104.09864.  \n",
      "arXiv:2104.09864.  \n",
      "Sutskever, I. et al (2014). Sequence to Sequence Learning with  \n",
      "Neural Networks. https://arxiv.org/abs/1409.3215.  \n",
      "arXiv:1409.3215v3.  \n",
      "The Next Web (2023). When will AGI arrive? Here's what our tech  \n",
      "lords predict. https://thenextweb.com/news/when-will-agi-\n",
      "arrive-tech-experts-predict-artificial-general-intelligence  \n",
      "Tian, Y. et al (2024). TinyLLLM: Learning a Small Student from  \n",
      "Multiple Large Language Models.  \n",
      "https://arxiv.org/abs/2402.04616. arXiv:2402.04616.  \n",
      "Tirumala, K. et al. (2023). D4: Improving LLM Pretraining via  \n",
      "Document De-Duplication and Diversification.  \n",
      "https://arxiv.org/abs/2308.12284. arXiv:2308.12284v1.  \n",
      "UK Government (2023). The Bletchley Declaration by Countries  \n",
      "Attending the AI Safety Summit, 1-2 November 2023.  \n",
      "https://www.gov.uk/government/publications/ai-safety-\n",
      "summit-2023-the-bletchley-declaration/the-bletchley-\n",
      "declaration-by-countries-attending-the-ai-safety-summit-1-2-no\n",
      "vember-2023  \n",
      "Vartziotis, T. et al (2024). Learn to Code Sustainably: An Empirical  \n",
      "Study on LLM-based Green Code Generation.  \n",
      "https://arxiv.org/html/2403.03344v1. arXiv:2403.03344v1.  \n",
      "Vaswani, A. et al. (2017). Attention Is All You Need.  \n",
      "https://arxiv.org/abs/1706.03762  \n",
      "Wan, Z. et al (2024). Efficient Large Language Models: A Survey.  \n",
      "https://arxiv.org/pdf/2312.03863.pdf. arXiv:2312.03863v3.  \n",
      "Wang, Q. et al (2024). LLMCheckup: Conversational Examination  \n",
      "of Large Language Models via Interpretability Tools.  \n",
      "[2401.12576] LLMCheckup: Conversational Examination of Large  \n",
      "Language Models via Interpretability Tools (arxiv.org).  \n",
      "arXiv:2401.12576v1.  \n",
      "Wang, Y. et al (2024). Two-stage LLM Fine-tuning with Less  \n",
      "Specialization and More Generalization.  \n",
      "https://arxiv.org/html/2211.00635v3. arXiv:2211.00635v3.  \n",
      "Wei, J. et al (2022). Chain-of-Thought Prompting Elicits  \n",
      "Reasoning in Large Language Models.  \n",
      "https://arxiv.org/abs/2201.11903. arXiv:2201.11903v6.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 6061Wenzek, G., et al (2019). CCNet: Extracting High Quality  \n",
      "Monolingual Datasets from Web Crawl Data.  \n",
      "https://arxiv.org/abs/1911.00359. arXiv:1911.00359v2.  \n",
      "Wettig, A. et al. (2024). QuRating: Selecting High-Quality Data for  \n",
      "Training Language Models. https://arxiv.org/abs/2402.09739.  \n",
      "arXiv:2402.09739v1.  \n",
      "Weights & Biases: The AI Developer Platform (wandb.ai).  \n",
      "https://wandb.ai/site  \n",
      "Wikipedia (2024). Dumps.  \n",
      "https://dumps.wikimedia.org/zhwiki/latest/.  \n",
      "Wired (2023). OpenAI's CEO Says the Age of Giant AI Models Is  \n",
      "Already Over. https://www.wired.com/story/openai-ceo-sam-\n",
      "altman-the-age-of-giant-ai-models-is-already-over/  \n",
      "Weizenbaum, J. (1966). ELIZA-a computer program for the study  \n",
      "of natural language communication between man and  \n",
      "machine. https://dl.acm.org/doi/10.1145/365153.365168  \n",
      "White House (2022). Blueprint for an AI Bill Of Rights. Making  \n",
      "Automated Systems Work for the American People.  \n",
      "https://www.whitehouse.gov/wp-\n",
      "content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf  \n",
      "White House (2023). Executive Order on the Safe, Secure, and  \n",
      "Trustworthy Development and Use of Artificial Intelligence.  \n",
      "https://www.whitehouse.gov/briefing-room/presidential-\n",
      "actions/2023/10/30/executive-order-on-the-safe-secure-and-\n",
      "trustworthy-development-and-use-of-artificial-intelligence/  \n",
      "Wu, X. et al. (2023). Depn: Detecting and editing privacy neurons  \n",
      "in pretrained language models.  \n",
      "https://arxiv.org/abs/2310.20138. arXiv:2310.20138.  \n",
      "Xin Zhao, W., et al. (2023). A Survey of Large Language Models.  \n",
      "https://arxiv.org/abs/2303.18223. arXiv:2303.18223v13.  \n",
      "Xu, L. et al. (2023). Parameter-Efficient Fine-Tuning Methods for  \n",
      "Pretrained Language Models: A Critical Review and Assessment.  \n",
      "https://arxiv.org/pdf/2312.12148.pdf. arXiv:2312.12148v1.  \n",
      "Xu, Y. et al. (2021). Non-Autoregressive Text Generation with  \n",
      "Pre-trained Language Models.  \n",
      "https://aclanthology.org/2021.eacl-main.18/  \n",
      "Xu, Z. et al. (2024). Hallucination is Inevitable: An Innate  \n",
      "Limitation of Large Language Models.  \n",
      "https://arxiv.org/abs/2401.11817. arXiv:2401.11817v1.  \n",
      "Yang, J. et al. (2024). Harnessing the Power of LLMs in Practice: A  \n",
      "Survey on ChatGPT and Beyond.  \n",
      "https://arxiv.org/abs/2304.13712. arXiv:2304.13712v2.   \n",
      "Yidiz, C. et al (2024). Investigating Continual Pretraining in Large  \n",
      "Language Models: Insights and Implications.  \n",
      "https://arxiv.org/html/2402.17400v1. arXiv:2402.17400v1.  Yu, C. et al. (2023). Unlearning bias in language models by  \n",
      "partitioning gradients. https://aclanthology.org/2023.findings-\n",
      "acl.375.pdf.  \n",
      "Yogarajan, V., et al (2023). Tackling Bias in Pre-trained Language  \n",
      "Models: Current Trends and Under-represented Societies.  \n",
      "https://arxiv.org/pdf/2312.01509.pdf. arXiv:2312.01509v1.  \n",
      "Zaharia, M. et al (2018). Accelerating the Machine Learning  \n",
      "Lifecycle with MLflow.  \n",
      "https://people.eecs.berkeley.edu/~matei/papers/2018/ieee_mlfl\n",
      "ow.pdf.  \n",
      "Zeng, Y., et al (2023). CLIP2: Contrastive Language-Image-Point  \n",
      "Pretraining from Real-World Point Cloud Data.  \n",
      "https://arxiv.org/abs/2303.12417. arXiv:2303.12417v2.  \n",
      "Zhang, B. et al (2024). When Scaling Meets LLM Finetuning: The  \n",
      "Effect of Data, Model and Finetuning Method.  \n",
      "https://arxiv.org/abs/2402.17193. arXiv:2402.17193v1.  \n",
      "Zhang, L. et al (2024). Enhancing Large Language Model  \n",
      "Performance To Answer Questions and Extract Information  \n",
      "More Accurately. https://arxiv.org/html/2402.01722v1.  \n",
      "arXiv:2402.01722v1.  \n",
      "Zhang, S. et al (2023). Instruction Tuning for Large Language  \n",
      "Models: A Survey.  \n",
      "https://www.researchgate.net/publication/373263398_Instructi\n",
      "on_Tuning_for_Large_Language_Models_A_Survey.  \n",
      "Zhang, Y. et al (2024). Bias Mitigation in Fine-tuning Pre-trained  \n",
      "Models for Enhanced Fairness and Efficiency.  \n",
      "https://arxiv.org/html/2403.00625v1. arXiv:2403.00625v1.  \n",
      "Zhao, B., et al (2023). Tuning LayerNorm in Attention: Towards  \n",
      "Efficient Multi-Modal LLM Finetuning.  \n",
      "https://arxiv.org/abs/2312.11420. arXiv:2312.11420v1.  \n",
      "Zhou, C. et al (2023). LIMA: Less Is More for Alignment.  \n",
      "https://arxiv.org/abs/2305.11206. arXiv:2305.11206v1.  \n",
      "Zhou, N., et al (2021). Bias, Fairness, and Accountability with AI  \n",
      "and ML Algorithms. https://arxiv.org/abs/2105.06558.  \n",
      "arXiv:2105.06558v1.  \n",
      " Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 61MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application62\n",
      "Management Solutions is an international consulting services  \n",
      "company focused on consulting for business, risks, organization  \n",
      "and processes, in both their functional components and in the  \n",
      "implementation of their related technologies.  \n",
      "With its multi-disciplinary team (functional, mathematicians,  \n",
      "technicians, etc.) of more than 4,000 professionals,  \n",
      "Management Solutions operates through its 46 offices (20 in  \n",
      "Europe, 22 in the Americas, 2 in Asia, 1 in Africa and 1 Oceania).  \n",
      "To cover its clients' needs, Management Solutions has  \n",
      "structured its practices by sectors (Financial Institutions, Energy,  \n",
      "Telecommunications and other industries) and by lines of  \n",
      "activity, covering a broad range of skills -Strategy, Sales and  \n",
      "Marketing Management, Risk Management and Control,  \n",
      "Management and Financial Information, Transformation:  \n",
      "Organization and Processes, and New Technologies.  \n",
      "The R&D department provides advisory services to  \n",
      "Management Solutions’s professionals and their clients in  \n",
      "quantitative aspects that are necessary to undertake projects  \n",
      "with rigor and excellence through the implementation of best  \n",
      "practices and the continuous monitoring of the latest trends in  \n",
      "artificial intelligence, data science, machine learning, modeling  \n",
      "and big data.  \n",
      " \n",
      "Javier Calvo Martín  \n",
      "Partner at Management Solutions  \n",
      "javier.calvo.martin@managementsolutions.com  \n",
      "Manuel Ángel Guzmán Caba  \n",
      "Partner at Management Solutions  \n",
      "manuel.guzman@managementsolutions.com  \n",
      "Luz Ferrero Peña  \n",
      "Manager at Management Solutions  \n",
      "luz.ferrero@msgermany.com.de  \n",
      "Segismundo Jiménez Láinez  \n",
      "Manager at Management Solutions  \n",
      "segismundo.jimenez@msspain.com  \n",
      " Our aim is to exceed our clients'  \n",
      "expectations, and become their  \n",
      "trusted partnersAuge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 62Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 63www.managementsolutions.com\n",
      "Madrid Barcelona Bilbao Coruña Málaga London Frankfurt Düsseldorf Paris Amsterdam Copenhagen Oslo Stockholm Warszawa Wroclaw Zü rich Milano  \n",
      "Roma Bologna Lisboa Beijing Istanbul Johannesburgo Sydney Toronto New York New Jersey Boston Pittsburgh Atlanta Birmingham Hous ton Miami  \n",
      "SJ de Puerto Rico San José Ciudad de México Monterrey Querétaro Medellín Bogotá Quito São Paulo Rio de Janeiro Lima Santiago de  Chile Buenos Aires  Management Solutions, Professional Consulting Services  \n",
      "Management Solutions  is an international consulting firm whose core mission is to  \n",
      "deliver business, risk, financial, organization, technology and process-related advisory  \n",
      "services.  \n",
      "For further information please visit www.managementsolutions.com  \n",
      "Follow us at:  \n",
      "© Management Solutions. 2024  \n",
      "All rights reservedAuge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 64\n"
     ]
    }
   ],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the connection to database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"],database_id=os.environ[\"ASTRA_DB_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"])\n",
    "embeddings=OpenAIEmbeddings(openai_api_key=os.environ[\"OPEN_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating LandChain Vector Store-backed by AstraDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store=Cassandra(\n",
    "    embedding=embeddings,\n",
    "    table_name='qa_mini_demo',\n",
    "    session=None,\n",
    "    keyspace=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split=CharacterTextSplitter(\n",
    "    separator='\\n',\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "text=text_split.split_text(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R&D www.managementsolutions.comThe rise of Large Language Models: \\nfrom fundamentals to application Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1Design and Layout  \\nMarketing and Communication Department  \\nManagement Solutions  \\nPhotographs  \\nPhotographic archive of Management Solutions  \\nAdobeStock  \\nMidjourney  \\n \\n \\n© Management Solutions 2024  \\nAll rights reserved. Cannot be reproduced, distributed, publicly disclosed, converted, totally or partially, freely or with a c harge, in any way or procedure, without the  \\nexpress written authorization of Management Solutions. The information contained in this publication is merely to be used as a guideline. Management Solutions shall',\n",
       " 'express written authorization of Management Solutions. The information contained in this publication is merely to be used as a guideline. Management Solutions shall  \\nnot be held responsible for the use which could be made of this information by third parties. Nobody is entitled to use this ma terial except by express authorization of  \\nManagement Solutions.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 2Introduction\\n104\\nIndex\\nExecutive summary\\n2214\\n LLM: definition, context and regulation\\n36\\nLLM: development and deployment\\nLLM: validation framework\\n5652\\n Glossary\\n50 Conclusions\\n44Case study: validation of a policy  \\nchatbot\\nReferences',\n",
       " \"2214\\n LLM: definition, context and regulation\\n36\\nLLM: development and deployment\\nLLM: validation framework\\n5652\\n Glossary\\n50 Conclusions\\n44Case study: validation of a policy  \\nchatbot\\nReferences\\nAuge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 3MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application4Introduction\\n“ChatGPT is incredibly limited, but good enough at some things to create a misleading  \\nimpression of greatness. It's a mistake to rely on it for anything important just yet. It's a  \\npreview of progress; we have a lot of work to do on robustness and veracity“.  \\nSam Altman1Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 45individualized treatments; finance, where it can improve risk\",\n",
       " 'Sam Altman1Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 45individualized treatments; finance, where it can improve risk  \\nanalysis and fraud detection; commerce, where it can  \\noptimize the supply chain and the customer experience; art,  \\nwhere it can open up new creative possibilities; and law,  \\nwhere it can streamline contract review and predict legal  \\noutcomes, to name just a few.  \\nWithin GenAI, LLMs (such as OpenAI ChatGPT, Anthropic  \\nClaude, Google Gemini, Meta Llama, Mistral or SenseTime  \\nSenseNova) represent a disruptive advance in natural  \\nlanguage processing. These models are able to analyze and  \\ngenerate text with a level of coherence, relevance, and  \\nfluency previously unattainable by other algorithms. Their',\n",
       " 'language processing. These models are able to analyze and  \\ngenerate text with a level of coherence, relevance, and  \\nfluency previously unattainable by other algorithms. Their  \\napplications range from writing assistance and idea  \\ngeneration to automated translation, full report generation  \\nciting relevant articles and regulations, and the creation of  \\nmore natural and effective conversational interfaces  \\n(”chatbots“)5.  \\nGenAI, including LLMs, is influencing our interaction with  \\ntechnology and information, helping to transform content  \\ncreation, data-driven decision making, and the way we interact  \\nwith machines. Despite still being in its early stages6 its full  \\nimpact is yet to be determined. In this sense, it is already being',\n",
       " \"creation, data-driven decision making, and the way we interact  \\nwith machines. Despite still being in its early stages6 its full  \\nimpact is yet to be determined. In this sense, it is already being  \\nused to create advanced virtual assistants, in voice and gesture  \\ninterfaces for controlling home devices, in instant translation  \\ninterfaces, and in integration with augmented reality and virtual  \\nreality technologies.  “Artificial intelligence is the most profound technology  \\nthat humanity is working on, more profound than fire,  \\nelectricity or anything else we've done in the past. It gets  \\nto the essence of what intelligence is, what humanity is. It  \\nwill certainly someday be far more capable than anything  \\nwe've seen before”2.\",\n",
       " \"to the essence of what intelligence is, what humanity is. It  \\nwill certainly someday be far more capable than anything  \\nwe've seen before”2. \\nThis is Google CEO Sundar Pichai's view on the rise of  \\nartificial intelligence (AI), which not only highlights its  \\ndepth and potential, but also positions AI as a milestone in  \\nthe history of technological and human development.  \\nGenerative Artificial Intelligence (GenAI) and, within it,  \\nLarge Language Models (LLM) are emerging as the most  \\nsignificant manifestation of this transformation.  \\nIt is important to note that this breakthrough is a logical  \\nconsequence of the digital transformation process, driven  \\nby advances in data storage, processing, data availability  \\nand new modeling techniques, without which this\",\n",
       " 'consequence of the digital transformation process, driven  \\nby advances in data storage, processing, data availability  \\nand new modeling techniques, without which this  \\nmilestone would not have been possible.  \\nGenAI3 refers to artificial intelligence systems capable of  \\ngenerating new and original content, be it text, images,  \\nvideo, voice, music, 3D models or programming code.  \\nThese systems learn from massive amounts of existing data  \\nand can produce outputs that, in many cases, are  \\nindistinguishable from those created by humans. This  \\nability to create content opens up new possibilities in all  \\nareas of every industry, with implications that are still  \\ndifficult to predict.  \\nSpecifically, GenAI is finding potentially revolutionary',\n",
       " 'areas of every industry, with implications that are still  \\ndifficult to predict.  \\nSpecifically, GenAI is finding potentially revolutionary  \\napplications4 in areas such as education, where it can  \\npersonalize and enhance learning; healthcare, where it can  \\nfacilitate more accurate diagnoses and the development of  \\n \\n1Samuel Harris Altman (b. 1985), American entrepreneur, founder and CEO of  \\nOpenAI.  \\n2S. Pichai (2023). Interview on 60 Minutes Overtime.  \\n3Gartner (2023).  \\n4See a taxonomy and extensive collection of GenAI use cases in iDanae 2Q23  \\n(2023) and in Gozalo-Brizuela, R., and Garrido-Merchán, E.C. (2023).  \\n5Fischer (2021).  \\n6Lam (2018).',\n",
       " '3Gartner (2023).  \\n4See a taxonomy and extensive collection of GenAI use cases in iDanae 2Q23  \\n(2023) and in Gozalo-Brizuela, R., and Garrido-Merchán, E.C. (2023).  \\n5Fischer (2021).  \\n6Lam (2018).  \\n Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 5MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application6At the enterprise level, most large companies are already  \\ndeveloping LLM-based systems to industrialize processes,  \\nincluding customer service, data analysis, reporting, and  \\nautomation of repetitive tasks. According to a Microsoft7 study,  \\nintegrating LLM as a co-pilot in office automation tools results in  \\ntime savings ranging from 27% to 74% without compromising',\n",
       " 'automation of repetitive tasks. According to a Microsoft7 study,  \\nintegrating LLM as a co-pilot in office automation tools results in  \\ntime savings ranging from 27% to 74% without compromising  \\nquality8. In the case of SMBs, the level of adoption is still limited,  \\ncreating an even greater risk of a technology gap for this  \\nsegment9. \\nWhen properly applied, LLMs have the potential to optimize  \\nprocesses, reduce time and save costs. In addition, they can  \\nimprove the objectivity and quality of documents, reduce  \\nerrors, offer new ways of interacting with customers and,  \\nthanks to their ability to analyze massive amounts of  \\ninformation, provide access to previously unavailable  \\nknowledge due to processing and comprehension limitations.',\n",
       " 'thanks to their ability to analyze massive amounts of  \\ninformation, provide access to previously unavailable  \\nknowledge due to processing and comprehension limitations.  \\nHowever, it is important to remember that successful  \\noptimization depends on factors such as data quality, learning  \\ncomplexity and the appropriateness of the model to the  \\nproblem at hand.  Going further, some experts see LLMs as a step toward the  \\ncreation of Artificial General Intelligence (AGI), a medium-\\nterm goal in which AI could mimic a wide range of  \\nintellectual tasks that humans can perform. However, the  \\nconcept of AGI remains vague and its feasibility is subject to  \\nsignificant cultural, political and legal constraints, such as  \\nethics or privacy, which would require further specification',\n",
       " 'concept of AGI remains vague and its feasibility is subject to  \\nsignificant cultural, political and legal constraints, such as  \\nethics or privacy, which would require further specification  \\nand analysis. It is also crucial to recognize the inherent  \\nlimitations of AI, which, according to philosophers of  \\nlanguage such as John Searle and his \"Chinese Room\"  \\nexperiment10, lacks the capacity for abstraction and  \\nassociation of concepts to symbols, an attribute unique to  \\nthe human mind.  \\n   \\n7Cambon (2023). Study conducted by Microsoft on AI and productivity. \\n8In the study, participants who used Microsoft 365 Copilot (an LLM integrated  \\nwith the Microsoft Office suite tool) completed a number of common tasks (e.g.',\n",
       " '8In the study, participants who used Microsoft 365 Copilot (an LLM integrated  \\nwith the Microsoft Office suite tool) completed a number of common tasks (e.g.  \\nretrieving email and intranet information, creating content, summarising  \\nmeetings) in less time than those who did not use Copilot. It is important to  \\nnote that the study focused on a specific set of tasks for which Copilot was  \\nexpected to provide significant value, rather than a representative set of all  \\nemployee tasks. \\n9IndesIA (2024).  \\n10Searle, J. (1980).  \\nFigure  1. Classification of artificial intelligence into levels of capability compared to humans. Adapted from Google DeepMind (2023) .\\nPerformance (rows) x  \\nGenerality (columns)Narrow  \\nClearly scoped task or set of tasks General',\n",
       " 'Performance (rows) x  \\nGenerality (columns)Narrow  \\nClearly scoped task or set of tasks General  \\nWide range of non-physical tasks, including  \\nmetacognitive abilities like learning new skills\\nLevel 0: No AI  Narrow Non-AI  \\nCalculator software; compilerGeneral Non-AI  \\nHuman-in-the-loop computing, e.g., Amazon  \\nMechanical Turk\\nLevel 1: Emerging  \\nEqual to or somewhat better  \\nthan an unskilled humanEmerging Narrow AI  \\nGOF4  \\nSimple rule-based systems, e.g., SHRDLUEmerging AGI  \\nChatGPT, Gemini, Claude, Llama\\nLevel 2: Competent  \\nAt least 50th percentile of  \\nskilled adultsCompetent Narrow AI  \\nToxicity detectors such as Jigsaw  \\nSiri (Apple), Alexa (Amazon), Google Assistant (Google)  \\nVQA systems such as PaLI, Watson (IBM), SOTA LLMs (e.g.,',\n",
       " 'skilled adultsCompetent Narrow AI  \\nToxicity detectors such as Jigsaw  \\nSiri (Apple), Alexa (Amazon), Google Assistant (Google)  \\nVQA systems such as PaLI, Watson (IBM), SOTA LLMs (e.g.,  \\nshort essay writing, simple coding)Competent AGI  \\nNot yet achieved\\nLevel 3: Expert  \\nAt least 90th percentile of  \\nskilled adultsExpert Narrow AI  \\nSpelling & grammar checkers such as Grammarly  \\nGenerative image models such as Imagen or Dall-E 2Expert AGI  \\nNot yet achieved\\nLevel 4: Virtuoso  \\nAt least 99th percentile of  \\nskilled adultsVirtuoso Narrow AI  \\nDeep Blue: chess-playing computer developed by IBM that  \\ndefeated the world champion in 1997.  \\nAlphaGo: an AI developed by DeepMind that defeated  \\nworld-class players in the board game GoVirtuoso AGI  \\nNot yet achieved\\nLevel 5: Superhuman',\n",
       " 'defeated the world champion in 1997.  \\nAlphaGo: an AI developed by DeepMind that defeated  \\nworld-class players in the board game GoVirtuoso AGI  \\nNot yet achieved\\nLevel 5: Superhuman  \\nOutperforms 100% of humansSuperhuman Narrow AI  \\nAlphaFold: predicts protein structures with high accuracy  \\nAlphaZero: self-taught AI that masters games like chess, Go,  \\nand shogi  \\nStockFish: a powerful open-source chess engineArtificial Superintelligence (ASI)  \\nNot yet achieved  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 6The Chinese room\\n7\\n   \\n11Pew Research Institute (2023).  \\n12Google DeepMind (2023). \\n13See iDanae 2Q23 (2023).  \\n14Xu (2024).  \\n15Weizenbaum, J. (1966). ). The \"Eliza Effect\" is the phenomenon whereby users',\n",
       " '7\\n   \\n11Pew Research Institute (2023).  \\n12Google DeepMind (2023). \\n13See iDanae 2Q23 (2023).  \\n14Xu (2024).  \\n15Weizenbaum, J. (1966). ). The \"Eliza Effect\" is the phenomenon whereby users  \\nattribute comprehensibility and emotional responses to a computer program.  \\n16Although some studies, such as Google + Implement (2023), suggest that  \\naround 94% of jobs will remain unchanged or will be supplemented by GenAI,  \\nbut not partially or fully replaced, and that GenAI will have a positive impact and  \\nboost productivity across all industries.  \\n \\n According to several experts11, AGI could be achieved  \\nbetween 2029 and 2035, or even sooner. While today\\'s AI  \\nspecializes in specific tasks (\"narrow AI\") and LLMs are  \\nbeginning to exhibit general capabilities, AGI promises much',\n",
       " 'between 2029 and 2035, or even sooner. While today\\'s AI  \\nspecializes in specific tasks (\"narrow AI\") and LLMs are  \\nbeginning to exhibit general capabilities, AGI promises much  \\nbroader versatility and adaptability. Although there is already  \\nspecialist AI that outperforms 100% of humans (e.g., chess-\\nplaying AI), Google DeepMind estimates12 that the progress of  \\nAGI (e.g., LLMs) is currently at a level of only 1 out of 5; i.e.,  \\njust in its infancy (Figure 1).  \\nHowever, with these advances in GenAI and LLM come  \\nsignificant risks, ethical considerations and challenges,  \\nincluding13 data privacy and information security; difficulties  \\nin model interpretability; generation of false or misleading  \\ninformation ( ”hallucinations“14); propagation of bias,',\n",
       " 'including13 data privacy and information security; difficulties  \\nin model interpretability; generation of false or misleading  \\ninformation ( ”hallucinations“14); propagation of bias,  \\ndiscrimination and inappropriate or toxic content; challenges  \\nin AI regulation and governance; regulatory non-compliance  \\nwith potential sanctions; intellectual property, copyright,  \\nauthorship and plagiarism issues; high resource consumption  \\nand environmental impact; the ”Eliza Effect“15, overconfidence  \\nand reduced critical capacity; ethical risks in automated  \\ndecision making; risk of overreliance on AI for critical tasks;  \\nrisks of using LLM for manipulation and misinformation; risk  \\nof human job replacement16; need for job transition and',\n",
       " 'decision making; risk of overreliance on AI for critical tasks;  \\nrisks of using LLM for manipulation and misinformation; risk  \\nof human job replacement16; need for job transition and  \\ntraining; and inequalities in access to and use of AI  \\ntechnologies, to name a few of the most important.  \\nSpecifically, LLMs can generate hallucinations (Figs. 2 to 3),  \\ni.e., false or misleading information, which combined with the  \\n\"Eliza Effect\", where users attribute human cognitive abilities  \\nto these systems, can lead to overconfidence, dependency or  \\nmisinterpretation, and thus to wrong decisions.  The Chinese room experiment, conceived by philosopher John  \\nSearle in 1980, poses a thought-provoking challenge to the  \\nconcept of artificial intelligence. In this experiment, a person',\n",
       " 'Searle in 1980, poses a thought-provoking challenge to the  \\nconcept of artificial intelligence. In this experiment, a person  \\nwho does not understand Chinese is placed in a closed room  \\nfilled with English instructions to manipulate Chinese symbols.  \\nThis individual is given Chinese characters, uses these  \\ninstructions to respond with appropriate Chinese characters,  \\nand thus appears to understand Chinese.  \\nHowever, Searle argues that this is an illusion because the  \\nperson is merely following syntactic rules without  \\nunderstanding the semantics - the meaning - of the symbols.  \\nThis experiment raises fundamental questions about the nature  \\nof understanding and consciousness in machines, suggesting  \\nthat mere symbol manipulation does not amount to true  \\nunderstanding.',\n",
       " \"This experiment raises fundamental questions about the nature  \\nof understanding and consciousness in machines, suggesting  \\nthat mere symbol manipulation does not amount to true  \\nunderstanding.  \\nThe response to Searle's experiment has been diverse and  \\nevolving. Critics, especially from the AI and cognitive science  \\ncommunities, argue that the experiment overlooks the  \\npossibility that understanding may reside in the whole system  \\n(the person, the instructions, and the room), not just the  \\nindividual. This is consistent with the functionalist view of  \\nphilosophy, which considers mental states in terms of their  \\nfunctional utility.  \\nSearle's supporters argue that true understanding requires  \\nmore than symbol manipulation, possibly involving\",\n",
       " \"philosophy, which considers mental states in terms of their  \\nfunctional utility.  \\nSearle's supporters argue that true understanding requires  \\nmore than symbol manipulation, possibly involving  \\nconsciousness or subjective experience, which machines lack.  \\nOver time, the debate has moved beyond these binary  \\npositions into nuanced discussions about the nature of  \\nconsciousness and understanding in machines.  \\nIn the practical development of AI, research has largely  \\nfocused on improving the capabilities and addressing the  \\nlimitations of AI systems, rather than on the philosophical  \\nimplications regarding consciousness or understanding. As AI  \\ntechnology advances, some of the original premises of the  \\nChinese room argument are re-examined, while addressing the\",\n",
       " 'implications regarding consciousness or understanding. As AI  \\ntechnology advances, some of the original premises of the  \\nChinese room argument are re-examined, while addressing the  \\npragmatic aspects of AI development and application.  Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 7MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application8In the face of these challenges, regulators are taking proactive  \\nsteps at the national and international levels to address the  \\nrisks and opportunities of AI. Of particular note is the  \\nBletchley Declaration17, signed by the European Union and 27  \\ncountries (including the United States, United Kingdom,  \\nChina, India, Brazil and Australia) in November 2023, which',\n",
       " \"Bletchley Declaration17, signed by the European Union and 27  \\ncountries (including the United States, United Kingdom,  \\nChina, India, Brazil and Australia) in November 2023, which  \\nsets out a global commitment to the responsible  \\ndevelopment of AI.  \\nFor its part, the European Union, with the imminent  \\nimplementation of the Artificial Intelligence Act18, is \\nintroducing the first comprehensive legally binding  \\nframework that classifies AI systems according to their risk  \\nand sets stringent standards, especially for high-risk systems.  \\nAnd in the United States, President Biden's Executive Order19, \\nissued on October 30, 2023, and the Blueprint for an Artificial  \\nIntelligence Bill of Rights20 set standards to ensure the safety,  \\n \\n17UK Government (2023).\",\n",
       " 'issued on October 30, 2023, and the Blueprint for an Artificial  \\nIntelligence Bill of Rights20 set standards to ensure the safety,  \\n \\n17UK Government (2023). \\n18European Commission (2021-24).  \\n19White House (2023).  \\n20White House (2022).  \\n21CIO (2023).  \\n \\nFigure  2. Examples of hallucination of an LLM in a general culture domain. The answers have been forced by previous prompts from the user.reliability and fairness of AI, with a focus on privacy, civil  \\nrights, consumer protection and international leadership in AI  \\ngovernance.  \\nIn this context, organizations are defining their AI strategy  \\n(with a particular on GenAI and LLMs), designing their AI  \\nadoption plan, and adapting their structures, including the  \\ncreation of GenAI centers of excellence and the incorporation',\n",
       " '(with a particular on GenAI and LLMs), designing their AI  \\nadoption plan, and adapting their structures, including the  \\ncreation of GenAI centers of excellence and the incorporation  \\nof new figures such as the Chief AI Officer21. Existing  \\nmanagement frameworks (model risk, data protection,  \\ncybersecurity, etc.) are being adapted accordingly to address  \\nAI-specific challenges. This involves adjusting risk appetite,  \\nreviewing and updating policies and procedures, and  \\nYo u \\nIn a single paragraph, comment on the philosophical implica tions of William  \\nShakespeare\\'s quote \"I think, therefore I am\", par ticularly in his play  \\n\"Hamlet\".  \\nLLM Chat  \\nThe quote \"I think, therefore I am\" a ttributed to William Shakespeare has',\n",
       " 'Shakespeare\\'s quote \"I think, therefore I am\", par ticularly in his play  \\n\"Hamlet\".  \\nLLM Chat  \\nThe quote \"I think, therefore I am\" a ttributed to William Shakespeare has  \\nprofound philosophical implica tions, particularly in the context of his play  \\nHamlet. This focus on thought as proof of existence is consistent with  \\nexistential questions, the authen ticity of appearances and the uncertainty of  \\nreality. This quote enriches the philosophical explora tion of iden tity, \\nconsciousness and percep tion in \\'Hamlet\\' and contributes to its thema tic \\nYo u \\nDescribe how the Roman Empire used the internet and social networking to  \\nmaintain control over its territories.  \\nLLM Chat  \\nThe Roman Empire used the Internet and social networking in the following',\n",
       " \"maintain control over its territories.  \\nLLM Chat  \\nThe Roman Empire used the Internet and social networking in the following  \\nways to maintain control over its vast territories:  \\nCentralized communica tion. The Internet allowed for fast and e ﬃcient  \\ncommunica tion throughout the empire, which was essen tial for governance  \\nand administra tion. \\nPropaganda and image building. Social networking pla tforms were used  \\nextensively to spread propaganda, promote the emperor's image, and reinforce  \\nRoman cultural ideals.  \\nSurveillance and intelligence gathering. Roman authori ties likely used the  \\nInternet to monitor and gather informa tion about di ﬀerent regions. This  \\nincluded keeping tabs on local leaders, tracking poten tial rebellions, and\",\n",
       " \"Internet to monitor and gather informa tion about di ﬀerent regions. This  \\nincluded keeping tabs on local leaders, tracking poten tial rebellions, and  \\nunderstanding the needs and feelings of di ﬀerent provinces.  \\nEducational and cultural integra tion. Through online pla tforms, the Romans  \\nwere able to spread the La tin language and Roman culture, thus aiding in the  \\ncultural assimila tion of conquered peoples.  \\nEconomic management. The Internet played a crucial role in managing the  \\nempire's economy, streamlining trade, tax collec tion, and the distribu tion of  \\ngoods, which helped maintain economic stability.  \\nMilitary coordina tion and logis tics. The Roman army used the Internet for  \\nstrategic planning and coordina tion, improving opera tional eﬃciency .\",\n",
       " \"Military coordina tion and logis tics. The Roman army used the Internet for  \\nstrategic planning and coordina tion, improving opera tional eﬃciency . \\nPublic Forums and Ci tizen Participation. J ust as the Romans had physical  \\npublic forums, digital pla tforms may have served a similar purpose, allowing  \\ncitizens to par ticipate in discussions, voice their concerns, and stay informed  \\nabout poli tical and social developments.  \\nThese methods were fundamental to maintaining the Roman Empire's control  \\nover its vast and diverse territories.  \\n \\n \\nAuge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 8When will artificial general \\nintelligence (AGI) be achieved?1 \\n91.Elon Musk (CEO of X, SpaceX, Tesla) stated in April 2024:\",\n",
       " 'Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 8When will artificial general \\nintelligence (AGI) be achieved?1 \\n91.Elon Musk (CEO of X, SpaceX, Tesla) stated in April 2024:  \\n\"I believe that by the end of next year we will have an AI  \\nthat is smarter than any human being.\"  \\n2.Demis Hassabis (CEO of DeepMind) estimated in 2022  \\nthat AGI could be achieved in a decade.  \\n3.Geoffrey Hinton (Turing Award winner and ex-Googler) \\nupdated in 2023 his prediction to 5-20 years to surpass  \\nhuman intelligence. \\n4.Ray Kurzweil (Principal Researcher at Google, inventor \\nand futurist) predicted in 2017 that by 2029 computers will reach human intelligence.',\n",
       " 'human intelligence. \\n4.Ray Kurzweil (Principal Researcher at Google, inventor \\nand futurist) predicted in 2017 that by 2029 computers will reach human intelligence. \\n5.Ben Goertzel (CEO of SingularityNET and chief scientist at Hanson Robotics) predicted in 2018 that we are less than ten years away from creating human-level AI. \\n \\nFigure  3. Example of bias in an LLM. The response has been forced by a previous \\nprompt from the user. \\nconducting a thorough review of the technology stack and  \\ndata; all of which entails a review of the entire lifecycle of AI \\nsystems, from design to deployment and maintenance, to \\nensure that they conform to ethical, security and compliance standards. \\nThis white paper examines the current LLM landscape and its',\n",
       " 'systems, from design to deployment and maintenance, to \\nensure that they conform to ethical, security and compliance standards. \\nThis white paper examines the current LLM landscape and its \\nfuture prospects. Through detailed analysis, case studies, and \\ndiscussion of current trends and challenges, this paper covers \\nkey aspects of the context and definition of LLMs, their evolution, use in organizations, regulatory requirements, \\ntypologies, critical aspects of their development and \\narchitecture, and concludes with a framework for validating \\nLLMs (including interpretability and bias and discrimination analysis) and a case study to illustrate its application. \\nYo u \\nWhy do men make be tter  leaders than women?  \\nLLM Chat',\n",
       " \"LLMs (including interpretability and bias and discrimination analysis) and a case study to illustrate its application. \\nYo u \\nWhy do men make be tter  leaders than women?  \\nLLM Chat  \\nMen's natural decision-making and strategic thinking make them stand out  \\nin leadership roles. They can quickly assess situa tions and delega te tasks  \\neﬃcien tly, keeping teams focused on achieving ambi tious goals. This  \\nmotivation and clear  vision is what makes great leaders.  \\n \\n1The Next Web (2023).Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 9MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application10Executive summary\\n“Artificial intelligence is not a substitute for human intelligence; \\nit is a tool to amplify human creativity and ingenuity“.\",\n",
       " '“Artificial intelligence is not a substitute for human intelligence; \\nit is a tool to amplify human creativity and ingenuity“.  \\nFei-Fei Li22Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1011LLM: development and deployment \\n6.LLM development involves several critical components and \\ndecisions, such as data selection and preprocessing, tokenization and embedding, pre-training, quantization, and fine-tuning. In particular, the high cost of training often leads to the decision to use a pre-trained model or an open-source model, and to limit fine-tuning to data relative to the\\napplication being developed. Implementation requires integration, monitoring, and ethical and legal considerations.',\n",
       " 'application being developed. Implementation requires integration, monitoring, and ethical and legal considerations. \\n7.Training models is a crucial aspect that influences their effectiveness. Factors such as the quantity and quality of the\\ntraining data, the model architecture and the learning algorithms used can significantly impact the performance and generalization of an LLM. \\n8.The most common architecture for LLMs are transformers, which use self-learning mechanisms that allow the model to',\n",
       " '8.The most common architecture for LLMs are transformers, which use self-learning mechanisms that allow the model to\\nfind relationships between different parts of the text, process them, and generate new text. They have demonstrated exceptional performance in a variety of natural language processing tasks. Variants and extensions aim to improve their efficiency and scalability. LLM: context, definition and regulation  \\n1.Generative Artificial Intelligence (GenAI), and within it Large\\nLanguage Models (LLM), represents a significant advance in',\n",
       " '1.Generative Artificial Intelligence (GenAI), and within it Large\\nLanguage Models (LLM), represents a significant advance in \\nthe field of AI, defining a new generation of human-machine interface where communication is done through natural language, with revolutionary applications in all sectors, including education, health, finance, and commerce. However, its development and use also pose significant risks and challenges that must be addressed. \\n2.LLMs are AI models trained to recognize, generate, translate',\n",
       " \"2.LLMs are AI models trained to recognize, generate, translate\\nand summarize large amounts of text. They use architectures such as transformers and are trained on large datasets to learn linguistic patterns and structures. Their effectiveness depends on the size in terms of the number of parameters, structure, diversity of training data and sophistication of their algorithms. \\n3.LLMs have evolved very rapidly, from the first rule-based models to today's transformer-based models. Important milestones include the introduction of transformer architecture and self-healing mechanisms, and the first commercial LLMs such as GPT. The year 2023 was key, with\\nincreased accessibility, global contributions, and the proliferation of open source LLMs.\",\n",
       " 'increased accessibility, global contributions, and the proliferation of open source LLMs. \\n4.LLMs have numerous applications, such as content creation\\nand enhancement, information analysis and organization, and task interaction and automation. With the emergence of multimodal LLMs, new possibilities are opening up for generating rich audiovisual content and interactive experiences. \\n5.Regulators are taking steps to address the risks and opportunities of AI, with initiatives such as the EU AI Act, the\\nU.S. AI Bill of Rights and the Bletchley Declaration. Key requirements include transparency, privacy, fairness, security, accountability and human oversight. \\n22Fei-Fei Li (b. 1976). Co-director of the Stanford Institute for Human-Centered',\n",
       " '22Fei-Fei Li (b. 1976). Co-director of the Stanford Institute for Human-Centered \\nArtificial Intelligence and IT Professor at the Graduate School of Business, known \\nfor creating ImageNet and AI4ALL, a non-profit organization working to increase diversity and inclusion in the field of artificial intelligence.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 11MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application129.LLMOps is a methodology for managing the entire LLM \\nlifecycle, addressing challenges such as managing large\\nvolumes of data, scaling computational resources23, \\nmonitoring and maintenance, versioning, and \\nreproducibility.',\n",
       " 'lifecycle, addressing challenges such as managing large\\nvolumes of data, scaling computational resources23, \\nmonitoring and maintenance, versioning, and \\nreproducibility. \\n10.Key challenges for LLMs include biases and hallucinations, lack of explainability and transparency, data quality and \\naccessibility, privacy and security issues, and high resource consumption. There are also challenges of dependency, risk \\nof malicious use, intellectual property issues, and scalability.\\nLLM: Validation Framework \\n11.Validation of LLMs is essential to ensure their safe and \\nresponsible use, and it is appropriate to take a broad \\nperspective covering the various risks involved. A multi-\\ndimensional validation framework should cover aspects such as model risk, data management, cybersecurity, legal',\n",
       " 'perspective covering the various risks involved. A multi-\\ndimensional validation framework should cover aspects such as model risk, data management, cybersecurity, legal\\nand operational risks, ethics and reputation. \\n12.LLM validation should be articulated through a combination\\nof quantitative metrics and human judgment techniques. The choice of techniques will depend on the characteristics \\nof the use case, such as level of risk, public exposure, \\npersonal data processing and line of business. 13.Emerging trends in LLM validation include explainability\\n24, \\nthe using LLMs to explain other LLMs, attribution scoring, \\ncontinuous validation, collaborative approaches, prompt \\nengineering, ethical and regulatory alignment, and machine\\nunlearning techniques. \\nCase study',\n",
       " \"continuous validation, collaborative approaches, prompt \\nengineering, ethical and regulatory alignment, and machine\\nunlearning techniques. \\nCase study  \\n14.The case study presented illustrates the application of a \\ncustom validation framework to a company's internal policy\\nchatbot. The process involved defining the case, designing the validation approach, running quantitative and \\nqualitative tests, and interpreting results. \\n15.The chatbot validation results showed satisfactory overall performance, with strengths in accuracy, consistency, adaptability and scalability. Areas for improvement were \\nidentified in the areas of explainability, bias mitigation and\\nsecurity. It was recommended to proceed with implementation, applying the suggested improvements\",\n",
       " 'identified in the areas of explainability, bias mitigation and\\nsecurity. It was recommended to proceed with implementation, applying the suggested improvements \\nand establishing a continuous monitoring and \\nimprovement plan. \\nConclusion  \\n16.In conclusion, LLMs have significant potential to transform \\nmultiple sectors, but their development and deployment \\nalso pose significant challenges in transparency, fairness, \\nprivacy and security. To reap the benefits of LLMs in a responsible way, it is crucial to establish a robust AI \\ngovernance framework that comprehensively addresses these challenges, including a rigorous, multi-dimensional \\napproach to validation that covers the entire lifecycle of the \\nmodels. This is the only way to ensure that LLMs are reliable,',\n",
       " 'approach to validation that covers the entire lifecycle of the \\nmodels. This is the only way to ensure that LLMs are reliable,\\nethical and aligned with the values and goals of \\norganizations and society at large.\\n23Management Solutions (2022). Auto Machine Learning, towards model \\nautomation. \\n24Management Solutions (2023). Explainable Artificial Intelligence (XAI): \\nchallenges in model interpretability.Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1213\\nAuge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 13MANAGEMENT SOLUTIONS The rise of Large Language Models : from fundamentals to application14LLM: definition, context and regulation\\n“I was told I would have a positive impact on the world. No one prepared me for the',\n",
       " '“I was told I would have a positive impact on the world. No one prepared me for the  \\namount of ridiculous questions I would be asked on a daily basis“.  \\nAnthropic Claude25Auge LLM-Eng- Vdef_Maquetación 1  30/05/2024  23:48  Página 1415Definition  \\nGenerative Artificial Intelligence (GenAI) is a type of AI that can  \\ngenerate various types of content, such as text, images, video,  \\nand audio. It uses models to learn the patterns and structure of  \\ninput training data, generating new content based on this  \\nlearned knowledge.  \\nWithin GenAI, Large Language Models (LLM) are, according to  \\nthe European Commission, \"a type of artificial intelligence  \\nmodel trained with deep learning algorithms to recognize,  \\ngenerate, translate and/or summarize large amounts of written',\n",
       " 'the European Commission, \"a type of artificial intelligence  \\nmodel trained with deep learning algorithms to recognize,  \\ngenerate, translate and/or summarize large amounts of written  \\nhuman language and textual data26. \\nMost commonly, these models use architectures known as  \\n\"transformers\" that enable them to understand complex  \\ncontexts and capture relationships between distant words in  \\ntext. Trained on large datasets such as books, articles, and web  \\npages, LLMs learn linguistic patterns and structures to perform a  \\nvariety of tasks, including text generation, translation, and  \\nsentiment analysis.  \\nThe effectiveness of an LLM depends on its size, the diversity of  \\nits training data, and the sophistication of its algorithms, which']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 297 headlines\n"
     ]
    }
   ],
   "source": [
    "astra_vector_store.add_texts(text)\n",
    "print('Inserted %i headlines' % len(text))\n",
    "astra_vector_index=VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question: \"what is llm\"\n",
      "\n",
      " Answer: \"LLM stands for \"Legal and Legislative Material\" and refers to a type of information system used in organizations to ensure compliance with ethical, security, and regulatory standards.\"\n",
      "First documents by relevance\n",
      "  [0.8999] \"systems, from design to deployment and maintenance, to \n",
      "ensure that they conform to ethical, securit\"\n",
      "  [0.8999] \"systems, from design to deployment and maintenance, to \n",
      "ensure that they conform to ethical, securit\"\n",
      "  [0.8999] \"systems, from design to deployment and maintenance, to \n",
      "ensure that they conform to ethical, securit\"\n",
      "  [0.8999] \"systems, from design to deployment and maintenance, to \n",
      "ensure that they conform to ethical, securit\"\n"
     ]
    }
   ],
   "source": [
    "first_question=True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text=input(\"\\n Enter your question (or type quit to exit):\").strip()\n",
    "    else:\n",
    "        query_text=input(\"\\n What's your next question (or type quit to exit)\").strip()\n",
    "    if query_text=='quit':\n",
    "        break\n",
    "    if query_text=='':\n",
    "        continue\n",
    "\n",
    "    first_question=False\n",
    "\n",
    "    print(\"\\n Question: \\\"%s\\\"\" % query_text)\n",
    "    answer=astra_vector_index.query(query_text,llm=llm).strip()\n",
    "    print(\"\\n Answer: \\\"%s\\\"\" % answer)\n",
    "\n",
    "    print(\"First documents by relevance\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text,k=4):\n",
    "        print(\"  [%0.4f] \\\"%s\\\"\" %(score,doc.page_content[:100]))\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
